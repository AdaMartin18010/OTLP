receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size: 4194304
        max_concurrent_streams: 16
        read_buffer_size: 524288
        write_buffer_size: 524288
      http:
        endpoint: 0.0.0.0:4318
        max_request_body_size: 4194304
        include_metadata: true
        cors:
          allowed_origins:
            - "http://localhost:3000"
            - "https://example.com"
          allowed_headers:
            - "Content-Type"
            - "Authorization"
          max_age: 7200

  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  zipkin:
    endpoint: 0.0.0.0:9411

  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['localhost:8888']

processors:
  # 批处理配置
  batch:
    timeout: 1s
    send_batch_size: 512
    send_batch_max_size: 2048
    metadata_keys:
      - "service.name"
      - "service.version"
      - "deployment.environment"

  # 内存限制
  memory_limiter:
    check_interval: 2s
    limit_mib: 512
    spike_limit_mib: 128
    limit_percentage: 80
    spike_limit_percentage: 95

  # 资源检测
  resourcedetection:
    detectors: [env, system, gcp, aws, azure]
    timeout: 2s
    override: false

  # 属性处理
  attributes:
    actions:
      - key: "service.name"
        action: "upsert"
        value: "advanced-service"
      - key: "deployment.environment"
        action: "insert"
        value: "production"
      - key: "host.name"
        action: "delete"

  # 采样
  probabilistic_sampler:
    sampling_percentage: 10.0
    hash_seed: 22

  # 过滤
  filter:
    traces:
      span:
        - 'attributes["http.method"] == "GET"'
        - 'attributes["http.status_code"] >= 400'
    metrics:
      metric:
        - 'name == "http_requests_total"'
    logs:
      log_record:
        - 'attributes["severity"] >= "WARN"'

  # 转换
  transform:
    trace_statements:
      - context: span
        statements:
          - set(attributes["processed"], true)
          - set(attributes["processor"], "advanced")
    metric_statements:
      - context: metric
        statements:
          - set(attributes["processed"], true)
    log_statements:
      - context: log
        statements:
          - set(attributes["processed"], true)

  # 路由
  routing:
    from_attribute: "service.name"
    default_exporters: [logging]
    table:
      - value: "user-service"
        exporters: [jaeger, prometheus]
      - value: "order-service"
        exporters: [jaeger, prometheus]
      - value: "payment-service"
        exporters: [jaeger, prometheus]

exporters:
  # 日志导出
  logging:
    loglevel: info
    sampling_initial: 5
    sampling_thereafter: 200
    verbosity: detailed

  # Jaeger导出
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # Prometheus导出
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "otel"
    const_labels:
      environment: "production"
      service: "collector"
    send_timestamps: true
    metric_relabeling:
      - source_labels: [__name__]
        regex: "http_requests_total"
        target_label: "metric_type"
        replacement: "counter"
    label_rename:
      - from: "service_name"
        to: "service"

  # OTLP导出
  otlp:
    endpoint: "https://api.honeycomb.io:443"
    headers:
      "x-honeycomb-team": "${HONEYCOMB_API_KEY}"
    tls:
      insecure: false
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 1000
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # 文件导出
  file:
    path: "/tmp/otel-data.json"
    format: "json"

  # Kafka导出
  kafka:
    brokers: ["kafka:9092"]
    topic: "otel-data"
    encoding: "json"
    metadata:
      full: true
      retry:
        max: 3
        backoff: 1s

extensions:
  # 健康检查
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/"

  # 性能分析
  pprof:
    endpoint: 0.0.0.0:1777
    block_profile_fraction: 0
    mutex_profile_fraction: 0

  # 内存分析
  memory_ballast:
    size_mib: 512

  # 配置热重载
  config:
    endpoint: 0.0.0.0:5555

  # 服务发现
  k8s_observer:
    auth_type: "serviceAccount"
    node: "${NODE_NAME}"
    observe_pods: true
    observe_nodes: true
    observe_services: true

service:
  extensions: [health_check, pprof, memory_ballast, config, k8s_observer]
  pipelines:
    traces:
      receivers: [otlp, jaeger, zipkin]
      processors: [memory_limiter, resourcedetection, attributes, probabilistic_sampler, filter, transform, routing, batch]
      exporters: [logging, jaeger, otlp, file, kafka]
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, resourcedetection, attributes, filter, transform, routing, batch]
      exporters: [logging, prometheus, otlp, file, kafka]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, attributes, filter, transform, routing, batch]
      exporters: [logging, otlp, file, kafka]
  telemetry:
    logs:
      level: info
      development: false
      disable_caller: false
      disable_stacktrace: false
      sampling:
        initial: 5
        thereafter: 200
    metrics:
      level: detailed
      address: 0.0.0.0:8888
      readers:
        - periodic:
            interval: 10s
