# 指标采集与聚合

**文档版本**: 1.0.0  
**创建日期**: 2025年10月7日  
**所属**: 第四部分 - 监测与实时观测  

---

## 目录

- [指标采集与聚合](#指标采集与聚合)
  - [目录](#目录)
  - [概述](#概述)
  - [4.2.1 指标采集策略](#421-指标采集策略)
    - [Push模式](#push模式)
    - [Pull模式](#pull模式)
    - [混合模式](#混合模式)
  - [4.2.2 指标聚合算法](#422-指标聚合算法)
    - [时间序列聚合](#时间序列聚合)
    - [多维聚合](#多维聚合)
    - [近似聚合](#近似聚合)
  - [4.2.3 指标存储优化](#423-指标存储优化)
    - [降采样](#降采样)
    - [压缩算法](#压缩算法)
    - [分层存储](#分层存储)
  - [4.2.4 查询优化](#424-查询优化)
    - [索引策略](#索引策略)
    - [查询缓存](#查询缓存)
  - [总结](#总结)

---

## 概述

本文档介绍OTLP指标的采集、聚合、存储和查询优化技术。

---

## 4.2.1 指标采集策略

### Push模式

**OTLP Push实现**：

```go
// Push模式指标收集器
type PushCollector struct {
    endpoint string
    client   *http.Client
    buffer   *MetricBuffer
    interval time.Duration
}

func (pc *PushCollector) Start() {
    ticker := time.NewTicker(pc.interval)
    defer ticker.Stop()
    
    for range ticker.C {
        pc.flush()
    }
}

func (pc *PushCollector) flush() error {
    // 1. 获取缓冲的指标
    metrics := pc.buffer.GetAll()
    if len(metrics) == 0 {
        return nil
    }
    
    // 2. 转换为OTLP格式
    request := &otlpmetrics.ExportMetricsServiceRequest{
        ResourceMetrics: pc.convertToOTLP(metrics),
    }
    
    // 3. 序列化
    data, err := proto.Marshal(request)
    if err != nil {
        return err
    }
    
    // 4. 发送到Collector
    resp, err := pc.client.Post(
        pc.endpoint,
        "application/x-protobuf",
        bytes.NewReader(data),
    )
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return fmt.Errorf("push failed: %d", resp.StatusCode)
    }
    
    // 5. 清空缓冲
    pc.buffer.Clear()
    return nil
}

// 指标缓冲区
type MetricBuffer struct {
    metrics []Metric
    maxSize int
    mu      sync.Mutex
}

func (mb *MetricBuffer) Add(metric Metric) bool {
    mb.mu.Lock()
    defer mb.mu.Unlock()
    
    if len(mb.metrics) >= mb.maxSize {
        return false  // 缓冲区满
    }
    
    mb.metrics = append(mb.metrics, metric)
    return true
}
```

### Pull模式

**Prometheus Pull实现**：

```go
// Pull模式指标暴露器
type PullExporter struct {
    registry *prometheus.Registry
    server   *http.Server
}

func NewPullExporter(port int) *PullExporter {
    registry := prometheus.NewRegistry()
    
    mux := http.NewServeMux()
    mux.Handle("/metrics", promhttp.HandlerFor(
        registry,
        promhttp.HandlerOpts{},
    ))
    
    return &PullExporter{
        registry: registry,
        server: &http.Server{
            Addr:    fmt.Sprintf(":%d", port),
            Handler: mux,
        },
    }
}

func (pe *PullExporter) Start() error {
    return pe.server.ListenAndServe()
}

// 注册指标
func (pe *PullExporter) RegisterMetric(metric prometheus.Collector) {
    pe.registry.MustRegister(metric)
}

// 使用示例
func main() {
    exporter := NewPullExporter(9090)
    
    // 创建指标
    requestCounter := prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total HTTP requests",
        },
        []string{"method", "path", "status"},
    )
    
    // 注册指标
    exporter.RegisterMetric(requestCounter)
    
    // 启动服务
    exporter.Start()
}
```

### 混合模式

**自适应采集**：

```go
// 混合模式采集器
type HybridCollector struct {
    pushCollector *PushCollector
    pullExporter  *PullExporter
    mode          CollectionMode
    mu            sync.RWMutex
}

type CollectionMode int

const (
    ModePush CollectionMode = iota
    ModePull
    ModeAuto
)

func (hc *HybridCollector) SetMode(mode CollectionMode) {
    hc.mu.Lock()
    defer hc.mu.Unlock()
    hc.mode = mode
}

func (hc *HybridCollector) Collect(metric Metric) {
    hc.mu.RLock()
    mode := hc.mode
    hc.mu.RUnlock()
    
    switch mode {
    case ModePush:
        hc.pushCollector.buffer.Add(metric)
    case ModePull:
        // 更新Prometheus指标
        hc.pullExporter.UpdateMetric(metric)
    case ModeAuto:
        // 根据网络状况自动选择
        if hc.isNetworkHealthy() {
            hc.pushCollector.buffer.Add(metric)
        } else {
            hc.pullExporter.UpdateMetric(metric)
        }
    }
}

func (hc *HybridCollector) isNetworkHealthy() bool {
    // 检查网络延迟、丢包率等
    return true  // 简化实现
}
```

---

## 4.2.2 指标聚合算法

### 时间序列聚合

**时间对齐聚合**：

```go
// 时间序列聚合器
type TimeSeriesAggregator struct {
    resolution time.Duration  // 聚合粒度
    buffer     map[int64][]DataPoint
    mu         sync.RWMutex
}

type DataPoint struct {
    Timestamp time.Time
    Value     float64
    Labels    map[string]string
}

func (tsa *TimeSeriesAggregator) Add(dp DataPoint) {
    // 1. 对齐到时间桶
    bucket := dp.Timestamp.Unix() / int64(tsa.resolution.Seconds())
    
    // 2. 添加到对应桶
    tsa.mu.Lock()
    tsa.buffer[bucket] = append(tsa.buffer[bucket], dp)
    tsa.mu.Unlock()
}

func (tsa *TimeSeriesAggregator) Aggregate(
    aggFunc AggregateFunction,
) []DataPoint {
    tsa.mu.RLock()
    defer tsa.mu.RUnlock()
    
    results := []DataPoint{}
    
    for bucket, points := range tsa.buffer {
        timestamp := time.Unix(bucket*int64(tsa.resolution.Seconds()), 0)
        
        // 按标签分组
        groups := tsa.groupByLabels(points)
        
        for labels, groupPoints := range groups {
            value := aggFunc(groupPoints)
            results = append(results, DataPoint{
                Timestamp: timestamp,
                Value:     value,
                Labels:    labels,
            })
        }
    }
    
    return results
}

// 聚合函数类型
type AggregateFunction func([]DataPoint) float64

// 常见聚合函数
func Sum(points []DataPoint) float64 {
    sum := 0.0
    for _, p := range points {
        sum += p.Value
    }
    return sum
}

func Avg(points []DataPoint) float64 {
    if len(points) == 0 {
        return 0
    }
    return Sum(points) / float64(len(points))
}

func Max(points []DataPoint) float64 {
    if len(points) == 0 {
        return 0
    }
    max := points[0].Value
    for _, p := range points[1:] {
        if p.Value > max {
            max = p.Value
        }
    }
    return max
}

func P95(points []DataPoint) float64 {
    if len(points) == 0 {
        return 0
    }
    
    // 排序
    values := make([]float64, len(points))
    for i, p := range points {
        values[i] = p.Value
    }
    sort.Float64s(values)
    
    // 计算P95
    index := int(float64(len(values)) * 0.95)
    return values[index]
}
```

### 多维聚合

**OLAP Cube聚合**：

```go
// 多维聚合器
type MultiDimensionalAggregator struct {
    dimensions []string
    cube       map[string]*AggregateValue
    mu         sync.RWMutex
}

type AggregateValue struct {
    Count int64
    Sum   float64
    Min   float64
    Max   float64
}

func (mda *MultiDimensionalAggregator) Add(
    dimensions map[string]string,
    value float64,
) {
    // 生成所有可能的维度组合
    combinations := mda.generateCombinations(dimensions)
    
    mda.mu.Lock()
    defer mda.mu.Unlock()
    
    for _, key := range combinations {
        if _, exists := mda.cube[key]; !exists {
            mda.cube[key] = &AggregateValue{
                Min: value,
                Max: value,
            }
        }
        
        agg := mda.cube[key]
        agg.Count++
        agg.Sum += value
        if value < agg.Min {
            agg.Min = value
        }
        if value > agg.Max {
            agg.Max = value
        }
    }
}

func (mda *MultiDimensionalAggregator) generateCombinations(
    dimensions map[string]string,
) []string {
    // 生成所有维度组合的键
    // 例如: {service: "api", region: "us"} ->
    // ["service=api", "region=us", "service=api,region=us", "*"]
    
    keys := []string{}
    
    // 单维度
    for dim, val := range dimensions {
        keys = append(keys, fmt.Sprintf("%s=%s", dim, val))
    }
    
    // 多维度组合
    if len(dimensions) > 1 {
        parts := []string{}
        for dim, val := range dimensions {
            parts = append(parts, fmt.Sprintf("%s=%s", dim, val))
        }
        sort.Strings(parts)
        keys = append(keys, strings.Join(parts, ","))
    }
    
    // 全局聚合
    keys = append(keys, "*")
    
    return keys
}

func (mda *MultiDimensionalAggregator) Query(
    dimensions map[string]string,
) *AggregateValue {
    key := mda.buildKey(dimensions)
    
    mda.mu.RLock()
    defer mda.mu.RUnlock()
    
    return mda.cube[key]
}
```

### 近似聚合

**Count-Min Sketch**：

```go
// Count-Min Sketch用于频率估计
type CountMinSketch struct {
    width  int
    depth  int
    table  [][]uint64
    hashes []hash.Hash64
}

func NewCountMinSketch(width, depth int) *CountMinSketch {
    cms := &CountMinSketch{
        width: width,
        depth: depth,
        table: make([][]uint64, depth),
    }
    
    for i := 0; i < depth; i++ {
        cms.table[i] = make([]uint64, width)
        cms.hashes = append(cms.hashes, fnv.New64a())
    }
    
    return cms
}

func (cms *CountMinSketch) Add(item string, count uint64) {
    for i := 0; i < cms.depth; i++ {
        cms.hashes[i].Reset()
        cms.hashes[i].Write([]byte(item))
        hash := cms.hashes[i].Sum64()
        
        j := int(hash % uint64(cms.width))
        cms.table[i][j] += count
    }
}

func (cms *CountMinSketch) Estimate(item string) uint64 {
    minCount := uint64(math.MaxUint64)
    
    for i := 0; i < cms.depth; i++ {
        cms.hashes[i].Reset()
        cms.hashes[i].Write([]byte(item))
        hash := cms.hashes[i].Sum64()
        
        j := int(hash % uint64(cms.width))
        count := cms.table[i][j]
        
        if count < minCount {
            minCount = count
        }
    }
    
    return minCount
}
```

---

## 4.2.3 指标存储优化

### 降采样

**自适应降采样**：

```go
// 降采样器
type Downsampler struct {
    rules []DownsampleRule
}

type DownsampleRule struct {
    Age        time.Duration
    Resolution time.Duration
    Aggregator AggregateFunction
}

func (ds *Downsampler) Downsample(
    points []DataPoint,
    age time.Duration,
) []DataPoint {
    // 找到适用的规则
    var rule *DownsampleRule
    for i := range ds.rules {
        if age >= ds.rules[i].Age {
            rule = &ds.rules[i]
            break
        }
    }
    
    if rule == nil {
        return points  // 不降采样
    }
    
    // 按时间桶分组
    buckets := make(map[int64][]DataPoint)
    for _, p := range points {
        bucket := p.Timestamp.Unix() / int64(rule.Resolution.Seconds())
        buckets[bucket] = append(buckets[bucket], p)
    }
    
    // 聚合每个桶
    result := []DataPoint{}
    for bucket, bucketPoints := range buckets {
        timestamp := time.Unix(bucket*int64(rule.Resolution.Seconds()), 0)
        value := rule.Aggregator(bucketPoints)
        
        result = append(result, DataPoint{
            Timestamp: timestamp,
            Value:     value,
            Labels:    bucketPoints[0].Labels,
        })
    }
    
    return result
}

// 使用示例
func main() {
    ds := &Downsampler{
        rules: []DownsampleRule{
            {Age: 30 * 24 * time.Hour, Resolution: 1 * time.Hour, Aggregator: Avg},
            {Age: 7 * 24 * time.Hour, Resolution: 5 * time.Minute, Aggregator: Avg},
            {Age: 24 * time.Hour, Resolution: 1 * time.Minute, Aggregator: Avg},
        },
    }
}
```

### 压缩算法

**Gorilla压缩**：

```go
// Gorilla时间序列压缩
type GorillaCompressor struct {
    prevTimestamp int64
    prevValue     uint64
    prevDelta     int64
    buffer        *bytes.Buffer
    bitWriter     *BitWriter
}

func (gc *GorillaCompressor) Compress(timestamp int64, value float64) {
    // 1. 压缩时间戳
    gc.compressTimestamp(timestamp)
    
    // 2. 压缩值（XOR编码）
    gc.compressValue(math.Float64bits(value))
}

func (gc *GorillaCompressor) compressTimestamp(timestamp int64) {
    if gc.prevTimestamp == 0 {
        // 第一个时间戳，完整存储
        gc.bitWriter.WriteBits(uint64(timestamp), 64)
        gc.prevTimestamp = timestamp
        return
    }
    
    delta := timestamp - gc.prevTimestamp
    deltaOfDelta := delta - gc.prevDelta
    
    if deltaOfDelta == 0 {
        // Delta相同，写入0
        gc.bitWriter.WriteBits(0, 1)
    } else if deltaOfDelta >= -63 && deltaOfDelta <= 64 {
        // 小delta，7位
        gc.bitWriter.WriteBits(2, 2)  // 标记
        gc.bitWriter.WriteBits(uint64(deltaOfDelta), 7)
    } else if deltaOfDelta >= -255 && deltaOfDelta <= 256 {
        // 中delta，9位
        gc.bitWriter.WriteBits(6, 3)  // 标记
        gc.bitWriter.WriteBits(uint64(deltaOfDelta), 9)
    } else {
        // 大delta，12位
        gc.bitWriter.WriteBits(14, 4)  // 标记
        gc.bitWriter.WriteBits(uint64(deltaOfDelta), 12)
    }
    
    gc.prevTimestamp = timestamp
    gc.prevDelta = delta
}

func (gc *GorillaCompressor) compressValue(value uint64) {
    if gc.prevValue == 0 {
        // 第一个值，完整存储
        gc.bitWriter.WriteBits(value, 64)
        gc.prevValue = value
        return
    }
    
    xor := value ^ gc.prevValue
    
    if xor == 0 {
        // 值相同，写入0
        gc.bitWriter.WriteBits(0, 1)
    } else {
        gc.bitWriter.WriteBits(1, 1)
        
        leadingZeros := bits.LeadingZeros64(xor)
        trailingZeros := bits.TrailingZeros64(xor)
        
        if leadingZeros >= 32 {
            // 前导零很多，使用控制位
            gc.bitWriter.WriteBits(1, 1)
            gc.bitWriter.WriteBits(uint64(leadingZeros), 5)
            
            significantBits := 64 - leadingZeros - trailingZeros
            gc.bitWriter.WriteBits(uint64(significantBits), 6)
            gc.bitWriter.WriteBits(xor>>uint(trailingZeros), significantBits)
        } else {
            // 直接存储
            gc.bitWriter.WriteBits(0, 1)
            gc.bitWriter.WriteBits(xor, 64)
        }
    }
    
    gc.prevValue = value
}
```

### 分层存储

**热温冷存储策略**：

```go
// 分层存储管理器
type TieredStorageManager struct {
    hotStorage  Storage  // 内存/SSD
    warmStorage Storage  // SSD
    coldStorage Storage  // HDD/对象存储
}

type StoragePolicy struct {
    HotDuration  time.Duration  // 热数据保留时间
    WarmDuration time.Duration  // 温数据保留时间
}

func (tsm *TieredStorageManager) Store(metric Metric) error {
    // 新数据写入热存储
    return tsm.hotStorage.Write(metric)
}

func (tsm *TieredStorageManager) Migrate(policy StoragePolicy) error {
    now := time.Now()
    
    // 1. 热 -> 温
    hotData := tsm.hotStorage.QueryOlderThan(now.Add(-policy.HotDuration))
    for _, data := range hotData {
        // 降采样
        downsampled := downsample(data, 5*time.Minute)
        
        // 写入温存储
        tsm.warmStorage.Write(downsampled)
        
        // 删除热存储
        tsm.hotStorage.Delete(data.ID)
    }
    
    // 2. 温 -> 冷
    warmData := tsm.warmStorage.QueryOlderThan(now.Add(-policy.WarmDuration))
    for _, data := range warmData {
        // 进一步降采样
        downsampled := downsample(data, 1*time.Hour)
        
        // 压缩
        compressed := compress(downsampled)
        
        // 写入冷存储
        tsm.coldStorage.Write(compressed)
        
        // 删除温存储
        tsm.warmStorage.Delete(data.ID)
    }
    
    return nil
}
```

---

## 4.2.4 查询优化

### 索引策略

**倒排索引**：

```go
// 倒排索引
type InvertedIndex struct {
    index map[string]map[string][]string  // label -> value -> seriesIDs
    mu    sync.RWMutex
}

func (ii *InvertedIndex) Index(seriesID string, labels map[string]string) {
    ii.mu.Lock()
    defer ii.mu.Unlock()
    
    for label, value := range labels {
        if _, exists := ii.index[label]; !exists {
            ii.index[label] = make(map[string][]string)
        }
        
        ii.index[label][value] = append(ii.index[label][value], seriesID)
    }
}

func (ii *InvertedIndex) Query(selector map[string]string) []string {
    ii.mu.RLock()
    defer ii.mu.RUnlock()
    
    var result []string
    first := true
    
    for label, value := range selector {
        seriesIDs := ii.index[label][value]
        
        if first {
            result = seriesIDs
            first = false
        } else {
            // 交集
            result = intersect(result, seriesIDs)
        }
    }
    
    return result
}

func intersect(a, b []string) []string {
    set := make(map[string]bool)
    for _, item := range a {
        set[item] = true
    }
    
    result := []string{}
    for _, item := range b {
        if set[item] {
            result = append(result, item)
        }
    }
    
    return result
}
```

### 查询缓存

**LRU缓存**：

```go
// 查询缓存
type QueryCache struct {
    cache *lru.Cache
    ttl   time.Duration
}

type CachedResult struct {
    Data      []DataPoint
    Timestamp time.Time
}

func (qc *QueryCache) Get(query string) ([]DataPoint, bool) {
    if val, ok := qc.cache.Get(query); ok {
        cached := val.(CachedResult)
        
        // 检查是否过期
        if time.Since(cached.Timestamp) < qc.ttl {
            return cached.Data, true
        }
        
        // 过期，删除
        qc.cache.Remove(query)
    }
    
    return nil, false
}

func (qc *QueryCache) Set(query string, data []DataPoint) {
    qc.cache.Add(query, CachedResult{
        Data:      data,
        Timestamp: time.Now(),
    })
}
```

---

## 总结

指标采集与聚合核心技术：

**采集策略**：

- Push：主动推送
- Pull：被动拉取
- 混合：自适应选择

**聚合算法**：

- 时间序列：对齐聚合
- 多维度：OLAP Cube
- 近似：Count-Min Sketch

**存储优化**：

- 降采样：自适应规则
- 压缩：Gorilla算法
- 分层：热温冷存储

**查询优化**：

- 倒排索引：快速查找
- LRU缓存：减少计算
- 预聚合：加速查询

**最佳实践**：

- 合理选择采集模式
- 使用近似算法
- 分层存储策略
- 查询结果缓存

---

**上一篇**: [11_实时监控架构.md](11_实时监控架构.md)  
**下一篇**: [13_告警与通知机制.md](13_告警与通知机制.md)

---

*最后更新: 2025年10月7日*-
