# 告警与通知机制

**文档版本**: 1.0.0  
**创建日期**: 2025年10月7日  
**所属**: 第四部分 - 监测与实时观测  

---

## 目录

- [告警与通知机制](#告警与通知机制)
  - [目录](#目录)
  - [概述](#概述)
  - [4.3.1 告警规则引擎](#431-告警规则引擎)
    - [规则定义](#规则定义)
    - [规则评估](#规则评估)
    - [动态规则](#动态规则)
  - [4.3.2 告警聚合与抑制](#432-告警聚合与抑制)
    - [告警聚合](#告警聚合)
    - [告警抑制](#告警抑制)
    - [告警静默](#告警静默)
  - [4.3.3 通知路由](#433-通知路由)
    - [路由策略](#路由策略)
    - [通知渠道](#通知渠道)
  - [4.3.4 告警升级](#434-告警升级)
    - [升级策略](#升级策略)
    - [值班管理](#值班管理)
  - [总结](#总结)

---

## 概述

本文档介绍OTLP的告警规则引擎、告警聚合抑制、通知路由和告警升级机制。

---

## 4.3.1 告警规则引擎

### 规则定义

**告警规则结构**：

```go
// 告警规则
type AlertRule struct {
    ID          string
    Name        string
    Description string
    Query       string           // PromQL或类似查询语言
    Duration    time.Duration    // 持续时间
    Severity    Severity
    Labels      map[string]string
    Annotations map[string]string
}

type Severity int

const (
    SeverityInfo Severity = iota
    SeverityWarning
    SeverityError
    SeverityCritical
)

// YAML配置示例
const ruleExample = `
rules:
  - name: HighErrorRate
    query: |
      rate(http_requests_total{status=~"5.."}[5m]) 
      / 
      rate(http_requests_total[5m]) > 0.05
    duration: 5m
    severity: critical
    labels:
      team: backend
      service: api
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value | humanizePercentage }}"
`
```

### 规则评估

**评估引擎**：

```go
// 规则评估引擎
type RuleEvaluator struct {
    rules       []*AlertRule
    queryEngine *QueryEngine
    alertState  map[string]*AlertState
    mu          sync.RWMutex
}

type AlertState struct {
    Rule       *AlertRule
    Active     bool
    FiredAt    time.Time
    ResolvedAt time.Time
    Value      float64
    Labels     map[string]string
}

func (re *RuleEvaluator) Evaluate() {
    for _, rule := range re.rules {
        re.evaluateRule(rule)
    }
}

func (re *RuleEvaluator) evaluateRule(rule *AlertRule) {
    // 1. 执行查询
    result, err := re.queryEngine.Query(rule.Query)
    if err != nil {
        log.Printf("Query failed for rule %s: %v", rule.Name, err)
        return
    }
    
    // 2. 检查阈值
    for _, series := range result {
        stateKey := re.getStateKey(rule, series.Labels)
        
        re.mu.Lock()
        state, exists := re.alertState[stateKey]
        if !exists {
            state = &AlertState{
                Rule:   rule,
                Labels: series.Labels,
            }
            re.alertState[stateKey] = state
        }
        re.mu.Unlock()
        
        // 3. 更新状态
        if series.Value > 0 {  // 阈值触发
            if !state.Active {
                // 首次触发
                state.FiredAt = time.Now()
            }
            
            // 检查持续时间
            if time.Since(state.FiredAt) >= rule.Duration {
                if !state.Active {
                    // 激活告警
                    state.Active = true
                    state.Value = series.Value
                    re.fireAlert(state)
                }
            }
        } else {
            // 恢复
            if state.Active {
                state.Active = false
                state.ResolvedAt = time.Now()
                re.resolveAlert(state)
            }
        }
    }
}

func (re *RuleEvaluator) fireAlert(state *AlertState) {
    alert := &Alert{
        Labels:      state.Labels,
        Annotations: state.Rule.Annotations,
        StartsAt:    state.FiredAt,
        Value:       state.Value,
    }
    
    // 发送到告警管理器
    alertManager.Send(alert)
}
```

### 动态规则

**自适应阈值**：

```go
// 自适应阈值规则
type AdaptiveThresholdRule struct {
    BaseRule    *AlertRule
    Baseline    *BaselineCalculator
    Sensitivity float64  // 敏感度（标准差倍数）
}

type BaselineCalculator struct {
    window  time.Duration
    history *TimeSeriesBuffer
}

func (atr *AdaptiveThresholdRule) Evaluate(value float64) bool {
    // 1. 计算基线
    baseline := atr.Baseline.Calculate()
    
    // 2. 计算标准差
    stddev := atr.Baseline.StdDev()
    
    // 3. 动态阈值 = 基线 + (敏感度 × 标准差)
    threshold := baseline + (atr.Sensitivity * stddev)
    
    // 4. 判断
    return value > threshold
}

func (bc *BaselineCalculator) Calculate() float64 {
    // 使用指数加权移动平均（EWMA）
    alpha := 0.2
    ewma := 0.0
    
    points := bc.history.GetAll()
    for _, p := range points {
        ewma = alpha*p.Value + (1-alpha)*ewma
    }
    
    return ewma
}

// 使用示例
func main() {
    rule := &AdaptiveThresholdRule{
        BaseRule: &AlertRule{
            Name:     "AdaptiveLatency",
            Severity: SeverityWarning,
        },
        Baseline: &BaselineCalculator{
            window:  24 * time.Hour,
            history: NewTimeSeriesBuffer(24 * time.Hour),
        },
        Sensitivity: 3.0,  // 3个标准差
    }
}
```

---

## 4.3.2 告警聚合与抑制

### 告警聚合

**按标签聚合**：

```go
// 告警聚合器
type AlertAggregator struct {
    groupBy      []string          // 聚合维度
    groupWait    time.Duration     // 等待时间
    groupInterval time.Duration    // 聚合间隔
    groups       map[string]*AlertGroup
    mu           sync.RWMutex
}

type AlertGroup struct {
    Key       string
    Alerts    []*Alert
    CreatedAt time.Time
    SentAt    time.Time
}

func (aa *AlertAggregator) Add(alert *Alert) {
    // 1. 计算分组键
    groupKey := aa.getGroupKey(alert)
    
    // 2. 添加到分组
    aa.mu.Lock()
    group, exists := aa.groups[groupKey]
    if !exists {
        group = &AlertGroup{
            Key:       groupKey,
            CreatedAt: time.Now(),
        }
        aa.groups[groupKey] = group
    }
    group.Alerts = append(group.Alerts, alert)
    aa.mu.Unlock()
}

func (aa *AlertAggregator) Flush() {
    aa.mu.Lock()
    defer aa.mu.Unlock()
    
    now := time.Now()
    
    for key, group := range aa.groups {
        // 首次发送：等待groupWait
        if group.SentAt.IsZero() {
            if now.Sub(group.CreatedAt) >= aa.groupWait {
                aa.sendGroup(group)
                group.SentAt = now
            }
        } else {
            // 后续发送：按groupInterval
            if now.Sub(group.SentAt) >= aa.groupInterval {
                aa.sendGroup(group)
                group.SentAt = now
                
                // 清空已发送的告警
                group.Alerts = nil
            }
        }
    }
}

func (aa *AlertAggregator) getGroupKey(alert *Alert) string {
    parts := []string{}
    for _, label := range aa.groupBy {
        if val, ok := alert.Labels[label]; ok {
            parts = append(parts, fmt.Sprintf("%s=%s", label, val))
        }
    }
    sort.Strings(parts)
    return strings.Join(parts, ",")
}
```

### 告警抑制

**抑制规则**：

```go
// 告警抑制器
type AlertInhibitor struct {
    rules []*InhibitRule
}

type InhibitRule struct {
    SourceMatch map[string]string  // 源告警匹配
    TargetMatch map[string]string  // 目标告警匹配
    Equal       []string           // 相等标签
}

func (ai *AlertInhibitor) ShouldInhibit(
    source *Alert,
    target *Alert,
) bool {
    for _, rule := range ai.rules {
        // 1. 检查源匹配
        if !ai.matches(source, rule.SourceMatch) {
            continue
        }
        
        // 2. 检查目标匹配
        if !ai.matches(target, rule.TargetMatch) {
            continue
        }
        
        // 3. 检查相等标签
        if !ai.labelsEqual(source, target, rule.Equal) {
            continue
        }
        
        // 满足抑制条件
        return true
    }
    
    return false
}

func (ai *AlertInhibitor) matches(
    alert *Alert,
    matchers map[string]string,
) bool {
    for label, value := range matchers {
        if alert.Labels[label] != value {
            return false
        }
    }
    return true
}

func (ai *AlertInhibitor) labelsEqual(
    source *Alert,
    target *Alert,
    labels []string,
) bool {
    for _, label := range labels {
        if source.Labels[label] != target.Labels[label] {
            return false
        }
    }
    return true
}

// 配置示例
const inhibitExample = `
inhibit_rules:
  - source_match:
      severity: critical
    target_match:
      severity: warning
    equal: [service, instance]
  
  # 节点宕机时，抑制该节点上的所有告警
  - source_match:
      alertname: NodeDown
    target_match_re:
      alertname: .*
    equal: [instance]
`
```

### 告警静默

**静默管理**：

```go
// 告警静默器
type AlertSilencer struct {
    silences map[string]*Silence
    mu       sync.RWMutex
}

type Silence struct {
    ID        string
    Matchers  map[string]string
    StartsAt  time.Time
    EndsAt    time.Time
    CreatedBy string
    Comment   string
}

func (as *AlertSilencer) Add(silence *Silence) {
    as.mu.Lock()
    defer as.mu.Unlock()
    
    as.silences[silence.ID] = silence
}

func (as *AlertSilencer) IsSilenced(alert *Alert) bool {
    as.mu.RLock()
    defer as.mu.RUnlock()
    
    now := time.Now()
    
    for _, silence := range as.silences {
        // 检查时间范围
        if now.Before(silence.StartsAt) || now.After(silence.EndsAt) {
            continue
        }
        
        // 检查匹配
        if as.matches(alert, silence.Matchers) {
            return true
        }
    }
    
    return false
}

func (as *AlertSilencer) matches(
    alert *Alert,
    matchers map[string]string,
) bool {
    for label, pattern := range matchers {
        value, ok := alert.Labels[label]
        if !ok {
            return false
        }
        
        // 支持正则表达式
        matched, _ := regexp.MatchString(pattern, value)
        if !matched {
            return false
        }
    }
    
    return true
}
```

---

## 4.3.3 通知路由

### 路由策略

**路由树**：

```go
// 通知路由器
type NotificationRouter struct {
    root *RouteNode
}

type RouteNode struct {
    Matchers map[string]string
    Receiver string
    Continue bool  // 是否继续匹配子路由
    Children []*RouteNode
}

func (nr *NotificationRouter) Route(alert *Alert) []string {
    receivers := []string{}
    nr.routeRecursive(alert, nr.root, &receivers)
    return receivers
}

func (nr *NotificationRouter) routeRecursive(
    alert *Alert,
    node *RouteNode,
    receivers *[]string,
) {
    // 1. 检查当前节点匹配
    if nr.matches(alert, node.Matchers) {
        if node.Receiver != "" {
            *receivers = append(*receivers, node.Receiver)
        }
        
        // 2. 如果不继续，则停止
        if !node.Continue {
            return
        }
    }
    
    // 3. 递归检查子节点
    for _, child := range node.Children {
        nr.routeRecursive(alert, child, receivers)
    }
}

// 配置示例
const routeExample = `
route:
  receiver: default
  group_by: [alertname, cluster]
  routes:
    - match:
        severity: critical
      receiver: pagerduty
      continue: true
    
    - match:
        team: backend
      receiver: backend-team
      routes:
        - match:
            service: database
          receiver: dba-team
    
    - match:
        team: frontend
      receiver: frontend-team
`
```

### 通知渠道

**多渠道通知**：

```go
// 通知发送器
type Notifier interface {
    Send(alert *Alert) error
}

// Email通知
type EmailNotifier struct {
    smtp     *smtp.Client
    from     string
    template *template.Template
}

func (en *EmailNotifier) Send(alert *Alert) error {
    // 渲染邮件内容
    var body bytes.Buffer
    err := en.template.Execute(&body, alert)
    if err != nil {
        return err
    }
    
    // 发送邮件
    msg := fmt.Sprintf("From: %s\r\nTo: %s\r\nSubject: %s\r\n\r\n%s",
        en.from,
        alert.Labels["email"],
        alert.Annotations["summary"],
        body.String(),
    )
    
    return en.smtp.Data([]byte(msg))
}

// Slack通知
type SlackNotifier struct {
    webhookURL string
    client     *http.Client
}

func (sn *SlackNotifier) Send(alert *Alert) error {
    payload := map[string]interface{}{
        "text": alert.Annotations["summary"],
        "attachments": []map[string]interface{}{
            {
                "color": sn.getColor(alert.Labels["severity"]),
                "fields": []map[string]interface{}{
                    {
                        "title": "Service",
                        "value": alert.Labels["service"],
                        "short": true,
                    },
                    {
                        "title": "Severity",
                        "value": alert.Labels["severity"],
                        "short": true,
                    },
                },
            },
        },
    }
    
    data, _ := json.Marshal(payload)
    resp, err := sn.client.Post(sn.webhookURL, "application/json", bytes.NewReader(data))
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    return nil
}

// PagerDuty通知
type PagerDutyNotifier struct {
    apiKey string
    client *http.Client
}

func (pdn *PagerDutyNotifier) Send(alert *Alert) error {
    event := map[string]interface{}{
        "routing_key":  pdn.apiKey,
        "event_action": "trigger",
        "payload": map[string]interface{}{
            "summary":  alert.Annotations["summary"],
            "severity": alert.Labels["severity"],
            "source":   alert.Labels["instance"],
        },
    }
    
    data, _ := json.Marshal(event)
    resp, err := pdn.client.Post(
        "https://events.pagerduty.com/v2/enqueue",
        "application/json",
        bytes.NewReader(data),
    )
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    return nil
}
```

---

## 4.3.4 告警升级

### 升级策略

**自动升级**：

```go
// 告警升级管理器
type EscalationManager struct {
    policies map[string]*EscalationPolicy
}

type EscalationPolicy struct {
    Levels []EscalationLevel
}

type EscalationLevel struct {
    Delay     time.Duration
    Receivers []string
}

func (em *EscalationManager) Escalate(alert *Alert) {
    policyName := alert.Labels["escalation_policy"]
    policy, exists := em.policies[policyName]
    if !exists {
        return
    }
    
    for i, level := range policy.Levels {
        // 等待延迟时间
        time.Sleep(level.Delay)
        
        // 检查告警是否已解决
        if alert.IsResolved() {
            return
        }
        
        // 通知当前级别的接收者
        for _, receiver := range level.Receivers {
            em.notify(receiver, alert, i+1)
        }
    }
}

// 配置示例
const escalationExample = `
escalation_policies:
  critical:
    - delay: 5m
      receivers: [oncall-engineer]
    - delay: 15m
      receivers: [team-lead]
    - delay: 30m
      receivers: [manager, director]
`
```

### 值班管理

**值班轮换**：

```go
// 值班管理器
type OnCallManager struct {
    schedules map[string]*OnCallSchedule
}

type OnCallSchedule struct {
    Team     string
    Rotation []OnCallShift
}

type OnCallShift struct {
    Engineer  string
    StartTime time.Time
    EndTime   time.Time
}

func (ocm *OnCallManager) GetOnCall(team string, t time.Time) string {
    schedule, exists := ocm.schedules[team]
    if !exists {
        return ""
    }
    
    for _, shift := range schedule.Rotation {
        if t.After(shift.StartTime) && t.Before(shift.EndTime) {
            return shift.Engineer
        }
    }
    
    return ""
}

// 自动轮换
func (ocm *OnCallManager) RotateSchedule(team string, duration time.Duration) {
    schedule := ocm.schedules[team]
    engineers := []string{"alice", "bob", "charlie"}
    
    now := time.Now()
    for i, engineer := range engineers {
        shift := OnCallShift{
            Engineer:  engineer,
            StartTime: now.Add(duration * time.Duration(i)),
            EndTime:   now.Add(duration * time.Duration(i+1)),
        }
        schedule.Rotation = append(schedule.Rotation, shift)
    }
}
```

---

## 总结

告警与通知机制核心要素：

**规则引擎**：

- 规则定义：YAML配置
- 规则评估：周期性执行
- 动态规则：自适应阈值

**聚合抑制**：

- 告警聚合：按标签分组
- 告警抑制：避免冗余
- 告警静默：维护窗口

**通知路由**：

- 路由树：灵活匹配
- 多渠道：Email/Slack/PagerDuty
- 模板化：自定义内容

**告警升级**：

- 升级策略：分级通知
- 值班管理：自动轮换
- 自动化：减少人工

**最佳实践**：

- 合理设置阈值
- 避免告警疲劳
- 分级响应机制
- 定期回顾优化

---

**上一篇**: [12_指标采集与聚合.md](12_指标采集与聚合.md)  
**下一篇**: [14_动态采样控制.md](14_动态采样控制.md)

---

*最后更新: 2025年10月7日*-
