# 根因分析算法

**文档版本**: 1.0.0  
**创建日期**: 2025年10月7日  
**所属**: 第七部分 - 系统状态推理与诊断  

---

## 目录

- [根因分析算法](#根因分析算法)
  - [目录](#目录)
  - [概述](#概述)
  - [7.2.1 因果图分析](#721-因果图分析)
    - [因果图构建](#因果图构建)
    - [路径追踪](#路径追踪)
  - [7.2.2 关联规则挖掘](#722-关联规则挖掘)
    - [频繁模式挖掘](#频繁模式挖掘)
    - [异常关联](#异常关联)
  - [7.2.3 时序因果分析](#723-时序因果分析)
    - [时间窗口关联](#时间窗口关联)
    - [传播路径分析](#传播路径分析)
  - [7.2.4 机器学习根因定位](#724-机器学习根因定位)
    - [随机森林](#随机森林)
    - [梯度提升树](#梯度提升树)
    - [特征重要性](#特征重要性)
  - [总结](#总结)

---

## 概述

本文档介绍OTLP的根因分析算法，包括因果图、关联规则、时序分析和机器学习方法。

---

## 7.2.1 因果图分析

### 因果图构建

**服务依赖图**：

```go
// 因果图分析器
type CausalGraphAnalyzer struct {
    graph          *ServiceGraph
    anomalyScores  map[string]float64
    propagationLog []PropagationEvent
}

type ServiceGraph struct {
    Nodes map[string]*ServiceNode
    Edges map[string][]Edge
}

type ServiceNode struct {
    Name        string
    Type        string // service, database, cache, etc.
    Metrics     map[string]float64
    IsAnomalous bool
}

type Edge struct {
    From   string
    To     string
    Weight float64 // 调用频率或依赖强度
}

type PropagationEvent struct {
    Timestamp time.Time
    Source    string
    Target    string
    Delay     time.Duration
}

// 构建服务依赖图
func BuildServiceGraph(traces []*Trace) *ServiceGraph {
    graph := &ServiceGraph{
        Nodes: make(map[string]*ServiceNode),
        Edges: make(map[string][]Edge),
    }
    
    // 从Trace提取服务依赖
    for _, trace := range traces {
        for _, span := range trace.Spans {
            serviceName := span.ServiceName
            
            // 添加节点
            if _, exists := graph.Nodes[serviceName]; !exists {
                graph.Nodes[serviceName] = &ServiceNode{
                    Name:    serviceName,
                    Type:    span.ServiceType,
                    Metrics: make(map[string]float64),
                }
            }
            
            // 添加边（父子关系）
            if span.ParentSpanID != "" {
                parentSpan := trace.FindSpan(span.ParentSpanID)
                if parentSpan != nil {
                    edge := Edge{
                        From:   parentSpan.ServiceName,
                        To:     serviceName,
                        Weight: 1.0,
                    }
                    graph.Edges[parentSpan.ServiceName] = append(
                        graph.Edges[parentSpan.ServiceName],
                        edge,
                    )
                }
            }
        }
    }
    
    return graph
}
```

### 路径追踪

**异常传播路径**：

```go
// 根因定位
func (cga *CausalGraphAnalyzer) LocateRootCause() []RootCause {
    // 1. 标记异常节点
    anomalousNodes := cga.detectAnomalousNodes()
    
    // 2. 计算异常传播路径
    propagationPaths := cga.tracePropagation(anomalousNodes)
    
    // 3. 根因评分
    rootCauses := cga.scoreRootCauses(propagationPaths)
    
    // 4. 排序返回
    sort.Slice(rootCauses, func(i, j int) bool {
        return rootCauses[i].Score > rootCauses[j].Score
    })
    
    return rootCauses
}

type RootCause struct {
    Service      string
    Score        float64
    Reason       string
    AffectedPath []string
    Evidence     []Evidence
}

type Evidence struct {
    Type        string
    Description string
    Confidence  float64
}

func (cga *CausalGraphAnalyzer) detectAnomalousNodes() []string {
    anomalous := []string{}
    
    for name, node := range cga.graph.Nodes {
        score := cga.calculateAnomalyScore(node)
        cga.anomalyScores[name] = score
        
        if score > 0.7 { // 阈值
            node.IsAnomalous = true
            anomalous = append(anomalous, name)
        }
    }
    
    return anomalous
}

func (cga *CausalGraphAnalyzer) calculateAnomalyScore(
    node *ServiceNode,
) float64 {
    score := 0.0
    count := 0
    
    // 综合多个指标
    metrics := []string{
        "error_rate",
        "latency_p99",
        "cpu_usage",
        "memory_usage",
    }
    
    for _, metric := range metrics {
        if value, exists := node.Metrics[metric]; exists {
            // 归一化并累加
            normalized := cga.normalizeMetric(metric, value)
            score += normalized
            count++
        }
    }
    
    if count == 0 {
        return 0
    }
    
    return score / float64(count)
}

// 追踪异常传播
func (cga *CausalGraphAnalyzer) tracePropagation(
    anomalousNodes []string,
) []PropagationPath {
    paths := []PropagationPath{}
    
    for _, node := range anomalousNodes {
        // 反向追踪（找上游）
        upstreamPaths := cga.traceUpstream(node, []string{}, 0)
        paths = append(paths, upstreamPaths...)
    }
    
    return paths
}

type PropagationPath struct {
    Path          []string
    TotalScore    float64
    PropagationDelay time.Duration
}

func (cga *CausalGraphAnalyzer) traceUpstream(
    current string,
    visited []string,
    depth int,
) []PropagationPath {
    // 防止循环
    for _, v := range visited {
        if v == current {
            return nil
        }
    }
    
    // 深度限制
    if depth > 10 {
        return nil
    }
    
    visited = append(visited, current)
    paths := []PropagationPath{}
    
    // 查找所有指向当前节点的边
    hasUpstream := false
    for source, edges := range cga.graph.Edges {
        for _, edge := range edges {
            if edge.To == current {
                hasUpstream = true
                
                // 递归追踪上游
                upstreamPaths := cga.traceUpstream(source, visited, depth+1)
                
                if len(upstreamPaths) == 0 {
                    // 这是根节点
                    paths = append(paths, PropagationPath{
                        Path:       append([]string{source}, current),
                        TotalScore: cga.anomalyScores[source],
                    })
                } else {
                    // 扩展路径
                    for _, path := range upstreamPaths {
                        extendedPath := append(path.Path, current)
                        paths = append(paths, PropagationPath{
                            Path:       extendedPath,
                            TotalScore: path.TotalScore + cga.anomalyScores[current],
                        })
                    }
                }
            }
        }
    }
    
    // 如果没有上游，当前节点可能是根因
    if !hasUpstream {
        paths = append(paths, PropagationPath{
            Path:       []string{current},
            TotalScore: cga.anomalyScores[current],
        })
    }
    
    return paths
}

// 根因评分
func (cga *CausalGraphAnalyzer) scoreRootCauses(
    paths []PropagationPath,
) []RootCause {
    // 统计每个服务作为根因的频率和分数
    candidateScores := make(map[string]*RootCauseCandidate)
    
    for _, path := range paths {
        if len(path.Path) == 0 {
            continue
        }
        
        root := path.Path[0]
        
        if _, exists := candidateScores[root]; !exists {
            candidateScores[root] = &RootCauseCandidate{
                Service:       root,
                Frequency:     0,
                TotalScore:    0,
                AffectedPaths: [][]string{},
            }
        }
        
        candidate := candidateScores[root]
        candidate.Frequency++
        candidate.TotalScore += path.TotalScore
        candidate.AffectedPaths = append(candidate.AffectedPaths, path.Path)
    }
    
    // 计算最终分数
    rootCauses := []RootCause{}
    
    for service, candidate := range candidateScores {
        score := candidate.TotalScore / float64(candidate.Frequency)
        
        // 考虑影响范围
        impactFactor := float64(len(candidate.AffectedPaths)) / float64(len(paths))
        finalScore := score * (1 + impactFactor)
        
        rootCauses = append(rootCauses, RootCause{
            Service: service,
            Score:   finalScore,
            Reason:  cga.generateReason(candidate),
            AffectedPath: cga.getMostImpactedPath(candidate.AffectedPaths),
            Evidence: cga.collectEvidence(service),
        })
    }
    
    return rootCauses
}

type RootCauseCandidate struct {
    Service       string
    Frequency     int
    TotalScore    float64
    AffectedPaths [][]string
}
```

---

## 7.2.2 关联规则挖掘

### 频繁模式挖掘

**故障模式识别**：

```go
// 故障模式挖掘器
type FailurePatternMiner struct {
    minSupport    float64
    minConfidence float64
    patterns      []FailurePattern
}

type FailurePattern struct {
    Symptoms  []string
    RootCause string
    Support   float64
    Confidence float64
}

type FailureEvent struct {
    Timestamp time.Time
    Service   string
    Symptoms  []string
    RootCause string
}

func (fpm *FailurePatternMiner) MinePatterns(
    events []FailureEvent,
) []FailurePattern {
    // 1. 构建事务数据库
    transactions := fpm.buildTransactions(events)
    
    // 2. 挖掘频繁症状集
    frequentSymptoms := fpm.findFrequentSymptoms(transactions)
    
    // 3. 生成关联规则
    patterns := fpm.generatePatterns(frequentSymptoms, transactions)
    
    return patterns
}

func (fpm *FailurePatternMiner) buildTransactions(
    events []FailureEvent,
) []Transaction {
    transactions := []Transaction{}
    
    for _, event := range events {
        trans := Transaction{
            Items:     event.Symptoms,
            RootCause: event.RootCause,
        }
        transactions = append(transactions, trans)
    }
    
    return transactions
}

type Transaction struct {
    Items     []string
    RootCause string
}

func (fpm *FailurePatternMiner) findFrequentSymptoms(
    transactions []Transaction,
) [][]string {
    n := len(transactions)
    frequent := [][]string{}
    
    // 使用FP-Growth算法
    fpGrowth := &FPGrowth{
        minSupport: int(fpm.minSupport * float64(n)),
    }
    
    // 转换为字符串切片
    data := [][]string{}
    for _, trans := range transactions {
        data = append(data, trans.Items)
    }
    
    itemSets := fpGrowth.Mine(data)
    
    // 转换回字符串切片
    for _, itemSet := range itemSets {
        items := []string{}
        for item := range itemSet {
            items = append(items, item)
        }
        frequent = append(frequent, items)
    }
    
    return frequent
}

func (fpm *FailurePatternMiner) generatePatterns(
    frequentSymptoms [][]string,
    transactions []Transaction,
) []FailurePattern {
    patterns := []FailurePattern{}
    
    for _, symptoms := range frequentSymptoms {
        // 统计该症状集合对应的根因
        rootCauseCounts := make(map[string]int)
        symptomCount := 0
        
        for _, trans := range transactions {
            if fpm.containsAll(trans.Items, symptoms) {
                symptomCount++
                rootCauseCounts[trans.RootCause]++
            }
        }
        
        // 计算支持度和置信度
        support := float64(symptomCount) / float64(len(transactions))
        
        for rootCause, count := range rootCauseCounts {
            confidence := float64(count) / float64(symptomCount)
            
            if confidence >= fpm.minConfidence {
                patterns = append(patterns, FailurePattern{
                    Symptoms:   symptoms,
                    RootCause:  rootCause,
                    Support:    support,
                    Confidence: confidence,
                })
            }
        }
    }
    
    return patterns
}
```

### 异常关联

**多维异常关联**：

```go
// 异常关联分析器
type AnomalyCorrelationAnalyzer struct {
    timeWindow time.Duration
}

func (aca *AnomalyCorrelationAnalyzer) FindCorrelations(
    anomalies []Anomaly,
) []AnomalyCorrelation {
    correlations := []AnomalyCorrelation{}
    
    // 按时间排序
    sort.Slice(anomalies, func(i, j int) bool {
        return anomalies[i].Timestamp.Before(anomalies[j].Timestamp)
    })
    
    // 查找时间窗口内的关联
    for i := 0; i < len(anomalies); i++ {
        for j := i + 1; j < len(anomalies); j++ {
            timeDiff := anomalies[j].Timestamp.Sub(anomalies[i].Timestamp)
            
            if timeDiff > aca.timeWindow {
                break
            }
            
            // 计算相关性
            correlation := aca.calculateCorrelation(
                anomalies[i],
                anomalies[j],
                timeDiff,
            )
            
            if correlation.Strength > 0.5 {
                correlations = append(correlations, correlation)
            }
        }
    }
    
    return correlations
}

type Anomaly struct {
    Timestamp time.Time
    Service   string
    Metric    string
    Value     float64
    Severity  float64
}

type AnomalyCorrelation struct {
    First     Anomaly
    Second    Anomaly
    Strength  float64
    Delay     time.Duration
    Type      string // "causal", "concurrent", "cascading"
}

func (aca *AnomalyCorrelationAnalyzer) calculateCorrelation(
    first, second Anomaly,
    timeDiff time.Duration,
) AnomalyCorrelation {
    correlation := AnomalyCorrelation{
        First:  first,
        Second: second,
        Delay:  timeDiff,
    }
    
    // 时间接近度
    timeProximity := 1.0 - (float64(timeDiff) / float64(aca.timeWindow))
    
    // 严重性相似度
    severitySimilarity := 1.0 - math.Abs(first.Severity-second.Severity)
    
    // 服务依赖关系
    dependencyScore := aca.getDependencyScore(first.Service, second.Service)
    
    // 综合评分
    correlation.Strength = (timeProximity + severitySimilarity + dependencyScore) / 3.0
    
    // 判断类型
    if timeDiff < time.Second {
        correlation.Type = "concurrent"
    } else if dependencyScore > 0.7 {
        correlation.Type = "causal"
    } else {
        correlation.Type = "cascading"
    }
    
    return correlation
}
```

---

## 7.2.3 时序因果分析

### 时间窗口关联

**滑动窗口分析**：

```go
// 时序因果分析器
type TemporalCausalAnalyzer struct {
    windowSize  time.Duration
    slideStep   time.Duration
    lagThreshold time.Duration
}

func (tca *TemporalCausalAnalyzer) AnalyzeCausality(
    metrics map[string][]TimeSeriesPoint,
) []CausalRelation {
    relations := []CausalRelation{}
    
    // 对每对指标进行分析
    services := []string{}
    for service := range metrics {
        services = append(services, service)
    }
    
    for i := 0; i < len(services); i++ {
        for j := 0; j < len(services); j++ {
            if i == j {
                continue
            }
            
            // 检查因果关系
            relation := tca.testCausality(
                services[i],
                services[j],
                metrics[services[i]],
                metrics[services[j]],
            )
            
            if relation.IsCausal {
                relations = append(relations, relation)
            }
        }
    }
    
    return relations
}

type TimeSeriesPoint struct {
    Timestamp time.Time
    Value     float64
}

type CausalRelation struct {
    Cause     string
    Effect    string
    IsCausal  bool
    Lag       time.Duration
    Strength  float64
    PValue    float64
}

func (tca *TemporalCausalAnalyzer) testCausality(
    causeService, effectService string,
    causeData, effectData []TimeSeriesPoint,
) CausalRelation {
    relation := CausalRelation{
        Cause:  causeService,
        Effect: effectService,
    }
    
    // 对齐时间序列
    aligned := tca.alignTimeSeries(causeData, effectData)
    
    // 尝试不同的滞后
    bestLag := time.Duration(0)
    maxCorrelation := 0.0
    
    for lag := time.Duration(0); lag <= tca.lagThreshold; lag += time.Second {
        correlation := tca.crossCorrelation(aligned, lag)
        
        if math.Abs(correlation) > math.Abs(maxCorrelation) {
            maxCorrelation = correlation
            bestLag = lag
        }
    }
    
    // Granger因果检验
    grangerTest := tca.grangerCausalityTest(aligned, bestLag)
    
    relation.IsCausal = grangerTest.PValue < 0.05 && maxCorrelation > 0.3
    relation.Lag = bestLag
    relation.Strength = maxCorrelation
    relation.PValue = grangerTest.PValue
    
    return relation
}

type AlignedTimeSeries struct {
    Timestamps []time.Time
    Cause      []float64
    Effect     []float64
}

func (tca *TemporalCausalAnalyzer) alignTimeSeries(
    causeData, effectData []TimeSeriesPoint,
) AlignedTimeSeries {
    aligned := AlignedTimeSeries{}
    
    // 找到公共时间范围
    causeMap := make(map[time.Time]float64)
    for _, point := range causeData {
        causeMap[point.Timestamp] = point.Value
    }
    
    effectMap := make(map[time.Time]float64)
    for _, point := range effectData {
        effectMap[point.Timestamp] = point.Value
    }
    
    // 对齐
    for _, point := range causeData {
        if effectValue, exists := effectMap[point.Timestamp]; exists {
            aligned.Timestamps = append(aligned.Timestamps, point.Timestamp)
            aligned.Cause = append(aligned.Cause, point.Value)
            aligned.Effect = append(aligned.Effect, effectValue)
        }
    }
    
    return aligned
}

func (tca *TemporalCausalAnalyzer) crossCorrelation(
    aligned AlignedTimeSeries,
    lag time.Duration,
) float64 {
    lagSteps := int(lag / time.Second)
    
    if lagSteps >= len(aligned.Cause) {
        return 0
    }
    
    // 计算互相关
    n := len(aligned.Cause) - lagSteps
    
    causeMean := tca.mean(aligned.Cause[:n])
    effectMean := tca.mean(aligned.Effect[lagSteps:])
    
    causeStd := tca.stddev(aligned.Cause[:n], causeMean)
    effectStd := tca.stddev(aligned.Effect[lagSteps:], effectMean)
    
    correlation := 0.0
    for i := 0; i < n; i++ {
        correlation += (aligned.Cause[i] - causeMean) *
            (aligned.Effect[i+lagSteps] - effectMean)
    }
    
    correlation /= (float64(n) * causeStd * effectStd)
    
    return correlation
}
```

### 传播路径分析

**故障传播追踪**：

```go
// 故障传播分析器
type FailurePropagationAnalyzer struct {
    graph          *ServiceGraph
    propagationMap map[string][]PropagationRecord
}

type PropagationRecord struct {
    FromService string
    ToService   string
    StartTime   time.Time
    EndTime     time.Time
    Delay       time.Duration
    Probability float64
}

func (fpa *FailurePropagationAnalyzer) TracePropagation(
    initialFailure Failure,
) *PropagationTree {
    root := &PropagationNode{
        Service:   initialFailure.Service,
        Timestamp: initialFailure.Timestamp,
        Severity:  initialFailure.Severity,
        Children:  []*PropagationNode{},
    }
    
    // BFS遍历传播路径
    queue := []*PropagationNode{root}
    visited := make(map[string]bool)
    visited[root.Service] = true
    
    for len(queue) > 0 {
        current := queue[0]
        queue = queue[1:]
        
        // 查找下游服务
        downstreams := fpa.findDownstreamFailures(
            current.Service,
            current.Timestamp,
        )
        
        for _, downstream := range downstreams {
            if visited[downstream.Service] {
                continue
            }
            
            node := &PropagationNode{
                Service:   downstream.Service,
                Timestamp: downstream.Timestamp,
                Severity:  downstream.Severity,
                Delay:     downstream.Timestamp.Sub(current.Timestamp),
                Children:  []*PropagationNode{},
            }
            
            current.Children = append(current.Children, node)
            queue = append(queue, node)
            visited[downstream.Service] = true
        }
    }
    
    return &PropagationTree{Root: root}
}

type Failure struct {
    Service   string
    Timestamp time.Time
    Severity  float64
    Type      string
}

type PropagationNode struct {
    Service   string
    Timestamp time.Time
    Severity  float64
    Delay     time.Duration
    Children  []*PropagationNode
}

type PropagationTree struct {
    Root *PropagationNode
}

func (fpa *FailurePropagationAnalyzer) findDownstreamFailures(
    service string,
    afterTime time.Time,
) []Failure {
    failures := []Failure{}
    
    // 查找依赖的下游服务
    if edges, exists := fpa.graph.Edges[service]; exists {
        for _, edge := range edges {
            downstream := edge.To
            
            // 检查传播记录
            if records, exists := fpa.propagationMap[service]; exists {
                for _, record := range records {
                    if record.ToService == downstream &&
                        record.StartTime.After(afterTime) {
                        failures = append(failures, Failure{
                            Service:   downstream,
                            Timestamp: record.EndTime,
                            Severity:  record.Probability,
                        })
                    }
                }
            }
        }
    }
    
    return failures
}
```

---

## 7.2.4 机器学习根因定位

### 随机森林

**特征重要性分析**：

```go
// 随机森林根因定位器
type RandomForestRCA struct {
    forest     []*DecisionTree
    numTrees   int
    maxDepth   int
    minSamples int
}

type DecisionTree struct {
    root *TreeNode
}

type TreeNode struct {
    Feature   int
    Threshold float64
    Left      *TreeNode
    Right     *TreeNode
    IsLeaf    bool
    Class     string
    Samples   int
}

func (rf *RandomForestRCA) Train(
    features [][]float64,
    labels []string,
) {
    rf.forest = make([]*DecisionTree, rf.numTrees)
    
    for i := 0; i < rf.numTrees; i++ {
        // Bootstrap采样
        bootFeatures, bootLabels := rf.bootstrap(features, labels)
        
        // 训练决策树
        tree := &DecisionTree{}
        tree.root = rf.buildTree(bootFeatures, bootLabels, 0)
        rf.forest[i] = tree
    }
}

func (rf *RandomForestRCA) bootstrap(
    features [][]float64,
    labels []string,
) ([][]float64, []string) {
    n := len(features)
    bootFeatures := make([][]float64, n)
    bootLabels := make([]string, n)
    
    for i := 0; i < n; i++ {
        idx := rand.Intn(n)
        bootFeatures[i] = features[idx]
        bootLabels[i] = labels[idx]
    }
    
    return bootFeatures, bootLabels
}

func (rf *RandomForestRCA) buildTree(
    features [][]float64,
    labels []string,
    depth int,
) *TreeNode {
    // 终止条件
    if depth >= rf.maxDepth || len(features) < rf.minSamples {
        return rf.createLeaf(labels)
    }
    
    // 检查纯度
    if rf.isPure(labels) {
        return rf.createLeaf(labels)
    }
    
    // 选择最佳分割
    bestFeature, bestThreshold, bestGain := rf.findBestSplit(features, labels)
    
    if bestGain <= 0 {
        return rf.createLeaf(labels)
    }
    
    // 分割数据
    leftFeatures, leftLabels, rightFeatures, rightLabels :=
        rf.splitData(features, labels, bestFeature, bestThreshold)
    
    // 递归构建子树
    return &TreeNode{
        Feature:   bestFeature,
        Threshold: bestThreshold,
        Left:      rf.buildTree(leftFeatures, leftLabels, depth+1),
        Right:     rf.buildTree(rightFeatures, rightLabels, depth+1),
        IsLeaf:    false,
        Samples:   len(features),
    }
}

func (rf *RandomForestRCA) Predict(features []float64) map[string]float64 {
    votes := make(map[string]int)
    
    // 每棵树投票
    for _, tree := range rf.forest {
        prediction := rf.predictTree(tree.root, features)
        votes[prediction]++
    }
    
    // 转换为概率
    probs := make(map[string]float64)
    total := float64(rf.numTrees)
    
    for class, count := range votes {
        probs[class] = float64(count) / total
    }
    
    return probs
}

func (rf *RandomForestRCA) predictTree(
    node *TreeNode,
    features []float64,
) string {
    if node.IsLeaf {
        return node.Class
    }
    
    if features[node.Feature] < node.Threshold {
        return rf.predictTree(node.Left, features)
    }
    return rf.predictTree(node.Right, features)
}
```

### 梯度提升树

**XGBoost根因定位**：

```go
// XGBoost根因定位器
type XGBoostRCA struct {
    trees        []*DecisionTree
    numRounds    int
    learningRate float64
    maxDepth     int
}

func (xgb *XGBoostRCA) Train(
    features [][]float64,
    labels []string,
) {
    // 初始化预测（所有类别概率相等）
    classes := xgb.getUniqueClasses(labels)
    numClasses := len(classes)
    
    predictions := make([][]float64, len(features))
    for i := range predictions {
        predictions[i] = make([]float64, numClasses)
        for j := range predictions[i] {
            predictions[i][j] = 1.0 / float64(numClasses)
        }
    }
    
    // 迭代训练
    for round := 0; round < xgb.numRounds; round++ {
        // 计算梯度和Hessian
        gradients, hessians := xgb.calculateGradients(
            predictions,
            labels,
            classes,
        )
        
        // 对每个类别训练一棵树
        for classIdx := range classes {
            tree := xgb.buildGradientTree(
                features,
                gradients[classIdx],
                hessians[classIdx],
                0,
            )
            xgb.trees = append(xgb.trees, tree)
            
            // 更新预测
            for i, feature := range features {
                leafValue := xgb.predictTree(tree.root, feature)
                predictions[i][classIdx] += xgb.learningRate * leafValue
            }
        }
    }
}

func (xgb *XGBoostRCA) calculateGradients(
    predictions [][]float64,
    labels []string,
    classes []string,
) ([][]float64, [][]float64) {
    n := len(predictions)
    numClasses := len(classes)
    
    gradients := make([][]float64, numClasses)
    hessians := make([][]float64, numClasses)
    
    for i := 0; i < numClasses; i++ {
        gradients[i] = make([]float64, n)
        hessians[i] = make([]float64, n)
    }
    
    // Softmax + Cross-Entropy
    for i := 0; i < n; i++ {
        // Softmax
        probs := xgb.softmax(predictions[i])
        
        // 真实标签
        trueClass := xgb.getClassIndex(labels[i], classes)
        
        // 梯度和Hessian
        for j := 0; j < numClasses; j++ {
            if j == trueClass {
                gradients[j][i] = probs[j] - 1.0
            } else {
                gradients[j][i] = probs[j]
            }
            hessians[j][i] = probs[j] * (1.0 - probs[j])
        }
    }
    
    return gradients, hessians
}

func (xgb *XGBoostRCA) softmax(logits []float64) []float64 {
    max := logits[0]
    for _, v := range logits {
        if v > max {
            max = v
        }
    }
    
    expSum := 0.0
    probs := make([]float64, len(logits))
    
    for i, v := range logits {
        probs[i] = math.Exp(v - max)
        expSum += probs[i]
    }
    
    for i := range probs {
        probs[i] /= expSum
    }
    
    return probs
}
```

### 特征重要性

**SHAP值分析**：

```go
// SHAP值计算器
type SHAPExplainer struct {
    model      *RandomForestRCA
    background [][]float64
}

func (se *SHAPExplainer) Explain(instance []float64) map[int]float64 {
    shapValues := make(map[int]float64)
    numFeatures := len(instance)
    
    // 对每个特征计算SHAP值
    for featureIdx := 0; featureIdx < numFeatures; featureIdx++ {
        shapValues[featureIdx] = se.calculateSHAP(instance, featureIdx)
    }
    
    return shapValues
}

func (se *SHAPExplainer) calculateSHAP(
    instance []float64,
    featureIdx int,
) float64 {
    // 简化实现：使用边际贡献
    numSamples := len(se.background)
    contributions := 0.0
    
    for _, bgSample := range se.background {
        // 有特征的预测
        withFeature := make([]float64, len(instance))
        copy(withFeature, instance)
        
        // 无特征的预测（用背景值替代）
        withoutFeature := make([]float64, len(instance))
        copy(withoutFeature, instance)
        withoutFeature[featureIdx] = bgSample[featureIdx]
        
        // 计算差异
        predWith := se.model.Predict(withFeature)
        predWithout := se.model.Predict(withoutFeature)
        
        // 取最大概率类别的差异
        maxWith := 0.0
        maxWithout := 0.0
        
        for _, prob := range predWith {
            if prob > maxWith {
                maxWith = prob
            }
        }
        
        for _, prob := range predWithout {
            if prob > maxWithout {
                maxWithout = prob
            }
        }
        
        contributions += (maxWith - maxWithout)
    }
    
    return contributions / float64(numSamples)
}
```

---

## 总结

根因分析算法核心技术：

**因果图分析**：

- 服务依赖图构建
- 异常传播路径追踪
- 根因评分与排序

**关联规则挖掘**：

- 频繁故障模式识别
- 多维异常关联
- 支持度/置信度评估

**时序因果分析**：

- 滑动窗口关联
- Granger因果检验
- 故障传播追踪

**机器学习方法**：

- 随机森林分类
- XGBoost梯度提升
- SHAP可解释性
- 特征重要性分析

**最佳实践**：

- 多算法融合
- 历史数据学习
- 实时更新模型
- 可解释性优先
- 人工验证闭环

---

**上一篇**: [20_状态推理引擎.md](20_状态推理引擎.md)  
**下一篇**: [22_诊断决策树.md](22_诊断决策树.md)

---

*最后更新: 2025年10月7日*-
