# 实时监控架构

**文档版本**: 1.0.0  
**创建日期**: 2025年10月7日  
**所属**: 第四部分 - 监测与实时观测  

---

## 目录

- [实时监控架构](#实时监控架构)
  - [目录](#目录)
  - [概述](#概述)
  - [4.1.1 实时监控架构设计](#411-实时监控架构设计)
    - [Lambda架构](#lambda架构)
    - [Kappa架构](#kappa架构)
    - [OTLP混合架构](#otlp混合架构)
  - [4.1.2 流式处理引擎](#412-流式处理引擎)
    - [Kafka流处理](#kafka流处理)
    - [Flink实时计算](#flink实时计算)
  - [4.1.3 实时聚合与计算](#413-实时聚合与计算)
    - [时间窗口聚合](#时间窗口聚合)
    - [增量计算](#增量计算)
  - [4.1.4 监控指标体系](#414-监控指标体系)
    - [RED方法](#red方法)
    - [USE方法](#use方法)
    - [四个黄金信号](#四个黄金信号)
  - [总结](#总结)

---

## 概述

本文档介绍OTLP的实时监控架构，包括Lambda/Kappa架构、流式处理引擎和监控指标体系。

---

## 4.1.1 实时监控架构设计

### Lambda架构

**架构图**：

```text
┌─────────────────────────────────────────────────────────┐
│                    数据源（OTLP）                        │
│              Traces | Metrics | Logs                    │
└────────────┬────────────────────────────────────────────┘
             │
             ├──────────────┬──────────────────────────────┐
             │              │                              │
             ▼              ▼                              ▼
    ┌────────────┐  ┌──────────────┐          ┌──────────────┐
    │  批处理层   │  │  速度层      │          │  服务层       │
    │ (Batch)    │  │ (Speed)      │          │ (Serving)    │
    │            │  │              │          │              │
    │ Hadoop/    │  │ Kafka/       │          │ Query        │
    │ Spark      │  │ Flink        │          │ Engine       │
    │            │  │              │          │              │
    │ 完整数据    │  │ 实时增量     │          │ 合并视图      │
    │ 高延迟      │  │ 低延迟       │          │ 对外服务      │
    └────────────┘  └──────────────┘          └──────────────┘
         │                  │                         ▲
         │                  │                         │
         └──────────────────┴─────────────────────────┘
```

**特点**：

- **批处理层**：处理全量历史数据，保证准确性
- **速度层**：处理实时增量数据，保证低延迟
- **服务层**：合并批处理和实时结果

### Kappa架构

**架构图**：

```text
┌─────────────────────────────────────────────────────────┐
│                    数据源（OTLP）                        │
└────────────┬────────────────────────────────────────────┘
             │
             ▼
    ┌─────────────────┐
    │   消息队列       │
    │   (Kafka)       │
    └────────┬────────┘
             │
             ├─────────────┬─────────────┐
             ▼             ▼             ▼
    ┌──────────┐  ┌──────────┐  ┌──────────┐
    │ 实时处理1 │  │ 实时处理2 │  │ 实时处理3 │
    │ (Flink)  │  │ (Flink)  │  │ (Flink)  │
    └──────────┘  └──────────┘  └──────────┘
         │             │             │
         └─────────────┴─────────────┘
                       │
                       ▼
              ┌──────────────┐
              │   存储层      │
              │ (时序数据库)   │
              └──────────────┘
```

**特点**：

- **统一流处理**：所有数据都作为流处理
- **简化架构**：无需维护批处理和速度层
- **重新处理**：通过重放消息队列实现

### OTLP混合架构

**推荐架构**：

```go
// OTLP实时监控架构
type MonitoringArchitecture struct {
    // 数据接收层
    receivers []Receiver
    
    // 流处理层
    streamProcessor *StreamProcessor
    
    // 存储层
    hotStorage  Storage  // 热数据（最近1小时）
    warmStorage Storage  // 温数据（最近7天）
    coldStorage Storage  // 冷数据（历史数据）
    
    // 查询层
    queryEngine *QueryEngine
}

// 数据接收器
type Receiver struct {
    protocol string  // grpc, http
    endpoint string
    buffer   *RingBuffer
}

func (r *Receiver) Receive(data []byte) error {
    // 1. 解析OTLP数据
    spans, err := r.parseOTLP(data)
    if err != nil {
        return err
    }
    
    // 2. 写入缓冲区
    for _, span := range spans {
        if !r.buffer.Push(span) {
            // 缓冲区满，记录丢弃
            metrics.DroppedSpans.Inc()
        }
    }
    
    return nil
}

// 流处理器
type StreamProcessor struct {
    windows map[string]*TimeWindow
    mu      sync.RWMutex
}

func (sp *StreamProcessor) Process(span Span) {
    // 1. 分配到时间窗口
    window := sp.getOrCreateWindow(span.Timestamp)
    
    // 2. 更新聚合指标
    window.Update(span)
    
    // 3. 检查窗口是否完成
    if window.IsComplete() {
        sp.flushWindow(window)
    }
}

// 时间窗口
type TimeWindow struct {
    start    time.Time
    end      time.Time
    metrics  map[string]*Metric
    mu       sync.Mutex
}

func (tw *TimeWindow) Update(span Span) {
    tw.mu.Lock()
    defer tw.mu.Unlock()
    
    // 更新各种指标
    tw.updateLatency(span)
    tw.updateThroughput(span)
    tw.updateErrorRate(span)
}
```

---

## 4.1.2 流式处理引擎

### Kafka流处理

**Kafka Streams实现**：

```go
// Kafka Streams处理器
type KafkaStreamProcessor struct {
    consumer *kafka.Consumer
    producer *kafka.Producer
}

func (ksp *KafkaStreamProcessor) ProcessStream() {
    for {
        msg, err := ksp.consumer.ReadMessage(-1)
        if err != nil {
            log.Printf("Consumer error: %v", err)
            continue
        }
        
        // 1. 解析消息
        span, err := parseSpan(msg.Value)
        if err != nil {
            continue
        }
        
        // 2. 处理Span
        metrics := ksp.computeMetrics(span)
        
        // 3. 输出结果
        result, _ := json.Marshal(metrics)
        ksp.producer.Produce(&kafka.Message{
            TopicPartition: kafka.TopicPartition{
                Topic:     kafka.StringPointer("metrics"),
                Partition: kafka.PartitionAny,
            },
            Value: result,
        }, nil)
    }
}

func (ksp *KafkaStreamProcessor) computeMetrics(span Span) Metrics {
    return Metrics{
        ServiceName: span.ServiceName,
        Operation:   span.OperationName,
        Duration:    span.Duration(),
        StatusCode:  span.Status.Code,
        Timestamp:   span.StartTime,
    }
}
```

### Flink实时计算

**Flink DataStream API**：

```go
// Flink处理函数（伪代码，实际用Java/Scala）
type SpanProcessFunction struct{}

func (spf *SpanProcessFunction) ProcessElement(
    span Span,
    ctx Context,
    out Collector,
) {
    // 1. 提取时间戳
    timestamp := span.StartTime
    
    // 2. 计算指标
    metric := Metric{
        ServiceName: span.ServiceName,
        Latency:     span.Duration(),
        Success:     span.Status.Code == StatusOK,
        Timestamp:   timestamp,
    }
    
    // 3. 输出
    out.Collect(metric)
}

// 窗口聚合
type WindowAggregateFunction struct{}

func (waf *WindowAggregateFunction) Aggregate(
    metrics []Metric,
) AggregatedMetric {
    result := AggregatedMetric{
        ServiceName: metrics[0].ServiceName,
        Count:       len(metrics),
    }
    
    // 计算统计量
    var totalLatency time.Duration
    var successCount int
    
    for _, m := range metrics {
        totalLatency += m.Latency
        if m.Success {
            successCount++
        }
    }
    
    result.AvgLatency = totalLatency / time.Duration(len(metrics))
    result.SuccessRate = float64(successCount) / float64(len(metrics))
    
    return result
}
```

---

## 4.1.3 实时聚合与计算

### 时间窗口聚合

**滚动窗口（Tumbling Window）**：

```go
// 滚动窗口聚合器
type TumblingWindowAggregator struct {
    windowSize time.Duration
    windows    map[int64]*WindowState
    mu         sync.RWMutex
}

type WindowState struct {
    start   time.Time
    end     time.Time
    metrics []Metric
    result  *AggregatedMetric
}

func (twa *TumblingWindowAggregator) Add(metric Metric) {
    // 1. 计算窗口ID
    windowID := metric.Timestamp.Unix() / int64(twa.windowSize.Seconds())
    
    // 2. 获取或创建窗口
    twa.mu.Lock()
    window, exists := twa.windows[windowID]
    if !exists {
        window = &WindowState{
            start: time.Unix(windowID*int64(twa.windowSize.Seconds()), 0),
            end:   time.Unix((windowID+1)*int64(twa.windowSize.Seconds()), 0),
        }
        twa.windows[windowID] = window
    }
    twa.mu.Unlock()
    
    // 3. 添加到窗口
    window.metrics = append(window.metrics, metric)
}

func (twa *TumblingWindowAggregator) Flush() []AggregatedMetric {
    twa.mu.Lock()
    defer twa.mu.Unlock()
    
    now := time.Now()
    results := []AggregatedMetric{}
    
    for windowID, window := range twa.windows {
        // 只处理已完成的窗口
        if window.end.Before(now) {
            result := twa.aggregate(window.metrics)
            results = append(results, result)
            delete(twa.windows, windowID)
        }
    }
    
    return results
}
```

**滑动窗口（Sliding Window）**：

```go
// 滑动窗口聚合器
type SlidingWindowAggregator struct {
    windowSize time.Duration
    slideSize  time.Duration
    buffer     *CircularBuffer
}

func (swa *SlidingWindowAggregator) Add(metric Metric) {
    swa.buffer.Add(metric)
    
    // 检查是否需要触发计算
    if swa.shouldTrigger() {
        swa.compute()
    }
}

func (swa *SlidingWindowAggregator) compute() AggregatedMetric {
    now := time.Now()
    windowStart := now.Add(-swa.windowSize)
    
    // 获取窗口内的数据
    metrics := swa.buffer.GetRange(windowStart, now)
    
    // 聚合计算
    return swa.aggregate(metrics)
}
```

### 增量计算

**增量均值计算**：

```go
// 增量统计计算器
type IncrementalStats struct {
    count   int64
    sum     float64
    sumSq   float64
    min     float64
    max     float64
    mu      sync.Mutex
}

func (is *IncrementalStats) Add(value float64) {
    is.mu.Lock()
    defer is.mu.Unlock()
    
    is.count++
    is.sum += value
    is.sumSq += value * value
    
    if is.count == 1 {
        is.min = value
        is.max = value
    } else {
        if value < is.min {
            is.min = value
        }
        if value > is.max {
            is.max = value
        }
    }
}

func (is *IncrementalStats) Mean() float64 {
    is.mu.Lock()
    defer is.mu.Unlock()
    
    if is.count == 0 {
        return 0
    }
    return is.sum / float64(is.count)
}

func (is *IncrementalStats) StdDev() float64 {
    is.mu.Lock()
    defer is.mu.Unlock()
    
    if is.count == 0 {
        return 0
    }
    
    mean := is.sum / float64(is.count)
    variance := (is.sumSq / float64(is.count)) - (mean * mean)
    return math.Sqrt(variance)
}
```

**HyperLogLog基数估计**：

```go
// HyperLogLog用于估计唯一值数量
type HyperLogLog struct {
    registers []uint8
    m         uint32  // 寄存器数量
    alpha     float64
}

func NewHyperLogLog(precision uint8) *HyperLogLog {
    m := uint32(1 << precision)
    return &HyperLogLog{
        registers: make([]uint8, m),
        m:         m,
        alpha:     getAlpha(m),
    }
}

func (hll *HyperLogLog) Add(value string) {
    // 1. 哈希
    hash := hash64(value)
    
    // 2. 提取寄存器索引
    j := hash & (uint64(hll.m) - 1)
    
    // 3. 计算前导零个数
    w := hash >> uint(math.Log2(float64(hll.m)))
    leadingZeros := uint8(bits.LeadingZeros64(w)) + 1
    
    // 4. 更新寄存器
    if leadingZeros > hll.registers[j] {
        hll.registers[j] = leadingZeros
    }
}

func (hll *HyperLogLog) Count() uint64 {
    // 调和平均数
    sum := 0.0
    for _, val := range hll.registers {
        sum += 1.0 / math.Pow(2, float64(val))
    }
    
    estimate := hll.alpha * float64(hll.m*hll.m) / sum
    return uint64(estimate)
}
```

---

## 4.1.4 监控指标体系

### RED方法

**Rate, Errors, Duration**：

```go
// RED指标收集器
type REDMetrics struct {
    // Rate - 请求速率
    requestRate *prometheus.CounterVec
    
    // Errors - 错误率
    errorRate *prometheus.CounterVec
    
    // Duration - 持续时间
    duration *prometheus.HistogramVec
}

func NewREDMetrics() *REDMetrics {
    return &REDMetrics{
        requestRate: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "requests_total",
                Help: "Total number of requests",
            },
            []string{"service", "operation"},
        ),
        errorRate: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "errors_total",
                Help: "Total number of errors",
            },
            []string{"service", "operation", "error_type"},
        ),
        duration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "request_duration_seconds",
                Help:    "Request duration in seconds",
                Buckets: prometheus.DefBuckets,
            },
            []string{"service", "operation"},
        ),
    }
}

func (red *REDMetrics) RecordSpan(span Span) {
    labels := prometheus.Labels{
        "service":   span.ServiceName,
        "operation": span.OperationName,
    }
    
    // 记录请求
    red.requestRate.With(labels).Inc()
    
    // 记录错误
    if span.Status.Code != StatusOK {
        errorLabels := prometheus.Labels{
            "service":    span.ServiceName,
            "operation":  span.OperationName,
            "error_type": span.Status.Message,
        }
        red.errorRate.With(errorLabels).Inc()
    }
    
    // 记录持续时间
    red.duration.With(labels).Observe(span.Duration().Seconds())
}
```

### USE方法

**Utilization, Saturation, Errors**：

```go
// USE指标（资源监控）
type USEMetrics struct {
    // Utilization - 利用率
    cpuUtilization    *prometheus.GaugeVec
    memoryUtilization *prometheus.GaugeVec
    
    // Saturation - 饱和度
    queueLength *prometheus.GaugeVec
    waitTime    *prometheus.HistogramVec
    
    // Errors - 错误
    resourceErrors *prometheus.CounterVec
}

func (use *USEMetrics) RecordResourceMetrics(resource Resource) {
    labels := prometheus.Labels{
        "resource": resource.Name,
        "host":     resource.Host,
    }
    
    // 利用率
    use.cpuUtilization.With(labels).Set(resource.CPUUsage)
    use.memoryUtilization.With(labels).Set(resource.MemoryUsage)
    
    // 饱和度
    use.queueLength.With(labels).Set(float64(resource.QueueLength))
    use.waitTime.With(labels).Observe(resource.WaitTime.Seconds())
    
    // 错误
    if resource.ErrorCount > 0 {
        use.resourceErrors.With(labels).Add(float64(resource.ErrorCount))
    }
}
```

### 四个黄金信号

**Latency, Traffic, Errors, Saturation**：

```go
// 四个黄金信号
type GoldenSignals struct {
    latency    *prometheus.HistogramVec  // 延迟
    traffic    *prometheus.CounterVec    // 流量
    errors     *prometheus.CounterVec    // 错误
    saturation *prometheus.GaugeVec      // 饱和度
}

func (gs *GoldenSignals) Observe(span Span) {
    labels := prometheus.Labels{
        "service": span.ServiceName,
    }
    
    // 1. Latency
    gs.latency.With(labels).Observe(span.Duration().Seconds())
    
    // 2. Traffic
    gs.traffic.With(labels).Inc()
    
    // 3. Errors
    if span.Status.Code != StatusOK {
        gs.errors.With(labels).Inc()
    }
    
    // 4. Saturation (需要额外的资源指标)
    // 这里简化为队列长度
    queueLen := getQueueLength(span.ServiceName)
    gs.saturation.With(labels).Set(float64(queueLen))
}
```

---

## 总结

实时监控架构核心要素：

**架构模式**：

- Lambda架构：批处理+实时
- Kappa架构：纯流处理
- OTLP混合架构：分层存储

**流式处理**：

- Kafka Streams：轻量级
- Flink：强大的流计算
- 窗口聚合：滚动、滑动

**增量计算**：

- 增量统计：均值、方差
- HyperLogLog：基数估计
- 高效内存使用

**监控指标**：

- RED：请求、错误、延迟
- USE：利用率、饱和度、错误
- 四个黄金信号：全面监控

**最佳实践**：

- 热温冷分层存储
- 实时+批处理结合
- 多维度指标体系
- 增量计算优化

---

**上一篇**: [10_性能瓶颈分析.md](10_性能瓶颈分析.md)  
**下一篇**: [12_指标采集与聚合.md](12_指标采集与聚合.md)

---

*最后更新: 2025年10月7日*-
