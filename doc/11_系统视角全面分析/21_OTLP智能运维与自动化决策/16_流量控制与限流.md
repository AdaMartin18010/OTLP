# 流量控制与限流

**文档版本**: 1.0.0  
**创建日期**: 2025年10月7日  
**所属**: 第五部分 - 控制与动态调整  

---

## 目录

- [流量控制与限流](#流量控制与限流)
  - [目录](#目录)
  - [概述](#概述)
  - [5.3.1 限流算法](#531-限流算法)
    - [令牌桶算法](#令牌桶算法)
    - [漏桶算法](#漏桶算法)
    - [滑动窗口算法](#滑动窗口算法)
  - [5.3.2 分布式限流](#532-分布式限流)
    - [Redis限流](#redis限流)
    - [一致性哈希限流](#一致性哈希限流)
  - [5.3.3 流量整形](#533-流量整形)
    - [流量平滑](#流量平滑)
    - [优先级队列](#优先级队列)
  - [5.3.4 背压机制](#534-背压机制)
    - [反向压力传播](#反向压力传播)
    - [自适应背压](#自适应背压)
  - [总结](#总结)

---

## 概述

本文档介绍OTLP的流量控制与限流机制，包括多种限流算法、分布式限流、流量整形和背压机制。

---

## 5.3.1 限流算法

### 令牌桶算法

**Token Bucket实现**：

```go
// 令牌桶限流器
type TokenBucket struct {
    capacity     int64         // 桶容量
    tokens       int64         // 当前令牌数
    refillRate   int64         // 每秒补充令牌数
    lastRefill   time.Time     // 上次补充时间
    mu           sync.Mutex
}

func NewTokenBucket(capacity, refillRate int64) *TokenBucket {
    return &TokenBucket{
        capacity:   capacity,
        tokens:     capacity,
        refillRate: refillRate,
        lastRefill: time.Now(),
    }
}

func (tb *TokenBucket) Allow() bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    // 1. 补充令牌
    tb.refill()
    
    // 2. 尝试消费令牌
    if tb.tokens > 0 {
        tb.tokens--
        return true
    }
    
    return false
}

func (tb *TokenBucket) AllowN(n int64) bool {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    tb.refill()
    
    if tb.tokens >= n {
        tb.tokens -= n
        return true
    }
    
    return false
}

func (tb *TokenBucket) refill() {
    now := time.Now()
    elapsed := now.Sub(tb.lastRefill)
    
    // 计算应补充的令牌数
    tokensToAdd := int64(elapsed.Seconds() * float64(tb.refillRate))
    
    if tokensToAdd > 0 {
        tb.tokens = min(tb.capacity, tb.tokens+tokensToAdd)
        tb.lastRefill = now
    }
}

// 等待令牌（阻塞）
func (tb *TokenBucket) Wait(ctx context.Context) error {
    for {
        if tb.Allow() {
            return nil
        }
        
        // 计算等待时间
        waitTime := tb.calculateWaitTime()
        
        select {
        case <-time.After(waitTime):
            continue
        case <-ctx.Done():
            return ctx.Err()
        }
    }
}

func (tb *TokenBucket) calculateWaitTime() time.Duration {
    tb.mu.Lock()
    defer tb.mu.Unlock()
    
    if tb.tokens > 0 {
        return 0
    }
    
    // 等待一个令牌生成的时间
    return time.Duration(float64(time.Second) / float64(tb.refillRate))
}
```

### 漏桶算法

**Leaky Bucket实现**：

```go
// 漏桶限流器
type LeakyBucket struct {
    capacity   int64         // 桶容量
    water      int64         // 当前水量
    leakRate   int64         // 每秒漏出速率
    lastLeak   time.Time     // 上次漏水时间
    mu         sync.Mutex
}

func NewLeakyBucket(capacity, leakRate int64) *LeakyBucket {
    return &LeakyBucket{
        capacity: capacity,
        water:    0,
        leakRate: leakRate,
        lastLeak: time.Now(),
    }
}

func (lb *LeakyBucket) Allow() bool {
    lb.mu.Lock()
    defer lb.mu.Unlock()
    
    // 1. 漏水
    lb.leak()
    
    // 2. 尝试加水
    if lb.water < lb.capacity {
        lb.water++
        return true
    }
    
    return false
}

func (lb *LeakyBucket) leak() {
    now := time.Now()
    elapsed := now.Sub(lb.lastLeak)
    
    // 计算应漏出的水量
    leaked := int64(elapsed.Seconds() * float64(lb.leakRate))
    
    if leaked > 0 {
        lb.water = max(0, lb.water-leaked)
        lb.lastLeak = now
    }
}

// 平滑输出
type SmoothLeakyBucket struct {
    bucket   *LeakyBucket
    queue    chan Request
    stopChan chan struct{}
}

func NewSmoothLeakyBucket(capacity, leakRate int64) *SmoothLeakyBucket {
    slb := &SmoothLeakyBucket{
        bucket:   NewLeakyBucket(capacity, leakRate),
        queue:    make(chan Request, capacity),
        stopChan: make(chan struct{}),
    }
    
    go slb.processQueue()
    return slb
}

func (slb *SmoothLeakyBucket) processQueue() {
    ticker := time.NewTicker(time.Second / time.Duration(slb.bucket.leakRate))
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            select {
            case req := <-slb.queue:
                // 处理请求
                req.Process()
            default:
                // 队列为空
            }
        case <-slb.stopChan:
            return
        }
    }
}

func (slb *SmoothLeakyBucket) Submit(req Request) error {
    select {
    case slb.queue <- req:
        return nil
    default:
        return errors.New("bucket full")
    }
}
```

### 滑动窗口算法

**Sliding Window实现**：

```go
// 滑动窗口限流器
type SlidingWindowLimiter struct {
    limit      int64         // 限制数量
    window     time.Duration // 窗口大小
    buckets    []int64       // 时间桶
    bucketSize time.Duration // 桶大小
    mu         sync.RWMutex
}

func NewSlidingWindowLimiter(limit int64, window time.Duration, bucketCount int) *SlidingWindowLimiter {
    return &SlidingWindowLimiter{
        limit:      limit,
        window:     window,
        buckets:    make([]int64, bucketCount),
        bucketSize: window / time.Duration(bucketCount),
    }
}

func (swl *SlidingWindowLimiter) Allow() bool {
    swl.mu.Lock()
    defer swl.mu.Unlock()
    
    now := time.Now()
    currentBucket := swl.getBucketIndex(now)
    
    // 1. 清理过期桶
    swl.cleanExpiredBuckets(now)
    
    // 2. 计算当前窗口内的请求数
    count := swl.countRequests()
    
    // 3. 判断是否超限
    if count < swl.limit {
        swl.buckets[currentBucket]++
        return true
    }
    
    return false
}

func (swl *SlidingWindowLimiter) getBucketIndex(t time.Time) int {
    return int((t.UnixNano() / int64(swl.bucketSize)) % int64(len(swl.buckets)))
}

func (swl *SlidingWindowLimiter) cleanExpiredBuckets(now time.Time) {
    cutoff := now.Add(-swl.window)
    
    for i := range swl.buckets {
        bucketTime := swl.getBucketTime(i)
        if bucketTime.Before(cutoff) {
            swl.buckets[i] = 0
        }
    }
}

func (swl *SlidingWindowLimiter) countRequests() int64 {
    var total int64
    for _, count := range swl.buckets {
        total += count
    }
    return total
}

// 精确滑动窗口（使用时间戳列表）
type PreciseSlidingWindow struct {
    limit      int64
    window     time.Duration
    timestamps []time.Time
    mu         sync.Mutex
}

func (psw *PreciseSlidingWindow) Allow() bool {
    psw.mu.Lock()
    defer psw.mu.Unlock()
    
    now := time.Now()
    cutoff := now.Add(-psw.window)
    
    // 1. 移除过期时间戳
    psw.removeExpired(cutoff)
    
    // 2. 检查是否超限
    if int64(len(psw.timestamps)) < psw.limit {
        psw.timestamps = append(psw.timestamps, now)
        return true
    }
    
    return false
}

func (psw *PreciseSlidingWindow) removeExpired(cutoff time.Time) {
    // 二分查找第一个未过期的位置
    left, right := 0, len(psw.timestamps)
    for left < right {
        mid := (left + right) / 2
        if psw.timestamps[mid].Before(cutoff) {
            left = mid + 1
        } else {
            right = mid
        }
    }
    psw.timestamps = psw.timestamps[left:]
}
```

---

## 5.3.2 分布式限流

### Redis限流

**基于Redis的分布式限流**：

```go
// Redis限流器
type RedisRateLimiter struct {
    client *redis.Client
    key    string
    limit  int64
    window time.Duration
}

func (rrl *RedisRateLimiter) Allow(userID string) (bool, error) {
    key := fmt.Sprintf("%s:%s", rrl.key, userID)
    now := time.Now().UnixNano()
    windowStart := now - int64(rrl.window)
    
    // Lua脚本保证原子性
    script := `
        local key = KEYS[1]
        local now = tonumber(ARGV[1])
        local window_start = tonumber(ARGV[2])
        local limit = tonumber(ARGV[3])
        
        -- 移除过期记录
        redis.call('ZREMRANGEBYSCORE', key, 0, window_start)
        
        -- 获取当前计数
        local count = redis.call('ZCARD', key)
        
        if count < limit then
            -- 添加新记录
            redis.call('ZADD', key, now, now)
            redis.call('EXPIRE', key, 60)
            return 1
        else
            return 0
        end
    `
    
    result, err := rrl.client.Eval(
        context.Background(),
        script,
        []string{key},
        now, windowStart, rrl.limit,
    ).Result()
    
    if err != nil {
        return false, err
    }
    
    return result.(int64) == 1, nil
}

// 令牌桶Redis实现
type RedisTokenBucket struct {
    client     *redis.Client
    key        string
    capacity   int64
    refillRate int64
}

func (rtb *RedisTokenBucket) Allow(userID string) (bool, error) {
    key := fmt.Sprintf("%s:%s", rtb.key, userID)
    
    script := `
        local key = KEYS[1]
        local capacity = tonumber(ARGV[1])
        local refill_rate = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        
        -- 获取当前状态
        local data = redis.call('HMGET', key, 'tokens', 'last_refill')
        local tokens = tonumber(data[1]) or capacity
        local last_refill = tonumber(data[2]) or now
        
        -- 补充令牌
        local elapsed = now - last_refill
        local tokens_to_add = math.floor(elapsed * refill_rate)
        tokens = math.min(capacity, tokens + tokens_to_add)
        
        -- 尝试消费令牌
        if tokens > 0 then
            tokens = tokens - 1
            redis.call('HMSET', key, 'tokens', tokens, 'last_refill', now)
            redis.call('EXPIRE', key, 60)
            return 1
        else
            return 0
        end
    `
    
    now := float64(time.Now().UnixNano()) / 1e9
    result, err := rtb.client.Eval(
        context.Background(),
        script,
        []string{key},
        rtb.capacity, float64(rtb.refillRate), now,
    ).Result()
    
    if err != nil {
        return false, err
    }
    
    return result.(int64) == 1, nil
}
```

### 一致性哈希限流

**分片限流**：

```go
// 一致性哈希限流器
type ConsistentHashLimiter struct {
    ring      *ConsistentHashRing
    limiters  map[string]*TokenBucket
    mu        sync.RWMutex
}

type ConsistentHashRing struct {
    nodes       []string
    virtualNodes int
    ring        map[uint32]string
    sortedKeys  []uint32
}

func (chl *ConsistentHashLimiter) Allow(key string) bool {
    // 1. 通过一致性哈希找到对应的节点
    node := chl.ring.GetNode(key)
    
    // 2. 获取该节点的限流器
    chl.mu.RLock()
    limiter, exists := chl.limiters[node]
    chl.mu.RUnlock()
    
    if !exists {
        chl.mu.Lock()
        limiter = NewTokenBucket(1000, 100)
        chl.limiters[node] = limiter
        chl.mu.Unlock()
    }
    
    // 3. 执行限流
    return limiter.Allow()
}

func (chr *ConsistentHashRing) GetNode(key string) string {
    if len(chr.ring) == 0 {
        return ""
    }
    
    hash := chr.hashKey(key)
    
    // 二分查找
    idx := sort.Search(len(chr.sortedKeys), func(i int) bool {
        return chr.sortedKeys[i] >= hash
    })
    
    if idx == len(chr.sortedKeys) {
        idx = 0
    }
    
    return chr.ring[chr.sortedKeys[idx]]
}

func (chr *ConsistentHashRing) hashKey(key string) uint32 {
    h := fnv.New32a()
    h.Write([]byte(key))
    return h.Sum32()
}
```

---

## 5.3.3 流量整形

### 流量平滑

**流量平滑器**：

```go
// 流量平滑器
type TrafficShaper struct {
    targetRate   float64       // 目标速率
    burstSize    int           // 突发大小
    queue        chan Request
    rateLimiter  *rate.Limiter
}

func NewTrafficShaper(targetRate float64, burstSize int) *TrafficShaper {
    ts := &TrafficShaper{
        targetRate:  targetRate,
        burstSize:   burstSize,
        queue:       make(chan Request, burstSize*2),
        rateLimiter: rate.NewLimiter(rate.Limit(targetRate), burstSize),
    }
    
    go ts.processQueue()
    return ts
}

func (ts *TrafficShaper) processQueue() {
    for req := range ts.queue {
        // 等待令牌
        ts.rateLimiter.Wait(context.Background())
        
        // 处理请求
        req.Process()
    }
}

func (ts *TrafficShaper) Submit(req Request) error {
    select {
    case ts.queue <- req:
        return nil
    default:
        return errors.New("queue full")
    }
}

// 自适应流量整形
type AdaptiveTrafficShaper struct {
    shaper         *TrafficShaper
    targetLatency  time.Duration
    adjustInterval time.Duration
}

func (ats *AdaptiveTrafficShaper) Start() {
    ticker := time.NewTicker(ats.adjustInterval)
    defer ticker.Stop()
    
    for range ticker.C {
        // 1. 测量当前延迟
        currentLatency := ats.measureLatency()
        
        // 2. 调整速率
        if currentLatency > ats.targetLatency {
            // 延迟过高，降低速率
            ats.shaper.targetRate *= 0.9
        } else {
            // 延迟正常，提高速率
            ats.shaper.targetRate *= 1.1
        }
        
        // 3. 更新限流器
        ats.shaper.rateLimiter.SetLimit(rate.Limit(ats.shaper.targetRate))
    }
}
```

### 优先级队列

**优先级流量控制**：

```go
// 优先级队列限流器
type PriorityRateLimiter struct {
    queues   []*PriorityQueue
    limiters []*TokenBucket
}

type PriorityQueue struct {
    priority int
    queue    chan Request
}

func NewPriorityRateLimiter(priorities []int, rates []int64) *PriorityRateLimiter {
    prl := &PriorityRateLimiter{
        queues:   make([]*PriorityQueue, len(priorities)),
        limiters: make([]*TokenBucket, len(priorities)),
    }
    
    for i, priority := range priorities {
        prl.queues[i] = &PriorityQueue{
            priority: priority,
            queue:    make(chan Request, 1000),
        }
        prl.limiters[i] = NewTokenBucket(rates[i]*10, rates[i])
    }
    
    go prl.processQueues()
    return prl
}

func (prl *PriorityRateLimiter) processQueues() {
    for {
        // 按优先级处理
        for i := range prl.queues {
            select {
            case req := <-prl.queues[i].queue:
                // 等待令牌
                for !prl.limiters[i].Allow() {
                    time.Sleep(10 * time.Millisecond)
                }
                
                // 处理请求
                go req.Process()
            default:
                // 该优先级队列为空，继续下一个
            }
        }
        
        time.Sleep(time.Millisecond)
    }
}

func (prl *PriorityRateLimiter) Submit(req Request, priority int) error {
    // 找到对应优先级的队列
    for i, queue := range prl.queues {
        if queue.priority == priority {
            select {
            case prl.queues[i].queue <- req:
                return nil
            default:
                return errors.New("queue full")
            }
        }
    }
    
    return errors.New("invalid priority")
}
```

---

## 5.3.4 背压机制

### 反向压力传播

**背压传播实现**：

```go
// 背压控制器
type BackpressureController struct {
    queueSize      int
    maxQueueSize   int
    highWaterMark  float64  // 高水位线
    lowWaterMark   float64  // 低水位线
    state          BackpressureState
    mu             sync.RWMutex
}

type BackpressureState int

const (
    StateNormal BackpressureState = iota
    StateWarning
    StateCritical
)

func (bpc *BackpressureController) CheckState() BackpressureState {
    bpc.mu.RLock()
    defer bpc.mu.RUnlock()
    
    utilization := float64(bpc.queueSize) / float64(bpc.maxQueueSize)
    
    if utilization > bpc.highWaterMark {
        return StateCritical
    } else if utilization > bpc.lowWaterMark {
        return StateWarning
    }
    
    return StateNormal
}

func (bpc *BackpressureController) ShouldApplyBackpressure() bool {
    return bpc.CheckState() != StateNormal
}

func (bpc *BackpressureController) GetBackpressureDelay() time.Duration {
    state := bpc.CheckState()
    
    switch state {
    case StateCritical:
        return 100 * time.Millisecond
    case StateWarning:
        return 50 * time.Millisecond
    default:
        return 0
    }
}

// 响应式背压
type ReactiveBackpressure struct {
    producer Consumer
    consumer Consumer
    buffer   chan Data
}

type Consumer interface {
    Request(n int)
    OnNext(data Data)
    OnComplete()
    OnError(err error)
}

func (rbp *ReactiveBackpressure) Start() {
    go func() {
        for data := range rbp.buffer {
            // 通知消费者
            rbp.consumer.OnNext(data)
            
            // 检查缓冲区
            if len(rbp.buffer) < cap(rbp.buffer)/2 {
                // 缓冲区低于50%，请求更多数据
                rbp.producer.Request(cap(rbp.buffer) / 2)
            }
        }
    }()
}
```

### 自适应背压

**动态调整背压策略**：

```go
// 自适应背压控制器
type AdaptiveBackpressure struct {
    targetLatency  time.Duration
    currentLatency time.Duration
    dropRate       float64
    mu             sync.RWMutex
}

func (abp *AdaptiveBackpressure) Update(latency time.Duration) {
    abp.mu.Lock()
    defer abp.mu.Unlock()
    
    abp.currentLatency = latency
    
    // 计算丢弃率
    if latency > abp.targetLatency {
        ratio := float64(latency) / float64(abp.targetLatency)
        abp.dropRate = 1.0 - (1.0 / ratio)
        abp.dropRate = math.Min(0.9, abp.dropRate)  // 最多丢弃90%
    } else {
        // 延迟正常，降低丢弃率
        abp.dropRate *= 0.9
    }
}

func (abp *AdaptiveBackpressure) ShouldDrop() bool {
    abp.mu.RLock()
    defer abp.mu.RUnlock()
    
    return rand.Float64() < abp.dropRate
}

// 分级背压
type TieredBackpressure struct {
    levels []BackpressureLevel
}

type BackpressureLevel struct {
    Threshold  float64
    Action     BackpressureAction
}

type BackpressureAction int

const (
    ActionNone BackpressureAction = iota
    ActionDelay
    ActionSample
    ActionDrop
)

func (tbp *TieredBackpressure) GetAction(utilization float64) BackpressureAction {
    for _, level := range tbp.levels {
        if utilization >= level.Threshold {
            return level.Action
        }
    }
    return ActionNone
}

// 使用示例
func main() {
    tbp := &TieredBackpressure{
        levels: []BackpressureLevel{
            {Threshold: 0.9, Action: ActionDrop},
            {Threshold: 0.7, Action: ActionSample},
            {Threshold: 0.5, Action: ActionDelay},
        },
    }
}
```

---

## 总结

流量控制与限流核心技术：

**限流算法**：

- 令牌桶：支持突发
- 漏桶：平滑输出
- 滑动窗口：精确控制

**分布式限流**：

- Redis原子操作
- 一致性哈希分片
- 分布式协调

**流量整形**：

- 流量平滑
- 优先级队列
- 自适应调整

**背压机制**：

- 反向压力传播
- 自适应丢弃
- 分级响应

**最佳实践**：

- 令牌桶用于API限流
- 漏桶用于流量整形
- 滑动窗口用于精确控制
- 背压用于过载保护
- 多级限流策略
- 监控与告警

---

**上一篇**: [15_自适应资源管理.md](15_自适应资源管理.md)  
**下一篇**: [17_时序数据分析.md](17_时序数据分析.md)

---

*最后更新: 2025年10月7日*-
