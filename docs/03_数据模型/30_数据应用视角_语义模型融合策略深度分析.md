# OTLPæ•°æ®åº”ç”¨è§†è§’ï¼šè¯­ä¹‰æ¨¡å‹èåˆç­–ç•¥æ·±åº¦åˆ†æ

> **æ–‡æ¡£ç±»å‹**: æ•°æ®æ¨¡å‹æ·±åº¦åˆ†æ  
> **åˆ†æç»´åº¦**: æ•°æ®åº”ç”¨è§†è§’ - è¯­ä¹‰æ¨¡å‹èåˆç­–ç•¥  
> **åˆ›å»ºæ—¥æœŸ**: 2025å¹´10æœˆ11æ—¥  
> **æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ“‹ ç›®å½•

- [OTLPæ•°æ®åº”ç”¨è§†è§’ï¼šè¯­ä¹‰æ¨¡å‹èåˆç­–ç•¥æ·±åº¦åˆ†æ](#otlpæ•°æ®åº”ç”¨è§†è§’è¯­ä¹‰æ¨¡å‹èåˆç­–ç•¥æ·±åº¦åˆ†æ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸ¯ æ‰§è¡Œæ‘˜è¦](#-æ‰§è¡Œæ‘˜è¦)
    - [è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯](#è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯)
  - [ğŸ“Š è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯](#-è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯)
    - [èåˆç±»å‹çŸ©é˜µ](#èåˆç±»å‹çŸ©é˜µ)
  - [ğŸ”— è¯­ä¹‰æ¨¡å‹èåˆ](#-è¯­ä¹‰æ¨¡å‹èåˆ)
    - [Tracesèåˆ](#tracesèåˆ)
    - [Metricsèåˆ](#metricsèåˆ)
    - [Logsèåˆ](#logsèåˆ)
  - [ğŸ“ˆ èåˆæ€§èƒ½åˆ†æ](#-èåˆæ€§èƒ½åˆ†æ)
    - [èåˆæ€§èƒ½åŸºå‡†æµ‹è¯•](#èåˆæ€§èƒ½åŸºå‡†æµ‹è¯•)
  - [âš¡ èåˆä¼˜åŒ–ç­–ç•¥](#-èåˆä¼˜åŒ–ç­–ç•¥)
    - [1. å¢é‡èåˆç­–ç•¥](#1-å¢é‡èåˆç­–ç•¥)
    - [2. å¹¶è¡Œèåˆç­–ç•¥](#2-å¹¶è¡Œèåˆç­–ç•¥)
    - [3. ç¼“å­˜èåˆç­–ç•¥](#3-ç¼“å­˜èåˆç­–ç•¥)
  - [ğŸ’¡ å®æˆ˜æ¡ˆä¾‹](#-å®æˆ˜æ¡ˆä¾‹)
    - [æ¡ˆä¾‹1ï¼šç”µå•†ç³»ç»Ÿè¯­ä¹‰èåˆ](#æ¡ˆä¾‹1ç”µå•†ç³»ç»Ÿè¯­ä¹‰èåˆ)
    - [æ¡ˆä¾‹2ï¼šé‡‘èç³»ç»Ÿè¯­ä¹‰èåˆ](#æ¡ˆä¾‹2é‡‘èç³»ç»Ÿè¯­ä¹‰èåˆ)
  - [ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®](#-æ€§èƒ½ä¼˜åŒ–å»ºè®®)
    - [èåˆä¼˜åŒ–çŸ©é˜µ](#èåˆä¼˜åŒ–çŸ©é˜µ)
  - [ğŸ¯ æ€»ç»“](#-æ€»ç»“)

---

## ğŸ¯ æ‰§è¡Œæ‘˜è¦

### è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯

```text
è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          OTLPè¯­ä¹‰æ¨¡å‹èåˆç­–ç•¥ä½“ç³»                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  èåˆç±»å‹                                      â”‚      â”‚
â”‚  â”‚  - Tracesèåˆ                                  â”‚      â”‚
â”‚  â”‚  - Metricsèåˆ                                 â”‚      â”‚
â”‚  â”‚  - Logsèåˆ                                    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                         â”‚                               â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚         â”‚               â”‚               â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ èåˆç­–ç•¥    â”‚  â”‚ èåˆç®—æ³•    â”‚  â”‚ æ€§èƒ½ä¼˜åŒ–    â”‚        â”‚
â”‚  â”‚ - å¢é‡èåˆ  â”‚  â”‚ - æ—¶é—´å¯¹é½  â”‚  â”‚ - å¹¶è¡Œ     â”‚        â”‚
â”‚  â”‚ - å¹¶è¡Œèåˆ  â”‚  â”‚ - å±æ€§åŒ¹é…  â”‚  â”‚ - ç¼“å­˜     â”‚        â”‚
â”‚  â”‚ - ç¼“å­˜èåˆ  â”‚  â”‚ - è¯­ä¹‰å…³è”  â”‚  â”‚ - å‹ç¼©     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  èåˆåœºæ™¯                                      â”‚      â”‚
â”‚  â”‚  - ç”µå•†ç³»ç»Ÿ                                    â”‚      â”‚
â”‚  â”‚  - é‡‘èç³»ç»Ÿ                                    â”‚      â”‚
â”‚  â”‚  - ç‰©æµç³»ç»Ÿ                                    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒæ´å¯Ÿ**ï¼š

1. **èåˆç±»å‹**ï¼šTracesèåˆ + Metricsèåˆ + Logsèåˆ
2. **èåˆç­–ç•¥**ï¼šå¢é‡èåˆ + å¹¶è¡Œèåˆ + ç¼“å­˜èåˆ
3. **èåˆç®—æ³•**ï¼šæ—¶é—´å¯¹é½ + å±æ€§åŒ¹é… + è¯­ä¹‰å…³è”
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šå¹¶è¡Œ + ç¼“å­˜ + å‹ç¼©

---

## ğŸ“Š è¯­ä¹‰æ¨¡å‹èåˆå…¨æ™¯

### èåˆç±»å‹çŸ©é˜µ

```text
èåˆç±»å‹çŸ©é˜µ:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  èåˆç±»å‹      â”‚ è¾“å…¥æ•°æ®    â”‚ è¾“å‡ºæ•°æ®    â”‚ æ•ˆæœ      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tracesèåˆ    â”‚ Spans[]    â”‚ Unified Traceâ”‚ å…³è”    â”‚
â”‚  Metricsèåˆ   â”‚ Metrics[]  â”‚ Unified Metricâ”‚ èšåˆ    â”‚
â”‚  Logsèåˆ      â”‚ Logs[]     â”‚ Unified Logâ”‚ å…³è”    â”‚
â”‚  è·¨ç±»å‹èåˆ    â”‚ Traces+Metrics+Logsâ”‚ Unified Dataâ”‚ å…³è”    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— è¯­ä¹‰æ¨¡å‹èåˆ

### Tracesèåˆ

```go
// Tracesèåˆ
package main

import (
    "go.opentelemetry.io/otel/trace"
)

type TraceMerger struct {
    traces map[string]*UnifiedTrace
    mutex  sync.Mutex
}

func NewTraceMerger() *TraceMerger {
    return &TraceMerger{
        traces: make(map[string]*UnifiedTrace),
    }
}

func (tm *TraceMerger) Merge(spans []*trace.Span) []*UnifiedTrace {
    tm.mutex.Lock()
    defer tm.mutex.Unlock()
    
    // æŒ‰trace_idåˆ†ç»„
    traceMap := make(map[string][]*trace.Span)
    for _, span := range spans {
        traceID := string(span.TraceId)
        traceMap[traceID] = append(traceMap[traceID], span)
    }
    
    // èåˆæ¯ä¸ªtrace
    unifiedTraces := make([]*UnifiedTrace, 0)
    for traceID, traceSpans := range traceMap {
        unified := tm.mergeTrace(traceID, traceSpans)
        unifiedTraces = append(unifiedTraces, unified)
    }
    
    return unifiedTraces
}

func (tm *TraceMerger) mergeTrace(traceID string, spans []*trace.Span) *UnifiedTrace {
    // æ„å»ºspanæ ‘
    spanTree := buildSpanTree(spans)
    
    // æå–å…³é”®ä¿¡æ¯
    startTime := getEarliestStartTime(spans)
    endTime := getLatestEndTime(spans)
    duration := endTime.Sub(startTime)
    
    // ç»Ÿè®¡ä¿¡æ¯
    totalSpans := len(spans)
    errorSpans := countErrorSpans(spans)
    slowSpans := countSlowSpans(spans, 1*time.Second)
    
    return &UnifiedTrace{
        TraceID:     traceID,
        Spans:       spans,
        SpanTree:    spanTree,
        StartTime:   startTime,
        EndTimeout:  endTime,
        Duration:    duration,
        TotalSpans:  totalSpans,
        ErrorSpans:  errorSpans,
        SlowSpans:   slowSpans,
    }
}

type UnifiedTrace struct {
    TraceID     string
    Spans       []*trace.Span
    SpanTree    *SpanNode
    StartTime   time.Time
    EndTimeout  time.Time
    Duration    time.Duration
    TotalSpans  int
    ErrorSpans  int
    SlowSpans   int
}

type SpanNode struct {
    Span      *trace.Span
    Children  []*SpanNode
}
```

### Metricsèåˆ

```go
// Metricsèåˆ
package main

import (
    "go.opentelemetry.io/otel/metric"
)

type MetricMerger struct {
    metrics map[string]*UnifiedMetric
    mutex   sync.Mutex
}

func NewMetricMerger() *MetricMerger {
    return &MetricMerger{
        metrics: make(map[string]*UnifiedMetric),
    }
}

func (mm *MetricMerger) Merge(metrics []*metric.Metric) []*UnifiedMetric {
    mm.mutex.Lock()
    defer mm.mutex.Unlock()
    
    // æŒ‰metricåç§°åˆ†ç»„
    metricMap := make(map[string][]*metric.Metric)
    for _, m := range metrics {
        metricMap[m.Name] = append(metricMap[m.Name], m)
    }
    
    // èåˆæ¯ä¸ªmetric
    unifiedMetrics := make([]*UnifiedMetric, 0)
    for name, metricList := range metricMap {
        unified := mm.mergeMetric(name, metricList)
        unifiedMetrics = append(unifiedMetrics, unified)
    }
    
    return unifiedMetrics
}

func (mm *MetricMerger) mergeMetric(name string, metrics []*metric.Metric) *UnifiedMetric {
    // èšåˆæ•°æ®ç‚¹
    dataPoints := make([]*DataPoint, 0)
    
    for _, m := range metrics {
        for _, dp := range m.DataPoints {
            dataPoints = append(dataPoints, &DataPoint{
                Timestamp: dp.Timestamp,
                Value:      dp.Value,
                Attributes: dp.Attributes,
            })
        }
    }
    
    // æŒ‰æ—¶é—´æ’åº
    sort.Slice(dataPoints, func(i, j int) bool {
        return dataPoints[i].Timestamp.Before(dataPoints[j].Timestamp)
    })
    
    // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    sum := calculateSum(dataPoints)
    avg := calculateAvg(dataPoints)
    min := calculateMin(dataPoints)
    max := calculateMax(dataPoints)
    
    return &UnifiedMetric{
        Name:       name,
        DataPoints: dataPoints,
        Sum:        sum,
        Avg:        avg,
        Min:        min,
        Max:        max,
        Count:      len(dataPoints),
    }
}

type UnifiedMetric struct {
    Name       string
    DataPoints []*DataPoint
    Sum        float64
    Avg        float64
    Min        float64
    Max        float64
    Count      int
}

type DataPoint struct {
    Timestamp  time.Time
    Value      float64
    Attributes map[string]string
}
```

### Logsèåˆ

```go
// Logsèåˆ
package main

import (
    "go.opentelemetry.io/otel/log"
)

type LogMerger struct {
    logs  map[string]*UnifiedLog
    mutex sync.Mutex
}

func NewLogMerger() *LogMerger {
    return &LogMerger{
        logs: make(map[string]*UnifiedLog),
    }
}

func (lm *LogMerger) Merge(logs []*log.LogRecord) []*UnifiedLog {
    lm.mutex.Lock()
    defer lm.mutex.Unlock()
    
    // æŒ‰trace_idåˆ†ç»„
    logMap := make(map[string][]*log.LogRecord)
    for _, l := range logs {
        traceID := string(l.TraceID)
        logMap[traceID] = append(logMap[traceID], l)
    }
    
    // èåˆæ¯ä¸ªtraceçš„æ—¥å¿—
    unifiedLogs := make([]*UnifiedLog, 0)
    for traceID, traceLogs := range logMap {
        unified := lm.mergeLog(traceID, traceLogs)
        unifiedLogs = append(unifiedLogs, unified)
    }
    
    return unifiedLogs
}

func (lm *LogMerger) mergeLog(traceID string, logs []*log.LogRecord) *UnifiedLog {
    // æŒ‰æ—¶é—´æ’åº
    sort.Slice(logs, func(i, j int) bool {
        return logs[i].Timestamp.Before(logs[j].Timestamp)
    })
    
    // æå–å…³é”®ä¿¡æ¯
    startTime := logs[0].Timestamp
    endTime := logs[len(logs)-1].Timestamp
    duration := endTime.Sub(startTime)
    
    // ç»Ÿè®¡ä¿¡æ¯
    totalLogs := len(logs)
    errorLogs := countErrorLogs(logs)
    warningLogs := countWarningLogs(logs)
    
    return &UnifiedLog{
        TraceID:      traceID,
        Logs:         logs,
        StartTime:    startTime,
        EndTime:      endTime,
        Duration:     duration,
        TotalLogs:    totalLogs,
        ErrorLogs:    errorLogs,
        WarningLogs:  warningLogs,
    }
}

type UnifiedLog struct {
    TraceID     string
    Logs        []*log.LogRecord
    StartTime   time.Time
    EndTime     time.Time
    Duration    time.Duration
    TotalLogs   int
    ErrorLogs   int
    WarningLogs int
}
```

---

## ğŸ“ˆ èåˆæ€§èƒ½åˆ†æ

### èåˆæ€§èƒ½åŸºå‡†æµ‹è¯•

```text
èåˆæ€§èƒ½åŸºå‡†æµ‹è¯• (100,000 Spans):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ“ä½œç±»å‹      â”‚ è€—æ—¶      â”‚ å†…å­˜      â”‚ å¤æ‚åº¦           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tracesèåˆ    â”‚ 100ms    â”‚ 200 MB   â”‚ O(n log n)       â”‚
â”‚  Metricsèåˆ   â”‚ 80ms     â”‚ 150 MB   â”‚ O(n log n)  â”‚
â”‚  Logsèåˆ      â”‚ 120ms    â”‚ 180 MB   â”‚ O(n log n)  â”‚
â”‚  è·¨ç±»å‹èåˆ    â”‚ 300ms    â”‚ 500 MB   â”‚ O(n log n)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ èåˆä¼˜åŒ–ç­–ç•¥

### 1. å¢é‡èåˆç­–ç•¥

```go
// å¢é‡èåˆç­–ç•¥
package main

import (
    "go.opentelemetry.io/otel/trace"
)

type IncrementalMerger struct {
    traces     map[string]*UnifiedTrace
    mutex      sync.Mutex
}

func NewIncrementalMerger() *IncrementalMerger {
    return &IncrementalMerger{
        traces: make(map[string]*UnifiedTrace),
    }
}

func (im *IncrementalMerger) Merge(spans []*trace.Span) []*UnifiedTrace {
    im.mutex.Lock()
    defer im.mutex.Unlock()
    
    // å¢é‡èåˆ
    for _, span := range spans {
        traceID := string(span.TraceId)
        
        // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if existing, ok := im.traces[traceID]; ok {
            // å¢é‡æ›´æ–°
            im.updateTrace(existing, span)
        } else {
            // æ–°å»º
            im.traces[traceID] = im.createTrace(traceID, span)
        }
    }
    
    // è¿”å›æ‰€æœ‰èåˆåçš„trace
    unifiedTraces := make([]*UnifiedTrace, 0, len(im.traces))
    for _, trace := range im.traces {
        unifiedTraces = append(unifiedTraces, trace)
    }
    
    return unifiedTraces
}

func (im *IncrementalMerger) updateTrace(trace *UnifiedTrace, span *trace.Span) {
    // æ·»åŠ span
    trace.Spans = append(trace.Spans, span)
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    trace.TotalSpans++
    if span.Status().Code == trace.StatusCodeError {
        trace.ErrorSpans++
    }
    if span.EndTime().Sub(span.StartTime()) > 1*time.Second {
        trace.SlowSpans++
    }
    
    // æ›´æ–°æ—¶é—´èŒƒå›´
    if span.StartTime().Before(trace.StartTime) {
        trace.StartTime = span.StartTime()
    }
    if span.EndTime().After(trace.EndTimeout) {
        trace.EndTimeout = span.EndTime()
    }
    trace.Duration = trace.EndTimeout.Sub(trace.StartTime)
}

func (im *IncrementalMerger) createTrace(traceID string, span *trace.Span) *UnifiedTrace {
    return &UnifiedTrace{
        TraceID:     traceID,
        Spans:       []*trace.Span{span},
        StartTime:   span.StartTime(),
        EndTimeout:  span.EndTime(),
        Duration:    span.EndTime().Sub(span.StartTime()),
        TotalSpans:  1,
        ErrorSpans:  0,
        SlowSpans:   0,
    }
}
```

### 2. å¹¶è¡Œèåˆç­–ç•¥

```go
// å¹¶è¡Œèåˆç­–ç•¥
package main

import (
    "go.opentelemetry.io/otel/trace"
)

type ParallelMerger struct {
    workerCount int
}

func NewParallelMerger(workerCount int) *ParallelMerger {
    return &ParallelMerger{
        workerCount: workerCount,
    }
}

func (pm *ParallelMerger) Merge(spans []*trace.Span) []*UnifiedTrace {
    // æŒ‰trace_idåˆ†ç»„
    traceMap := make(map[string][]*trace.Span)
    for _, span := range spans {
        traceID := string(span.TraceId)
        traceMap[traceID] = append(traceMap[traceID], span)
    }
    
    // å¹¶è¡Œèåˆ
    results := make(chan *UnifiedTrace, len(traceMap))
    errors := make(chan error, len(traceMap))
    
    for traceID, traceSpans := range traceMap {
        go func(id string, ts []*trace.Span) {
            unified := pm.mergeTrace(id, ts)
            results <- unified
        }(traceID, traceSpans)
    }
    
    // æ”¶é›†ç»“æœ
    unifiedTraces := make([]*UnifiedTrace, 0)
    for i := 0; i < len(traceMap); i++ {
        select {
        case trace := <-results:
            unifiedTraces = append(unifiedTraces, trace)
        case err := <-errors:
            return nil, err
        }
    }
    
    return unifiedTraces
}

func (pm *ParallelMerger) mergeTrace(traceID string, spans []*trace.Span) *UnifiedTrace {
    // æ„å»ºspanæ ‘
    spanTree := buildSpanTree(spans)
    
    // æå–å…³é”®ä¿¡æ¯
    startTime := getEarliestStartTime(spans)
    endTime := getLatestEndTime(spans)
    duration := endTime.Sub(startTime)
    
    // ç»Ÿè®¡ä¿¡æ¯
    totalSpans := len(spans)
    errorSpans := countErrorSpans(spans)
    slowSpans := countSlowSpans(spans, 1*time.Second)
    
    return &UnifiedTrace{
        TraceID:     traceID,
        Spans:       spans,
        SpanTree:    spanTree,
        StartTime:   startTime,
        EndTimeout:  endTime,
        Duration:    duration,
        TotalSpans:  totalSpans,
        ErrorSpans:  errorSpans,
        SlowSpans:   slowSpans,
    }
}
```

### 3. ç¼“å­˜èåˆç­–ç•¥

```go
// ç¼“å­˜èåˆç­–ç•¥
package main

import (
    "go.opentelemetry.io/otel/trace"
    "github.com/patrickmn/go-cache"
)

type CachedMerger struct {
    merger *IncrementalMerger
    cache  *cache.Cache
    mutex  sync.Mutex
}

func NewCachedMerger() *CachedMerger {
    return &CachedMerger{
        merger: NewIncrementalMerger(),
        cache:  cache.New(5*time.Minute, 10*time.Minute),
    }
}

func (cm *CachedMerger) Merge(spans []*trace.Span) []*UnifiedTrace {
    cm.mutex.Lock()
    defer cm.mutex.Unlock()
    
    // æ£€æŸ¥ç¼“å­˜
    cacheKey := generateCacheKey(spans)
    if cached, found := cm.cache.Get(cacheKey); found {
        return cached.([]*UnifiedTrace)
    }
    
    // èåˆ
    unifiedTraces := cm.merger.Merge(spans)
    
    // æ›´æ–°ç¼“å­˜
    cm.cache.Set(cacheKey, unifiedTraces, cache.DefaultExpiration)
    
    return unifiedTraces
}

func generateCacheKey(spans []*trace.Span) string {
    traceIDs := make([]string, 0)
    for _, span := range spans {
        traceIDs = append(traceIDs, string(span.TraceId))
    }
    sort.Strings(traceIDs)
    
    h := sha256.New()
    h.Write([]byte(strings.Join(traceIDs, ",")))
    return hex.EncodeToString(h.Sum(nil))
}
```

---

## ğŸ’¡ å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šç”µå•†ç³»ç»Ÿè¯­ä¹‰èåˆ

```go
// ç”µå•†ç³»ç»Ÿè¯­ä¹‰èåˆ
package main

import (
    "go.opentelemetry.io/otel/trace"
)

type ECommerceSemanticMerger struct {
    traceMerger  *TraceMerger
    metricMerger *MetricMerger
    logMerger    *LogMerger
    mutex        sync.Mutex
}

func NewECommerceSemanticMerger() *ECommerceSemanticMerger {
    return &ECommerceSemanticMerger{
        traceMerger:  NewTraceMerger(),
        metricMerger: NewMetricMerger(),
        logMerger:    NewLogMerger(),
    }
}

func (ecsm *ECommerceSemanticMerger) Merge(spans []*trace.Span, metrics []*metric.Metric, logs []*log.LogRecord) (*ECommerceUnifiedData, error) {
    ecsm.mutex.Lock()
    defer ecsm.mutex.Unlock()
    
    // èåˆTraces
    unifiedTraces := ecsm.traceMerger.Merge(spans)
    
    // èåˆMetrics
    unifiedMetrics := ecsm.metricMerger.Merge(metrics)
    
    // èåˆLogs
    unifiedLogs := ecsm.logMerger.Merge(logs)
    
    // å…³è”æ•°æ®
    correlated := ecsm.correlate(unifiedTraces, unifiedMetrics, unifiedLogs)
    
    return &ECommerceUnifiedData{
        Traces:     unifiedTraces,
        Metrics:    unifiedMetrics,
        Logs:       unifiedLogs,
        Correlated: correlated,
    }, nil
}

func (ecsm *ECommerceSemanticMerger) correlate(traces []*UnifiedTrace, metrics []*UnifiedMetric, logs []*UnifiedLog) map[string]*CorrelatedData {
    correlated := make(map[string]*CorrelatedData)
    
    // æŒ‰trace_idå…³è”
    for _, trace := range traces {
        traceID := trace.TraceID
        
        correlated[traceID] = &CorrelatedData{
            Trace:   trace,
            Metrics: filterMetricsByTraceID(metrics, traceID),
            Logs:    filterLogsByTraceID(logs, traceID),
        }
    }
    
    return correlated
}

type ECommerceUnifiedData struct {
    Traces     []*UnifiedTrace
    Metrics    []*UnifiedMetric
    Logs       []*UnifiedLog
    Correlated map[string]*CorrelatedData
}

type CorrelatedData struct {
    Trace   *UnifiedTrace
    Metrics []*UnifiedMetric
    Logs    []*UnifiedLog
}
```

### æ¡ˆä¾‹2ï¼šé‡‘èç³»ç»Ÿè¯­ä¹‰èåˆ

```go
// é‡‘èç³»ç»Ÿè¯­ä¹‰èåˆ
package main

import (
    "go.opentelemetry.io/otel/trace"
)

type FinancialSemanticMerger struct {
    merger *CachedMerger
    mutex  sync.Mutex
}

func NewFinancialSemanticMerger() *FinancialSemanticMerger {
    return &FinancialSemanticMerger{
        merger: NewCachedMerger(),
    }
}

func (fsm *FinancialSemanticMerger) Merge(spans []*trace.Span) (*FinancialUnifiedData, error) {
    fsm.mutex.Lock()
    defer fsm.mutex.Unlock()
    
    // èåˆTraces
    unifiedTraces := fsm.merger.Merge(spans)
    
    // åˆ†æé‡‘èäº¤æ˜“
    transactions := fsm.analyzeTransactions(unifiedTraces)
    
    // é£é™©è¯„ä¼°
    risks := fsm.assessRisks(transactions)
    
    return &FinancialUnifiedData{
        Traces:      unifiedTraces,
        Transactions: transactions,
        Risks:       risks,
    }, nil
}

func (fsm *FinancialSemanticMerger) analyzeTransactions(traces []*UnifiedTrace) []*Transaction {
    transactions := make([]*Transaction, 0)
    
    for _, trace := range traces {
        // æå–äº¤æ˜“ä¿¡æ¯
        transaction := &Transaction{
            TraceID:    trace.TraceID,
            Amount:     extractAmount(trace),
            Type:       extractType(trace),
            Status:     extractStatus(trace),
            Timestamp:  trace.StartTime,
            Duration:   trace.Duration,
        }
        
        transactions = append(transactions, transaction)
    }
    
    return transactions
}

func (fsm *FinancialSemanticMerger) assessRisks(transactions []*Transaction) []*Risk {
    risks := make([]*Risk, 0)
    
    for _, tx := range transactions {
        // è¯„ä¼°é£é™©
        riskScore := calculateRiskScore(tx)
        
        if riskScore > 0.7 {
            risks = append(risks, &Risk{
                TransactionID: tx.TraceID,
                RiskScore:     riskScore,
                RiskType:      determineRiskType(tx),
                Timestamp:     tx.Timestamp,
            })
        }
    }
    
    return risks
}

type FinancialUnifiedData struct {
    Traces       []*UnifiedTrace
    Transactions []*Transaction
    Risks        []*Risk
}

type Transaction struct {
    TraceID   string
    Amount    float64
    Type      string
    Status    string
    Timestamp time.Time
    Duration  time.Duration
}

type Risk struct {
    TransactionID string
    RiskScore     float64
    RiskType      string
    Timestamp     time.Time
}
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### èåˆä¼˜åŒ–çŸ©é˜µ

```text
èåˆä¼˜åŒ–çŸ©é˜µ:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¼˜åŒ–é¡¹          â”‚ ç­–ç•¥                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¢é‡èåˆ        â”‚ å¢é‡æ›´æ–° (é™ä½å»¶è¿Ÿ)                    â”‚
â”‚  å¹¶è¡Œèåˆ        â”‚ å¹¶è¡Œå¤„ç† (æå‡æ€§èƒ½)                    â”‚
â”‚  ç¼“å­˜èåˆ        â”‚ ç¼“å­˜ç»“æœ (é™ä½è®¡ç®—)                    â”‚
â”‚  æ—¶é—´å¯¹é½        â”‚ æ—¶é—´å¯¹é½ (æå‡å‡†ç¡®æ€§)                   â”‚
â”‚  å±æ€§åŒ¹é…        â”‚ å±æ€§åŒ¹é… (æå‡å…³è”)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ æ€»ç»“

**è¯­ä¹‰æ¨¡å‹èåˆç­–ç•¥**æ˜¯OTLPæ•°æ®åº”ç”¨çš„æ ¸å¿ƒï¼š

1. **èåˆç±»å‹**ï¼šTracesèåˆ + Metricsèåˆ + Logsèåˆ
2. **èåˆç­–ç•¥**ï¼šå¢é‡èåˆ + å¹¶è¡Œèåˆ + ç¼“å­˜èåˆ
3. **èåˆç®—æ³•**ï¼šæ—¶é—´å¯¹é½ + å±æ€§åŒ¹é… + è¯­ä¹‰å…³è”
4. **ä¼˜åŒ–ç­–ç•¥**ï¼šå¹¶è¡Œ + ç¼“å­˜ + å‹ç¼©

**å…³é”®è¦ç‚¹**ï¼š

- âœ… Tracesèåˆæ„å»ºå®Œæ•´é“¾è·¯
- âœ… MetricsèåˆèšåˆæŒ‡æ ‡æ•°æ®
- âœ… Logsèåˆå…³è”æ—¥å¿—ä¿¡æ¯
- âœ… å¢é‡èåˆé™ä½å»¶è¿Ÿ
- âœ… å¹¶è¡Œèåˆæå‡æ€§èƒ½
- âœ… ç¼“å­˜èåˆé™ä½è®¡ç®—
- âœ… æ—¶é—´å¯¹é½æå‡å‡†ç¡®æ€§
- âœ… å±æ€§åŒ¹é…æå‡å…³è”

---

**æœ€åæ›´æ–°**: 2025å¹´10æœˆ11æ—¥  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**ç»´æŠ¤è€…**: OTLPæ·±åº¦æ¢³ç†å›¢é˜Ÿ
