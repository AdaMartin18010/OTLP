# OpenTelemetry éƒ¨ç½²æŒ‡å—

> ğŸ“š **æ–‡æ¡£å¯¼èˆª**: [è¿”å›æ–‡æ¡£ç´¢å¼•](INDEX.md) | [æ¶æ„è®¾è®¡](ARCHITECTURE.md) | [å®‰å…¨æŒ‡å—](SECURITY_GUIDE.md) | [æ•…éšœæ’é™¤](TROUBLESHOOTING.md)
> æœ€åæ›´æ–°: 2025-09-17

## éƒ¨ç½²æ–¹å¼é€‰æ‹©

### 1. æœ¬åœ°éƒ¨ç½²

**é€‚ç”¨åœºæ™¯**: å¼€å‘ã€æµ‹è¯•ã€å°è§„æ¨¡ç”Ÿäº§
**ä¼˜ç‚¹**: ç®€å•ã€å¿«é€Ÿã€æˆæœ¬ä½
**ç¼ºç‚¹**: æ‰©å±•æ€§å·®ã€å¯é æ€§ä½

### 2. å®¹å™¨åŒ–éƒ¨ç½²

**é€‚ç”¨åœºæ™¯**: ä¸­ç­‰è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ
**ä¼˜ç‚¹**: å¯ç§»æ¤ã€æ˜“ç®¡ç†ã€èµ„æºåˆ©ç”¨ç‡é«˜
**ç¼ºç‚¹**: éœ€è¦å®¹å™¨åŒ–çŸ¥è¯†

### 3. Kuberneteséƒ¨ç½²

**é€‚ç”¨åœºæ™¯**: å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ
**ä¼˜ç‚¹**: é«˜å¯ç”¨ã€è‡ªåŠ¨æ‰©å±•ã€æœåŠ¡å‘ç°
**ç¼ºç‚¹**: å¤æ‚åº¦é«˜ã€å­¦ä¹ æˆæœ¬é«˜

### 4. äº‘æœåŠ¡éƒ¨ç½²

**é€‚ç”¨åœºæ™¯**: å¿«é€Ÿéƒ¨ç½²ã€æ‰˜ç®¡æœåŠ¡
**ä¼˜ç‚¹**: å…è¿ç»´ã€é«˜å¯ç”¨ã€å¼¹æ€§æ‰©å±•
**ç¼ºç‚¹**: æˆæœ¬é«˜ã€å‚å•†é”å®š

## æœ¬åœ°éƒ¨ç½²

### 1. ä½¿ç”¨Docker Compose

```yaml
version: '3.8'
services:
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "13133:13133" # Health check
    depends_on:
      - jaeger
      - prometheus

  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14250:14250"
    environment:
      - COLLECTOR_OTLP_ENABLED=true

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
```

### 2. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f otel-collector
```

## å®¹å™¨åŒ–éƒ¨ç½²

### 1. æ„å»ºé•œåƒ

```dockerfile
# Dockerfile
FROM golang:1.21-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN go build -o app .

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /app/app .
CMD ["./app"]
```

### 2. è¿è¡Œå®¹å™¨

```bash
# æ„å»ºé•œåƒ
docker build -t my-app:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name my-app \
  -p 8080:8080 \
  -e OTEL_SERVICE_NAME=my-app \
  -e OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317 \
  my-app:latest
```

## Kuberneteséƒ¨ç½²

### 1. å‘½åç©ºé—´

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: observability
```

### 2. ConfigMap

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: observability
data:
  otel-collector.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
    processors:
      batch:
        timeout: 1s
        send_batch_size: 512
    exporters:
      jaeger:
        endpoint: jaeger:14250
        tls:
          insecure: true
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [jaeger]
```

### 3. Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: observability
spec:
  replicas: 3
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        args:
          - --config=/etc/otel-collector-config.yaml
        volumeMounts:
        - name: config
          mountPath: /etc/otel-collector-config.yaml
          subPath: otel-collector.yaml
        ports:
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 13133
          name: health-check
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
```

### 4. Service

```yaml
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: observability
spec:
  selector:
    app: otel-collector
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  - name: health-check
    port: 13133
    targetPort: 13133
  type: ClusterIP
```

### 5. éƒ¨ç½²åº”ç”¨

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  namespace: default
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: my-app:latest
        ports:
        - containerPort: 8080
        env:
        - name: OTEL_SERVICE_NAME
          value: "my-app"
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: "http://otel-collector.observability.svc.cluster.local:4317"
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
```

## äº‘æœåŠ¡éƒ¨ç½²

### 1. AWSéƒ¨ç½²

```yaml
# ECS Task Definition
{
  "family": "otel-collector",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "256",
  "memory": "512",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "otel-collector",
      "image": "otel/opentelemetry-collector-contrib:latest",
      "portMappings": [
        {
          "containerPort": 4317,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "AWS_REGION",
          "value": "us-west-2"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/otel-collector",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

### 2. GCPéƒ¨ç½²

```yaml
# Cloud Run Service
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: otel-collector
  annotations:
    run.googleapis.com/ingress: all
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/maxScale: "10"
        run.googleapis.com/cpu-throttling: "false"
    spec:
      containers:
      - image: otel/opentelemetry-collector-contrib:latest
        ports:
        - containerPort: 4317
        env:
        - name: GOOGLE_CLOUD_PROJECT
          value: "my-project"
        resources:
          limits:
            cpu: "1"
            memory: "512Mi"
```

## é…ç½®ç®¡ç†

### 1. ç¯å¢ƒå˜é‡

```bash
# åŸºç¡€é…ç½®
export OTEL_SERVICE_NAME="my-service"
export OTEL_SERVICE_VERSION="1.0.0"
export OTEL_RESOURCE_ATTRIBUTES="deployment.environment=production"

# å¯¼å‡ºå™¨é…ç½®
export OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4317"
export OTEL_EXPORTER_OTLP_PROTOCOL="grpc"
export OTEL_EXPORTER_OTLP_INSECURE="true"

# é‡‡æ ·é…ç½®
export OTEL_TRACES_SAMPLER="traceidratio"
export OTEL_TRACES_SAMPLER_ARG="0.1"
```

### 2. é…ç½®æ–‡ä»¶

```yaml
# otel-collector.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 1s
    send_batch_size: 512
  memory_limiter:
    limit_mib: 512

exporters:
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
  prometheus:
    endpoint: "0.0.0.0:8889"

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [jaeger]
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [prometheus]
```

## ç›‘æ§å’Œå‘Šè­¦

### 1. å¥åº·æ£€æŸ¥

```yaml
# Kubernetes Health Check
livenessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  httpGet:
    path: /
    port: 13133
  initialDelaySeconds: 5
  periodSeconds: 5
```

### 2. ç›‘æ§æŒ‡æ ‡

```yaml
# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: otel-collector
  namespace: observability
spec:
  selector:
    matchLabels:
      app: otel-collector
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### 3. å‘Šè­¦è§„åˆ™

```yaml
# PrometheusRule
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: otel-collector-alerts
  namespace: observability
spec:
  groups:
  - name: otel-collector
    rules:
    - alert: OtelCollectorDown
      expr: up{job="otel-collector"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "OpenTelemetry Collector is down"
    
    - alert: HighRefusedSpans
      expr: rate(otelcol_receiver_refused_spans[5m]) > 100
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High number of refused spans"
```

## æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜

- **æœåŠ¡æ— æ³•å¯åŠ¨**: æ£€æŸ¥é…ç½®æ–‡ä»¶å’Œç«¯å£
- **æ•°æ®ä¸¢å¤±**: æ£€æŸ¥é‡‡æ ·é…ç½®å’Œæ‰¹å¤„ç†è®¾ç½®
- **æ€§èƒ½é—®é¢˜**: æ£€æŸ¥èµ„æºé™åˆ¶å’Œç½‘ç»œé…ç½®

### 2. è°ƒè¯•å‘½ä»¤

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get pods -n observability

# æŸ¥çœ‹æ—¥å¿—
kubectl logs -f deployment/otel-collector -n observability

# æ£€æŸ¥é…ç½®
kubectl describe configmap otel-collector-config -n observability

# æµ‹è¯•è¿æ¥
kubectl port-forward svc/otel-collector 4317:4317 -n observability
```

### 3. æ€§èƒ½è°ƒä¼˜

```yaml
# èµ„æºé™åˆ¶
resources:
  requests:
    memory: "512Mi"
    cpu: "200m"
  limits:
    memory: "1Gi"
    cpu: "500m"

# æ‰¹å¤„ç†ä¼˜åŒ–
processors:
  batch:
    timeout: 100ms
    send_batch_size: 1024
    send_batch_max_size: 2048
```

## é«˜çº§éƒ¨ç½²åœºæ™¯

### 1. å¤šç¯å¢ƒéƒ¨ç½²

#### ç¯å¢ƒéš”ç¦»ç­–ç•¥

```yaml
# å¤šç¯å¢ƒé…ç½®
environments:
  development:
    namespace: "otel-dev"
    replicas: 1
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    sampling_rate: 1.0
    retention: "24h"
  
  staging:
    namespace: "otel-staging"
    replicas: 2
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "512Mi"
        cpu: "400m"
    sampling_rate: 0.1
    retention: "7d"
  
  production:
    namespace: "otel-prod"
    replicas: 3
    resources:
      requests:
        memory: "512Mi"
        cpu: "400m"
      limits:
        memory: "1Gi"
        cpu: "800m"
    sampling_rate: 0.01
    retention: "30d"
```

#### ç¯å¢ƒé…ç½®ç®¡ç†

```bash
#!/bin/bash
# deploy-environment.sh

ENVIRONMENT=${1:-"development"}
NAMESPACE="otel-${ENVIRONMENT}"

echo "=== éƒ¨ç½²åˆ° $ENVIRONMENT ç¯å¢ƒ ==="

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# éƒ¨ç½²é…ç½®
kubectl apply -f "configs/${ENVIRONMENT}/" -n $NAMESPACE

# éƒ¨ç½²Collector
kubectl apply -f "deployments/${ENVIRONMENT}/collector.yaml" -n $NAMESPACE

# éƒ¨ç½²åº”ç”¨
kubectl apply -f "deployments/${ENVIRONMENT}/app.yaml" -n $NAMESPACE

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl wait --for=condition=available --timeout=300s deployment/otel-collector -n $NAMESPACE

echo "=== $ENVIRONMENT ç¯å¢ƒéƒ¨ç½²å®Œæˆ ==="
```

### 2. é«˜å¯ç”¨éƒ¨ç½²

#### é›†ç¾¤éƒ¨ç½²é…ç½®

```yaml
# é«˜å¯ç”¨éƒ¨ç½²é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector-ha
  namespace: observability
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - otel-collector
            topologyKey: kubernetes.io/hostname
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        ports:
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 13133
          name: health-check
        resources:
          requests:
            memory: "512Mi"
            cpu: "400m"
          limits:
            memory: "1Gi"
            cpu: "800m"
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 5
          periodSeconds: 5
```

#### è´Ÿè½½å‡è¡¡é…ç½®

```yaml
# è´Ÿè½½å‡è¡¡é…ç½®
apiVersion: v1
kind: Service
metadata:
  name: otel-collector-lb
  namespace: observability
spec:
  selector:
    app: otel-collector
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  type: LoadBalancer
  loadBalancerSourceRanges:
  - 10.0.0.0/8
  - 172.16.0.0/12
  - 192.168.0.0/16
```

### 3. è¾¹ç¼˜éƒ¨ç½²

#### è¾¹ç¼˜èŠ‚ç‚¹é…ç½®

```yaml
# è¾¹ç¼˜èŠ‚ç‚¹é…ç½®
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-collector-edge
  namespace: observability
spec:
  selector:
    matchLabels:
      app: otel-collector-edge
  template:
    metadata:
      labels:
        app: otel-collector-edge
    spec:
      nodeSelector:
        node-role.kubernetes.io/edge: "true"
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        args:
          - --config=/etc/otel-collector-config.yaml
        volumeMounts:
        - name: config
          mountPath: /etc/otel-collector-config.yaml
          subPath: otel-collector.yaml
        - name: data
          mountPath: /var/lib/otel-collector
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        env:
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: "k8s.node.name=$(NODE_NAME),k8s.namespace.name=$(NAMESPACE)"
      volumes:
      - name: config
        configMap:
          name: otel-collector-edge-config
      - name: data
        hostPath:
          path: /var/lib/otel-collector
          type: DirectoryOrCreate
```

#### è¾¹ç¼˜æ•°æ®åŒæ­¥

```yaml
# è¾¹ç¼˜æ•°æ®åŒæ­¥é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-edge-config
  namespace: observability
data:
  otel-collector.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:
      batch:
        timeout: 5s
        send_batch_size: 256
      memory_limiter:
        limit_mib: 128
        spike_limit_mib: 32
    
    exporters:
      otlp:
        endpoint: "https://central-collector.company.com:4317"
        tls:
          insecure: false
          cert_file: /etc/otel/certs/client.crt
          key_file: /etc/otel/certs/client.key
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
      file:
        path: /var/lib/otel-collector/backup.json
        format: json
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [otlp, file]
```

### 4. æ··åˆäº‘éƒ¨ç½²

#### å¤šäº‘éƒ¨ç½²é…ç½®

```yaml
# å¤šäº‘éƒ¨ç½²é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-multicloud
  namespace: observability
data:
  otel-collector.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:
      batch:
        timeout: 1s
        send_batch_size: 512
      resource:
        attributes:
          - key: cloud.provider
            value: "${CLOUD_PROVIDER}"
            action: insert
          - key: cloud.region
            value: "${CLOUD_REGION}"
            action: insert
    
    exporters:
      awsxray:
        region: "${AWS_REGION}"
        role_arn: "${AWS_ROLE_ARN}"
      googlecloud:
        project: "${GCP_PROJECT}"
        location: "${GCP_REGION}"
        credentials_file: "/etc/gcp/credentials.json"
      azuremonitor:
        connection_string: "${AZURE_MONITOR_CONNECTION_STRING}"
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [resource, batch]
          exporters: [awsxray, googlecloud, azuremonitor]
```

#### å¤šäº‘éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy-multicloud.sh

CLOUD_PROVIDER=${1:-"aws"}
ENVIRONMENT=${2:-"production"}

echo "=== éƒ¨ç½²åˆ° $CLOUD_PROVIDER äº‘å¹³å° ==="

case $CLOUD_PROVIDER in
  "aws")
    echo "éƒ¨ç½²åˆ°AWS EKS..."
    eksctl create cluster --name otel-cluster --region us-west-2 --nodes 3
    kubectl apply -f deployments/aws/ -n observability
    ;;
  "gcp")
    echo "éƒ¨ç½²åˆ°GCP GKE..."
    gcloud container clusters create otel-cluster --zone us-central1-a --num-nodes 3
    kubectl apply -f deployments/gcp/ -n observability
    ;;
  "azure")
    echo "éƒ¨ç½²åˆ°Azure AKS..."
    az aks create --resource-group otel-rg --name otel-cluster --node-count 3
    kubectl apply -f deployments/azure/ -n observability
    ;;
  *)
    echo "ä¸æ”¯æŒçš„äº‘å¹³å°: $CLOUD_PROVIDER"
    exit 1
    ;;
esac

echo "=== $CLOUD_PROVIDER äº‘å¹³å°éƒ¨ç½²å®Œæˆ ==="
```

### 5. è‡ªåŠ¨åŒ–éƒ¨ç½²

#### CI/CDæµæ°´çº¿

```yaml
# CI/CDæµæ°´çº¿é…ç½®
name: Deploy OpenTelemetry

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Run tests
      run: |
        go test ./...
        python -m pytest tests/
    
    - name: Run security scan
      run: |
        docker run --rm -v $(pwd):/app securecodewarrior/docker-security-scan /app
    
    - name: Run performance tests
      run: |
        ./benchmarks/run-rust.ps1 -Loops 1000 -SleepMs 0

  deploy-dev:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to development
      run: |
        kubectl apply -f deployments/development/ -n otel-dev
        kubectl rollout status deployment/otel-collector -n otel-dev

  deploy-prod:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to production
      run: |
        kubectl apply -f deployments/production/ -n otel-prod
        kubectl rollout status deployment/otel-collector -n otel-prod
    
    - name: Run smoke tests
      run: |
        ./scripts/smoke-tests.sh
```

#### è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# auto-deploy.sh

ENVIRONMENT=${1:-"development"}
VERSION=${2:-"latest"}

echo "=== è‡ªåŠ¨åŒ–éƒ¨ç½²åˆ° $ENVIRONMENT ç¯å¢ƒ ==="

# æ£€æŸ¥ç¯å¢ƒ
if [ "$ENVIRONMENT" = "production" ]; then
    echo "ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²éœ€è¦ç¡®è®¤..."
    read -p "ç¡®è®¤éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ? (y/N): " confirm
    if [ "$confirm" != "y" ]; then
        echo "å–æ¶ˆéƒ¨ç½²"
        exit 1
    fi
fi

# æ„å»ºé•œåƒ
echo "æ„å»ºé•œåƒ..."
docker build -t otel-collector:$VERSION .

# æ¨é€é•œåƒ
echo "æ¨é€é•œåƒ..."
docker push otel-collector:$VERSION

# æ›´æ–°éƒ¨ç½²
echo "æ›´æ–°éƒ¨ç½²..."
kubectl set image deployment/otel-collector otel-collector=otel-collector:$VERSION -n otel-$ENVIRONMENT

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
echo "ç­‰å¾…éƒ¨ç½²å®Œæˆ..."
kubectl rollout status deployment/otel-collector -n otel-$ENVIRONMENT

# è¿è¡Œå¥åº·æ£€æŸ¥
echo "è¿è¡Œå¥åº·æ£€æŸ¥..."
./scripts/health-check.sh $ENVIRONMENT

# è¿è¡ŒçƒŸé›¾æµ‹è¯•
echo "è¿è¡ŒçƒŸé›¾æµ‹è¯•..."
./scripts/smoke-tests.sh $ENVIRONMENT

echo "=== $ENVIRONMENT ç¯å¢ƒéƒ¨ç½²å®Œæˆ ==="
```

### 6. ç¾éš¾æ¢å¤

#### å¤‡ä»½ç­–ç•¥

```bash
#!/bin/bash
# backup.sh

BACKUP_DIR="/backup/otel-$(date +%Y%m%d-%H%M%S)"
mkdir -p $BACKUP_DIR

echo "=== OpenTelemetry å¤‡ä»½ ==="

# å¤‡ä»½é…ç½®
echo "å¤‡ä»½é…ç½®..."
kubectl get configmaps -n observability -o yaml > $BACKUP_DIR/configmaps.yaml
kubectl get secrets -n observability -o yaml > $BACKUP_DIR/secrets.yaml

# å¤‡ä»½æ•°æ®
echo "å¤‡ä»½æ•°æ®..."
kubectl exec -n observability deployment/jaeger -- tar czf - /data > $BACKUP_DIR/jaeger-data.tar.gz
kubectl exec -n observability deployment/prometheus -- tar czf - /prometheus > $BACKUP_DIR/prometheus-data.tar.gz

# å¤‡ä»½åˆ°äº‘å­˜å‚¨
echo "å¤‡ä»½åˆ°äº‘å­˜å‚¨..."
aws s3 cp $BACKUP_DIR s3://otel-backups/ --recursive

echo "=== å¤‡ä»½å®Œæˆ ==="
```

#### æ¢å¤ç­–ç•¥

```bash
#!/bin/bash
# restore.sh

BACKUP_DATE=${1:-$(date -d "yesterday" +%Y%m%d)}
BACKUP_DIR="/backup/otel-$BACKUP_DATE-*"

echo "=== OpenTelemetry æ¢å¤ ==="

# æ¢å¤é…ç½®
echo "æ¢å¤é…ç½®..."
kubectl apply -f $BACKUP_DIR/configmaps.yaml
kubectl apply -f $BACKUP_DIR/secrets.yaml

# æ¢å¤æ•°æ®
echo "æ¢å¤æ•°æ®..."
kubectl exec -n observability deployment/jaeger -- tar xzf - < $BACKUP_DIR/jaeger-data.tar.gz
kubectl exec -n observability deployment/prometheus -- tar xzf - < $BACKUP_DIR/prometheus-data.tar.gz

# é‡å¯æœåŠ¡
echo "é‡å¯æœåŠ¡..."
kubectl rollout restart deployment/otel-collector -n observability
kubectl rollout restart deployment/jaeger -n observability
kubectl rollout restart deployment/prometheus -n observability

echo "=== æ¢å¤å®Œæˆ ==="
```

## æœ€ä½³å®è·µ

### 1. éƒ¨ç½²ç­–ç•¥

- **è“ç»¿éƒ¨ç½²**: ä½¿ç”¨è“ç»¿éƒ¨ç½²ç­–ç•¥
- **æ»šåŠ¨æ›´æ–°**: æ”¯æŒæ»šåŠ¨æ›´æ–°
- **å›æ»šæœºåˆ¶**: æ”¯æŒå¿«é€Ÿå›æ»š
- **é‡‘ä¸é›€å‘å¸ƒ**: å®æ–½é‡‘ä¸é›€å‘å¸ƒ
- **A/Bæµ‹è¯•**: æ”¯æŒA/Bæµ‹è¯•

### 2. é…ç½®ç®¡ç†

- **ç‰ˆæœ¬æ§åˆ¶**: ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†é…ç½®
- **ç¯å¢ƒéš”ç¦»**: ä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒé…ç½®
- **é…ç½®éªŒè¯**: éƒ¨ç½²å‰éªŒè¯é…ç½®
- **é…ç½®ä¸­å¿ƒ**: ä½¿ç”¨é…ç½®ä¸­å¿ƒç®¡ç†é…ç½®
- **çƒ­é‡è½½**: æ”¯æŒé…ç½®çƒ­é‡è½½

### 3. ç›‘æ§è¿ç»´

- **å¥åº·æ£€æŸ¥**: é…ç½®å¥åº·æ£€æŸ¥
- **ç›‘æ§å‘Šè­¦**: è®¾ç½®ç›‘æ§å’Œå‘Šè­¦
- **æ—¥å¿—ç®¡ç†**: é›†ä¸­ç®¡ç†æ—¥å¿—
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§ç³»ç»Ÿæ€§èƒ½
- **å®¹é‡è§„åˆ’**: è¿›è¡Œå®¹é‡è§„åˆ’

### 4. å®‰å…¨è€ƒè™‘

- **è®¿é—®æ§åˆ¶**: å®æ–½è®¿é—®æ§åˆ¶
- **æ•°æ®åŠ å¯†**: åŠ å¯†æ•æ„Ÿæ•°æ®
- **ç½‘ç»œå®‰å…¨**: é…ç½®ç½‘ç»œå®‰å…¨
- **å®¡è®¡æ—¥å¿—**: è®°å½•å®¡è®¡æ—¥å¿—
- **åˆè§„æ€§**: ç¡®ä¿åˆè§„æ€§

### 5. è‡ªåŠ¨åŒ–

- **CI/CD**: å®æ–½CI/CDæµæ°´çº¿
- **è‡ªåŠ¨åŒ–éƒ¨ç½²**: å®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²
- **è‡ªåŠ¨åŒ–æµ‹è¯•**: å®ç°è‡ªåŠ¨åŒ–æµ‹è¯•
- **è‡ªåŠ¨åŒ–ç›‘æ§**: å®ç°è‡ªåŠ¨åŒ–ç›‘æ§
- **è‡ªåŠ¨åŒ–æ¢å¤**: å®ç°è‡ªåŠ¨åŒ–æ¢å¤
