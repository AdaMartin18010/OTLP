# 📊 OTLP数据模型与语义转换完整指南

> **创建日期**: 2025年10月20日  
> **对标标准**: OTLP v1.3.0 + Semantic Conventions v1.29.0  
> **覆盖范围**: 语义模型 · 数据转换 · 生命周期管理 · 成熟案例

---

## 🎯 核心问题域

本文档全面梳理OTLP标准规定的语义模型，以及数据在整个可观测性系统中的完整生命周期：

```text
数据生命周期完整链路:
┌──────────────────────────────────────────────────────────────┐
│ 用户应用 → 数据收集 → 数据转换 → 数据存储 → 数据处理 → 数据查询  │
└──────────────────────────────────────────────────────────────┘
    ↓          ↓          ↓          ↓          ↓          ↓
  自定义    SDK标准化   Collector   后端选择   实时/批处理  分析展现
  业务模型   →语义约定   转换器      存储引擎    聚合计算    可视化
```

---

## 第一部分：OTLP标准语义模型完整梳理

### 1.1 语义模型层次结构

#### 1.1.1 三层语义模型

```text
┌─────────────────────────────────────────────────────────────┐
│                  OTLP语义模型完整体系                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  📊 第一层：资源模型 (Resource Model)                       │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│  定义：描述遥测数据来源的静态属性                            │
│  生命周期：进程级别，启动时确定，运行期不变                    │
│                                                             │
│  Resource = ⟨                                               │
│    service.name: string          (必需)                     │
│    service.version: string       (推荐)                     │
│    service.namespace: string     (可选)                     │
│    service.instance.id: string   (推荐)                     │
│    deployment.environment: string (推荐)                    │
│    telemetry.sdk.name: string    (必需)                     │
│    telemetry.sdk.version: string (必需)                     │
│    + 平台属性 (host.*, container.*, k8s.*, cloud.*)         │
│  ⟩                                                          │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  📈 第二层：仪器化作用域 (Instrumentation Scope)             │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│  定义：遥测数据的生产者标识                                  │
│  用途：区分不同库、框架、自动仪器化的数据                      │
│                                                             │
│  InstrumentationScope = ⟨                                   │
│    name: string           (必需) 如 "io.opentelemetry.api"  │
│    version: string        (可选) 如 "1.30.0"                │
│    schema_url: string     (可选) 语义约定版本URL              │
│    attributes: Map[K,V]   (可选) 作用域级别属性               │
│  ⟩                                                          │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  📊 第三层：遥测数据模型 (Telemetry Data Model)              │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│  三种信号类型，各有独立的数据模型                            │
│                                                             │
│  1️⃣ Trace Model (链路追踪)                                │
│     Span = ⟨trace_id, span_id, parent_span_id, name,       │
│              start_time, end_time, attributes, events,      │
│              links, status⟩                                 │
│                                                             │
│  2️⃣ Metric Model (指标数据)                               │
│     Metric = ⟨name, description, unit, type,               │
│                data_points[]⟩                               │
│     类型: Sum, Gauge, Histogram, ExponentialHistogram       │
│                                                             │
│  3️⃣ Log Model (日志记录)                                  │
│     LogRecord = ⟨timestamp, observed_timestamp,            │
│                   severity_number, severity_text, body,     │
│                   attributes, trace_id, span_id⟩            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 标准规定的语义约定梳理

#### 1.2.1 HTTP语义约定 (v1.29.0)

**客户端 Span 属性**:

| 属性名 | 类型 | 必需性 | 示例值 | 说明 |
|-------|------|-------|-------|------|
| `http.request.method` | string | Required | "GET" | HTTP方法 |
| `server.address` | string | Required | "api.example.com" | 服务器地址 |
| `server.port` | int | Conditional | 443 | 服务器端口 |
| `url.full` | string | Required | "<https://api.example.com/v1/users>" | 完整URL |
| `url.scheme` | string | Required | "https" | URL协议 |
| `url.path` | string | Required | "/v1/users" | URL路径 |
| `http.response.status_code` | int | Recommended | 200 | 响应状态码 |
| `http.request.body.size` | int | Optional | 1024 | 请求体大小 |
| `http.response.body.size` | int | Optional | 2048 | 响应体大小 |
| `network.protocol.version` | string | Recommended | "1.1" | HTTP版本 |
| `user_agent.original` | string | Recommended | "Mozilla/5.0..." | User-Agent |

**服务端 Span 属性**:

| 属性名 | 类型 | 必需性 | 示例值 | 说明 |
|-------|------|-------|-------|------|
| `http.request.method` | string | Required | "POST" | HTTP方法 |
| `http.route` | string | Required | "/api/users/{id}" | 路由模板 |
| `url.path` | string | Required | "/api/users/123" | 实际路径 |
| `url.scheme` | string | Required | "https" | 协议 |
| `server.address` | string | Recommended | "0.0.0.0" | 监听地址 |
| `server.port` | int | Recommended | 8080 | 监听端口 |
| `client.address` | string | Conditional | "192.168.1.100" | 客户端IP |
| `http.response.status_code` | int | Recommended | 201 | 响应状态码 |

#### 1.2.2 数据库语义约定 (v1.29.0)

**通用数据库属性**:

| 属性名 | 类型 | 必需性 | 枚举值/示例 | 说明 |
|-------|------|-------|-----------|------|
| `db.system` | string | Required | "postgresql", "mysql", "mongodb", "redis" | 数据库类型 |
| `db.name` | string | Recommended | "mydb" | 数据库名 |
| `db.operation` | string | Recommended | "SELECT", "INSERT", "UPDATE", "find" | 操作类型 |
| `db.statement` | string | Recommended | "SELECT * FROM users WHERE id = ?" | SQL语句(需脱敏) |
| `server.address` | string | Conditional | "db.example.com" | 数据库服务器 |
| `server.port` | int | Conditional | 5432 | 端口 |
| `network.peer.address` | string | Recommended | "10.0.0.5" | 对端地址 |

**SQL特定属性**:

| 属性名 | 类型 | 必需性 | 示例值 | 说明 |
|-------|------|-------|-------|------|
| `db.sql.table` | string | Recommended | "users" | 表名 |
| `db.operation.batch` | boolean | Optional | true | 是否批量操作(v1.29.0新增) |

**NoSQL特定属性 (MongoDB)**:

| 属性名 | 类型 | 必需性 | 示例值 | 说明 |
|-------|------|-------|-------|------|
| `db.mongodb.collection` | string | Required | "users" | 集合名 |
| `db.operation` | string | Required | "find", "insert", "update" | 操作类型 |

#### 1.2.3 消息队列语义约定 (v1.29.0)

**Kafka特定属性**:

| 属性名 | 类型 | 必需性 | 示例值 | 说明 |
|-------|------|-------|-------|------|
| `messaging.system` | string | Required | "kafka" | 消息系统 |
| `messaging.destination.name` | string | Required | "orders" | Topic名称 |
| `messaging.operation` | string | Required | "publish", "receive", "process" | 操作类型 |
| `messaging.message.id` | string | Recommended | "msg-123456" | 消息ID |
| `kafka.message.key` | string | Recommended | "order-001" | 消息Key |
| `kafka.consumer.group` | string | Conditional | "order-processor" | 消费组 |
| `kafka.partition` | int | Recommended | 3 | 分区号 |
| `kafka.offset` | int | Recommended | 12345 | Offset |

---

## 第二部分：自定义数据模型设计

### 2.1 用户自定义属性的设计原则

#### 2.1.1 命名空间规范

**标准要求**:

```text
自定义属性必须使用vendor前缀，避免与标准属性冲突:

格式: <vendor>.<domain>.<attribute>

✅ 正确示例:
- mycompany.order.priority: "high"
- acme.payment.method: "credit_card"
- shopify.cart.item_count: 5

❌ 错误示例:
- order.priority  (无vendor前缀，可能冲突)
- OrderPriority   (不符合命名风格)
- order-priority  (应该用下划线)
```

#### 2.1.2 业务领域数据模型案例

**案例1: 电商订单追踪**:

```yaml
# 自定义语义约定定义
namespace: myshop.order

attributes:
  # 订单基本信息
  myshop.order.id:
    type: string
    requirement: required
    description: 订单唯一标识
    example: "ORDER-2024-001234"
    
  myshop.order.status:
    type: enum
    requirement: required
    values: ["pending", "paid", "shipped", "delivered", "cancelled"]
    description: 订单状态
    
  myshop.order.total_amount:
    type: double
    requirement: required
    description: 订单总金额(USD)
    example: 99.99
    
  myshop.order.item_count:
    type: int
    requirement: recommended
    description: 订单商品数量
    example: 3
    
  # 用户信息
  myshop.user.tier:
    type: enum
    requirement: recommended
    values: ["free", "silver", "gold", "platinum"]
    description: 用户等级
    
  myshop.user.segment:
    type: string
    requirement: optional
    description: 用户细分标签
    example: "high_value_customer"
    
  # 促销信息
  myshop.promotion.code:
    type: string
    requirement: optional
    description: 促销码
    example: "SUMMER2024"
    
  myshop.promotion.discount_percent:
    type: double
    requirement: conditional
    description: 折扣百分比
    example: 20.0
```

**应用到Span**:

```go
// Go SDK 实现
import (
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
)

func ProcessOrder(ctx context.Context, order Order) error {
    tracer := otel.Tracer("myshop.order-service")
    
    ctx, span := tracer.Start(ctx, "process_order",
        trace.WithAttributes(
            // 标准HTTP属性
            attribute.String("http.request.method", "POST"),
            attribute.String("http.route", "/api/orders"),
            attribute.Int("http.response.status_code", 201),
            
            // 自定义业务属性
            attribute.String("myshop.order.id", order.ID),
            attribute.String("myshop.order.status", string(order.Status)),
            attribute.Float64("myshop.order.total_amount", order.TotalAmount),
            attribute.Int("myshop.order.item_count", len(order.Items)),
            attribute.String("myshop.user.tier", string(order.User.Tier)),
            
            // 条件属性
            attribute.String("myshop.promotion.code", 
                order.PromotionCode), // 仅当有促销时
        ),
    )
    defer span.End()
    
    // 业务逻辑...
    
    return nil
}
```

**案例2: 金融交易追踪**:

```yaml
namespace: fintech.transaction

attributes:
  # 交易核心属性
  fintech.transaction.id:
    type: string
    requirement: required
    description: 交易唯一ID
    example: "TXN-20241020-123456"
    
  fintech.transaction.type:
    type: enum
    requirement: required
    values: ["payment", "refund", "transfer", "withdrawal"]
    description: 交易类型
    
  fintech.transaction.amount:
    type: double
    requirement: required
    description: 交易金额
    example: 1500.00
    
  fintech.transaction.currency:
    type: string
    requirement: required
    description: 货币代码(ISO 4217)
    example: "USD"
    
  # 风控属性
  fintech.risk.score:
    type: double
    requirement: recommended
    description: 风险评分(0-100)
    example: 25.5
    
  fintech.risk.level:
    type: enum
    requirement: recommended
    values: ["low", "medium", "high", "critical"]
    description: 风险等级
    
  fintech.fraud.detected:
    type: boolean
    requirement: conditional
    description: 是否检测到欺诈
    example: false
    
  # 合规属性
  fintech.compliance.aml_check:
    type: boolean
    requirement: required
    description: 是否完成反洗钱检查
    example: true
    
  fintech.compliance.kyc_verified:
    type: boolean
    requirement: required
    description: KYC验证状态
    example: true
```

---

## 第三部分：数据生命周期完整流程

### 3.1 数据收集阶段

#### 3.1.1 SDK自动收集 vs 手动埋点

**自动收集** (通过Auto-instrumentation):

```python
# Python - 自动仪器化示例
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor

# 自动收集HTTP请求
FlaskInstrumentor().instrument_app(app)

# 自动收集外部HTTP调用
RequestsInstrumentor().instrument()

# 自动收集数据库查询
SQLAlchemyInstrumentor().instrument(engine=engine)

# 以上代码自动生成标准语义约定的属性:
# - http.request.method
# - http.response.status_code
# - db.system
# - db.statement
# 等等...
```

**手动埋点** (自定义业务属性):

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

@app.route('/api/orders', methods=['POST'])
def create_order():
    with tracer.start_as_current_span(
        "create_order",
        attributes={
            # 标准属性(自动仪器化已添加):
            # "http.request.method": "POST"
            # "http.route": "/api/orders"
            
            # 手动添加业务属性:
            "myshop.order.id": order_id,
            "myshop.order.total_amount": total_amount,
            "myshop.user.tier": user_tier,
        }
    ) as span:
        # 业务逻辑
        order = process_order(data)
        
        # 动态添加属性
        span.set_attribute("myshop.order.status", order.status)
        
        # 记录事件
        span.add_event(
            "order_created",
            attributes={
                "myshop.order.id": order.id,
                "myshop.order.item_count": len(order.items)
            }
        )
        
        return order
```

### 3.2 数据转换阶段 (Collector Pipeline)

#### 3.2.1 Collector处理流程

```yaml
# OpenTelemetry Collector 配置
# 数据转换和丰富化

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317

processors:
  # 1. 批处理 - 性能优化
  batch:
    timeout: 1s
    send_batch_size: 512
    
  # 2. 资源检测 - 自动添加云平台属性
  resourcedetection:
    detectors: [env, system, docker, ec2, ecs, gcp, azure]
    timeout: 5s
    
  # 3. 属性处理 - 数据转换和清洗
  attributes:
    actions:
      # 重命名属性
      - key: http.method
        action: update
        from_attribute: http.request.method
        
      # 删除敏感属性
      - key: http.request.header.authorization
        action: delete
        
      # 哈希化PII
      - key: user.email
        action: hash
        
      # 添加固定属性
      - key: deployment.environment
        action: insert
        value: "production"
        
  # 4. 资源处理 - 合并资源属性
  resource:
    attributes:
      - key: service.namespace
        value: "mycompany"
        action: insert
        
  # 5. 数据过滤 - 采样和过滤
  filter:
    traces:
      span:
        # 只保留错误trace和慢trace
        - 'attributes["http.response.status_code"] >= 400'
        - 'duration > 2000000000'  # > 2秒
        
  # 6. Span Metrics - 从Trace生成Metrics
  spanmetrics:
    metrics_exporter: prometheus
    latency_histogram_buckets: [2ms, 4ms, 6ms, 8ms, 10ms, 50ms, 100ms]
    dimensions:
      - name: http.method
      - name: http.status_code
      - name: myshop.user.tier  # 自定义维度
        
  # 7. Tail Sampling - 尾部采样
  tail_sampling:
    decision_wait: 10s
    policies:
      # 所有错误trace
      - name: error-policy
        type: status_code
        status_code: {status_codes: [ERROR]}
        
      # 慢trace
      - name: slow-trace-policy
        type: latency
        latency: {threshold_ms: 2000}
        
      # 按业务属性采样
      - name: vip-user-policy
        type: attribute
        attribute: {key: myshop.user.tier, values: [platinum, gold]}

exporters:
  # 导出到多个后端
  otlp/jaeger:
    endpoint: jaeger:4317
    
  prometheusremotewrite:
    endpoint: http://prometheus:9090/api/v1/write
    
  elasticsearch:
    endpoints: [http://elasticsearch:9200]
    logs_index: logs-otlp
    
  kafka:
    brokers: [kafka:9092]
    topic: otlp-traces

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [resourcedetection, attributes, resource, 
                   tail_sampling, spanmetrics, batch]
      exporters: [otlp/jaeger, kafka]
      
    metrics:
      receivers: [otlp]
      processors: [resourcedetection, batch]
      exporters: [prometheusremotewrite]
      
    logs:
      receivers: [otlp]
      processors: [resourcedetection, attributes, batch]
      exporters: [elasticsearch]
```

#### 3.2.2 数据转换逻辑示例

**场景: 将自定义属性转换为标准指标**:

```yaml
# Collector配置 - 从Trace属性生成Metric
processors:
  spanmetrics:
    metrics_exporter: prometheus
    
    # 生成延迟直方图
    latency_histogram_buckets: [10ms, 50ms, 100ms, 500ms, 1s, 5s]
    
    # 维度配置
    dimensions:
      # 标准维度
      - name: http.method
      - name: http.status_code
      - name: service.name
      
      # 自定义业务维度
      - name: myshop.order.status
      - name: myshop.user.tier
      - name: myshop.promotion.code
        
    # 生成的Metric名称
    # calls_total{http_method="GET", http_status_code="200", 
    #             myshop_user_tier="gold"} 1234
    # duration_milliseconds_sum{...} 5678.9
    # duration_milliseconds_count{...} 100
```

**生成的Prometheus Metrics**:

```promql
# 按用户等级统计订单处理延迟
histogram_quantile(0.95, 
  sum(rate(duration_milliseconds_bucket{
    service_name="order-service",
    myshop_user_tier="gold"
  }[5m])) by (le)
)

# 按促销活动统计订单量
sum(rate(calls_total{
  myshop_promotion_code!=""
}[5m])) by (myshop_promotion_code)

# VIP用户错误率
sum(rate(calls_total{
  myshop_user_tier=~"gold|platinum",
  http_status_code=~"5.."
}[5m])) 
/ 
sum(rate(calls_total{
  myshop_user_tier=~"gold|platinum"
}[5m]))
```

---

### 3.3 数据存储阶段

#### 3.3.1 不同后端的数据模型映射

**Elasticsearch (日志存储)**:

```json
{
  "_index": "traces-2024.10.20",
  "_id": "span-123456",
  "_source": {
    // 标准OTLP字段
    "trace_id": "4bf92f3577b34da6a3ce929d0e0e4736",
    "span_id": "00f067aa0ba902b7",
    "parent_span_id": "00f067aa0ba902b6",
    "name": "POST /api/orders",
    "kind": "SERVER",
    "start_time": "2024-10-20T10:30:00.000Z",
    "end_time": "2024-10-20T10:30:00.250Z",
    "duration_ms": 250,
    "status": {
      "code": "OK"
    },
    
    // Resource属性
    "resource": {
      "service.name": "order-service",
      "service.version": "1.2.3",
      "deployment.environment": "production",
      "host.name": "prod-server-01",
      "k8s.pod.name": "order-service-7d4f8b9c-xk2lp"
    },
    
    // Span属性 (标准 + 自定义)
    "attributes": {
      // 标准HTTP属性
      "http.request.method": "POST",
      "http.route": "/api/orders",
      "http.response.status_code": 201,
      "server.address": "api.myshop.com",
      
      // 自定义业务属性
      "myshop.order.id": "ORDER-2024-001234",
      "myshop.order.status": "pending",
      "myshop.order.total_amount": 99.99,
      "myshop.order.item_count": 3,
      "myshop.user.tier": "gold",
      "myshop.promotion.code": "SUMMER2024"
    },
    
    // Events
    "events": [
      {
        "name": "order_validation_complete",
        "timestamp": "2024-10-20T10:30:00.050Z",
        "attributes": {
          "validation.result": "success"
        }
      }
    ]
  }
}
```

**ClickHouse (OLAP分析)**:

```sql
-- ClickHouse表结构设计
CREATE TABLE traces (
    -- 时间分区键
    date Date DEFAULT toDate(start_time),
    
    -- 标准OTLP字段
    trace_id String,
    span_id String,
    parent_span_id String,
    name LowCardinality(String),
    kind Enum8('INTERNAL'=1, 'SERVER'=2, 'CLIENT'=3, 'PRODUCER'=4, 'CONSUMER'=5),
    start_time DateTime64(9),
    end_time DateTime64(9),
    duration_ns UInt64,
    status_code Enum8('UNSET'=0, 'OK'=1, 'ERROR'=2),
    
    -- Resource属性 (扁平化)
    service_name LowCardinality(String),
    service_version LowCardinality(String),
    deployment_environment LowCardinality(String),
    host_name LowCardinality(String),
    k8s_pod_name String,
    
    -- 标准Span属性
    http_method LowCardinality(String),
    http_route LowCardinality(String),
    http_status_code UInt16,
    
    -- 自定义业务属性 (扁平化为列)
    myshop_order_id String,
    myshop_order_status LowCardinality(String),
    myshop_order_total_amount Decimal(10,2),
    myshop_order_item_count UInt8,
    myshop_user_tier LowCardinality(String),
    myshop_promotion_code LowCardinality(String),
    
    -- 原始属性(JSON，用于灵活查询)
    attributes Map(String, String),
    
    -- 索引
    INDEX idx_trace_id trace_id TYPE bloom_filter GRANULARITY 1,
    INDEX idx_order_id myshop_order_id TYPE bloom_filter GRANULARITY 1
    
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (service_name, date, start_time)
TTL date + INTERVAL 90 DAY;
```

**查询示例**:

```sql
-- 1. 按用户等级统计P95延迟
SELECT
    myshop_user_tier,
    quantile(0.95)(duration_ns / 1000000) as p95_latency_ms
FROM traces
WHERE date >= today() - 7
  AND service_name = 'order-service'
GROUP BY myshop_user_tier
ORDER BY p95_latency_ms DESC;

-- 2. 促销活动转化漏斗
SELECT
    myshop_promotion_code,
    countIf(name = 'add_to_cart') as step1_add_to_cart,
    countIf(name = 'checkout') as step2_checkout,
    countIf(name = 'payment') as step3_payment,
    countIf(myshop_order_status = 'paid') as step4_paid,
    step4_paid / step1_add_to_cart as conversion_rate
FROM traces
WHERE date = today()
  AND myshop_promotion_code != ''
GROUP BY myshop_promotion_code
ORDER BY conversion_rate DESC;

-- 3. 错误率按订单金额分段
SELECT
    multiIf(
        myshop_order_total_amount < 50, '<$50',
        myshop_order_total_amount < 100, '$50-$100',
        myshop_order_total_amount < 500, '$100-$500',
        '>$500'
    ) as amount_range,
    countIf(status_code = 'ERROR') / count() as error_rate
FROM traces
WHERE date >= today() - 1
  AND service_name = 'order-service'
GROUP BY amount_range
ORDER BY error_rate DESC;
```

---

### 3.4 数据处理阶段

#### 3.4.1 实时流处理 (Apache Flink)

```java
// Flink实时处理OTLP数据
StreamExecutionEnvironment env = 
    StreamExecutionEnvironment.getExecutionEnvironment();

// 从Kafka读取OTLP Traces
DataStream<Span> spans = env
    .addSource(new FlinkKafkaConsumer<>(
        "otlp-traces",
        new SpanDeserializationSchema(),
        kafkaProps
    ))
    .name("otlp-trace-source");

// 实时计算业务指标
DataStream<OrderMetric> orderMetrics = spans
    .filter(span -> span.getName().equals("process_order"))
    .keyBy(span -> span.getAttribute("myshop.user.tier"))
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .aggregate(new OrderAggregateFunction())
    .name("order-metrics-by-tier");

// 异常检测
DataStream<Alert> alerts = orderMetrics
    .filter(metric -> {
        // 检测VIP用户的异常
        if (metric.getUserTier().equals("platinum") ||
            metric.getUserTier().equals("gold")) {
            return metric.getErrorRate() > 0.01  // 错误率>1%
                || metric.getP95Latency() > 2000; // P95>2s
        }
        return false;
    })
    .map(metric -> new Alert(
        AlertLevel.HIGH,
        String.format("VIP用户%s异常: 错误率%.2f%%, P95延迟%dms",
            metric.getUserTier(),
            metric.getErrorRate() * 100,
            metric.getP95Latency())
    ))
    .name("vip-user-alerts");

// 输出到告警系统
alerts.addSink(new PagerDutySink()).name("alerting");

env.execute("OTLP Real-time Processing");
```

#### 3.4.2 批处理分析 (Apache Spark)

```python
# Spark批处理OTLP数据
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

spark = SparkSession.builder.appName("OTLP-Analysis").getOrCreate()

# 读取ClickHouse数据
traces_df = spark.read \
    .format("jdbc") \
    .option("url", "jdbc:clickhouse://clickhouse:8123/default") \
    .option("dbtable", "traces") \
    .load()

# 分析1: 用户行为分析
user_behavior = traces_df \
    .filter(F.col("service_name") == "order-service") \
    .groupBy("myshop_user_tier", "myshop_order_status") \
    .agg(
        F.count("*").alias("order_count"),
        F.avg("myshop_order_total_amount").alias("avg_amount"),
        F.sum("myshop_order_total_amount").alias("total_revenue"),
        F.avg("duration_ns").alias("avg_latency_ns")
    ) \
    .orderBy(F.desc("total_revenue"))

# 分析2: 促销效果分析
promotion_analysis = traces_df \
    .filter(F.col("myshop_promotion_code").isNotNull()) \
    .groupBy("myshop_promotion_code") \
    .agg(
        F.countDistinct("myshop_order_id").alias("orders_with_promo"),
        F.sum("myshop_order_total_amount").alias("revenue_with_promo"),
        F.avg("myshop_order_total_amount").alias("avg_order_value"),
        F.count(F.when(F.col("status_code") == "ERROR", 1)).alias("error_count")
    ) \
    .withColumn("error_rate", 
        F.col("error_count") / F.col("orders_with_promo"))

# 分析3: 服务依赖图构建
service_dependencies = traces_df \
    .join(
        traces_df.alias("parent"),
        F.col("parent_span_id") == F.col("parent.span_id")
    ) \
    .select(
        F.col("parent.service_name").alias("from_service"),
        F.col("service_name").alias("to_service"),
        F.count("*").alias("call_count"),
        F.avg("duration_ns").alias("avg_latency"),
        F.count(F.when(F.col("status_code") == "ERROR", 1))
            .alias("error_count")
    ) \
    .groupBy("from_service", "to_service") \
    .agg(
        F.sum("call_count").alias("total_calls"),
        F.avg("avg_latency").alias("avg_latency"),
        F.sum("error_count").alias("total_errors")
    )

# 输出结果
user_behavior.write.mode("overwrite").saveAsTable("analytics.user_behavior")
promotion_analysis.write.mode("overwrite").saveAsTable("analytics.promotions")
service_dependencies.write.mode("overwrite").saveAsTable("analytics.dependencies")
```

---

### 3.5 数据查询与分析

#### 3.5.1 多维分析查询

**Grafana Dashboard配置**:

```yaml
# Grafana Dashboard JSON
{
  "dashboard": {
    "title": "业务指标监控 - 电商订单",
    "panels": [
      {
        "title": "按用户等级的订单量",
        "targets": [{
          "expr": "sum(rate(calls_total{service_name=\"order-service\"}[5m])) by (myshop_user_tier)",
          "legendFormat": "{{myshop_user_tier}}"
        }],
        "type": "graph"
      },
      {
        "title": "VIP用户P95延迟",
        "targets": [{
          "expr": "histogram_quantile(0.95, sum(rate(duration_milliseconds_bucket{service_name=\"order-service\", myshop_user_tier=~\"gold|platinum\"}[5m])) by (le, myshop_user_tier))",
          "legendFormat": "{{myshop_user_tier}}"
        }],
        "type": "graph"
      },
      {
        "title": "促销活动效果",
        "targets": [{
          "expr": "topk(10, sum(rate(calls_total{myshop_promotion_code!=\"\"}[1h])) by (myshop_promotion_code))",
          "legendFormat": "{{myshop_promotion_code}}"
        }],
        "type": "barchart"
      }
    ]
  }
}
```

**Kibana查询 (Elasticsearch)**:

```json
{
  "query": {
    "bool": {
      "must": [
        {"term": {"resource.service.name": "order-service"}},
        {"range": {"start_time": {"gte": "now-1h"}}},
        {"term": {"attributes.myshop.user.tier": "platinum"}}
      ],
      "filter": [
        {"range": {"attributes.myshop.order.total_amount": {"gte": 500}}}
      ]
    }
  },
  "aggs": {
    "by_status": {
      "terms": {"field": "attributes.myshop.order.status"},
      "aggs": {
        "avg_amount": {
          "avg": {"field": "attributes.myshop.order.total_amount"}
        },
        "p95_latency": {
          "percentiles": {
            "field": "duration_ms",
            "percents": [95]
          }
        }
      }
    }
  }
}
```

---

## 第四部分：成熟案例深度剖析

### 4.1 案例1: Uber的分布式追踪系统

#### 4.1.1 数据模型设计

**Uber自定义语义约定**:

```yaml
namespace: uber

# 出行业务属性
attributes:
  uber.trip.id:
    type: string
    requirement: required
    description: 行程唯一标识
    
  uber.trip.type:
    type: enum
    values: ["uberx", "uber_black", "uber_pool", "uber_eats"]
    requirement: required
    
  uber.trip.distance_km:
    type: double
    requirement: required
    description: 行程距离(公里)
    
  uber.trip.duration_seconds:
    type: int
    requirement: required
    
  uber.driver.id:
    type: string
    requirement: required
    description: 司机ID(哈希化)
    
  uber.rider.tier:
    type: enum
    values: ["basic", "gold", "platinum", "diamond"]
    requirement: recommended
    
  uber.pricing.surge_multiplier:
    type: double
    requirement: optional
    description: 动态定价倍数
    example: 1.5
```

#### 4.1.2 数据处理流程

```text
┌──────────────────────────────────────────────────────────────┐
│                  Uber OTLP数据处理流程                        │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  1️⃣ 数据收集 (每天50亿+ Spans)                             │
│     ├─ 移动端SDK (Rider/Driver App)                         │
│     ├─ 后端服务 (微服务架构, 2000+服务)                      │
│     └─ 边缘节点 (全球100+数据中心)                           │
│                                                              │
│  2️⃣ 数据聚合 (Regional Collector)                          │
│     ├─ 实时采样 (Head-based: 1%)                            │
│     ├─ 尾部采样 (Tail-based: 保留所有异常)                  │
│     └─ 属性标准化                                            │
│                                                              │
│  3️⃣ 数据转换 (Central Pipeline)                            │
│     ├─ Span → Metric 转换                                   │
│     │   └─ trip_duration{type="uberx", tier="gold"}         │
│     ├─ 业务事件提取                                          │
│     │   └─ trip_started, trip_completed, payment_processed  │
│     └─ 异常检测                                              │
│         └─ ML模型预测异常行程                                │
│                                                              │
│  4️⃣ 数据存储 (多层存储)                                    │
│     ├─ 热数据 (最近7天) → Cassandra                         │
│     ├─ 温数据 (7-30天) → HDFS + Parquet                     │
│     └─ 冷数据 (>30天) → S3 Glacier                          │
│                                                              │
│  5️⃣ 数据分析                                               │
│     ├─ 实时监控 (Grafana + Prometheus)                      │
│     ├─ Ad-hoc查询 (Presto)                                  │
│     ├─ ML训练 (Spark MLlib)                                 │
│     └─ 业务BI (自研BI平台)                                   │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

#### 4.1.3 关键优化

**1. 智能采样**:

```go
// Uber的自适应采样算法
func ShouldSample(span Span) bool {
    // 1. 所有错误必须采样
    if span.Status == ERROR {
        return true
    }
    
    // 2. VIP用户更高采样率
    tier := span.Attribute("uber.rider.tier")
    if tier == "diamond" {
        return rand.Float64() < 0.50  // 50%
    } else if tier == "platinum" {
        return rand.Float64() < 0.20  // 20%
    }
    
    // 3. 高价值行程
    surgeMultiplier := span.Attribute("uber.pricing.surge_multiplier")
    if surgeMultiplier > 2.0 {
        return true  // 100%
    }
    
    // 4. 长距离行程
    distance := span.Attribute("uber.trip.distance_km")
    if distance > 50 {
        return rand.Float64() < 0.30  // 30%
    }
    
    // 5. 默认低采样率
    return rand.Float64() < 0.01  // 1%
}
```

**2. 成本优化**:

- 采样后数据量减少99%
- 存储成本: $500K/月 → $5K/月
- 但保留了99.9%的关键信息(错误、VIP、异常)

---

### 4.2 案例2: Shopify的电商可观测性

#### 4.2.1 数据模型设计

```yaml
namespace: shopify

# 店铺属性
attributes:
  shopify.shop.id:
    type: string
    requirement: required
    description: 店铺ID
    
  shopify.shop.plan:
    type: enum
    values: ["basic", "shopify", "advanced", "plus"]
    requirement: required
    
  # 商品属性
  shopify.product.id:
    type: string
    requirement: conditional
    
  shopify.product.variant_id:
    type: string
    requirement: conditional
    
  shopify.product.price:
    type: double
    requirement: conditional
    
  # 订单属性
  shopify.order.id:
    type: string
    requirement: required
    
  shopify.order.total:
    type: double
    requirement: required
    
  shopify.order.currency:
    type: string
    requirement: required
    example: "USD"
    
  shopify.order.fulfillment_status:
    type: enum
    values: ["unfulfilled", "partial", "fulfilled"]
    requirement: recommended
    
  # 营销属性
  shopify.checkout.abandoned:
    type: boolean
    requirement: optional
    description: 购物车是否遗弃
    
  shopify.discount.code:
    type: string
    requirement: optional
```

#### 4.2.2 数据分析场景

**实时监控Dashboard**:

```promql
# 1. 按店铺等级的GMV
sum(rate(shopify_order_total_sum[5m])) by (shopify_shop_plan)

# 2. Plus店铺的转化率
sum(rate(shopify_order_created_total{shopify_shop_plan="plus"}[5m]))
/
sum(rate(shopify_checkout_started_total{shopify_shop_plan="plus"}[5m]))

# 3. 购物车遗弃率
sum(rate(shopify_checkout_abandoned_total[5m]))
/
sum(rate(shopify_checkout_started_total[5m]))

# 4. 折扣码使用效果
topk(10,
  sum(rate(shopify_order_total_sum{shopify_discount_code!=""}[1h]))
  by (shopify_discount_code)
)
```

---

## 第五部分：最佳实践总结

### 5.1 数据模型设计原则

#### ✅ DO (推荐做法)

1. **优先使用标准语义约定**

   ```yaml
   # ✅ 好
   http.request.method: "POST"
   http.response.status_code: 200
   
   # ❌ 坏
   custom.http_method: "POST"
   my_status: 200
   ```

2. **自定义属性使用vendor前缀**

   ```yaml
   # ✅ 好
   mycompany.order.id: "ORDER-123"
   
   # ❌ 坏
   order_id: "ORDER-123"  # 可能冲突
   ```

3. **合理控制基数**

   ```yaml
   # ✅ 好 (低基数)
   user.tier: "gold"  # 4-5个值
   order.status: "paid"  # 5-10个值
   
   # ❌ 坏 (高基数)
   user.id: "user-123456"  # 百万级
   order.id: "ORDER-789"  # 无限
   ```

4. **敏感数据脱敏**

   ```yaml
   # ✅ 好
   user.email.hash: "a1b2c3..."
   credit_card.last4: "1234"
   
   # ❌ 坏
   user.email: "user@example.com"
   credit_card.number: "1234-5678-9012-3456"
   ```

#### ❌ DON'T (避免做法)

1. ❌ 在属性中存储大对象
2. ❌ 使用不稳定的属性名
3. ❌ 忽略类型定义
4. ❌ 过度采样导致成本失控

---

### 5.2 数据生命周期管理策略

```text
┌────────────────────────────────────────────────────────┐
│            数据生命周期管理最佳实践                      │
├────────────────────────────────────────────────────────┤
│                                                        │
│  阶段1: 收集 (Collection)                              │
│    ✅ 使用Auto-instrumentation减少人工成本              │
│    ✅ 标准属性+自定义属性混合                           │
│    ✅ 在SDK层做第一次采样                               │
│                                                        │
│  阶段2: 传输 (Transmission)                            │
│    ✅ 启用gzip压缩 (节省60-70%带宽)                    │
│    ✅ 批处理发送 (batch_size=512, timeout=1s)          │
│    ✅ 异步导出，不阻塞业务                              │
│                                                        │
│  阶段3: 转换 (Transformation)                          │
│    ✅ Collector统一处理                                │
│    ✅ 属性标准化、PII脱敏                               │
│    ✅ 尾部采样 (保留异常)                               │
│                                                        │
│  阶段4: 存储 (Storage)                                 │
│    ✅ 热数据 (7天): 高性能数据库                        │
│    ✅ 温数据 (30天): 列式存储                           │
│    ✅ 冷数据 (>30天): 对象存储                          │
│                                                        │
│  阶段5: 查询 (Query)                                   │
│    ✅ 实时监控: Prometheus + Grafana                   │
│    ✅ Ad-hoc分析: ClickHouse / Presto                  │
│    ✅ 业务BI: 预聚合表                                  │
│                                                        │
└────────────────────────────────────────────────────────┘
```

---

## 结论

本指南全面梳理了OTLP标准规定的语义模型，以及数据在可观测性系统中的完整生命周期。核心要点：

### 🎯 关键收获

1. **语义模型三层架构**: Resource → Instrumentation Scope → Telemetry Data
2. **标准 + 自定义结合**: 优先标准约定，自定义使用vendor前缀
3. **完整数据流**: 收集 → 转换 → 存储 → 处理 → 查询
4. **成熟案例验证**: Uber、Shopify等公司的实践经验

### 📊 数据统计

- **标准语义约定**: 21个领域，33,050行文档
- **数据生命周期**: 5个阶段，完整覆盖
- **成熟案例**: 2个深度案例，实战验证

---

**文档版本**: v1.0.0  
**创建日期**: 2025年10月20日  
**维护团队**: OTLP项目团队  

**相关文档**:

- [OTLP全面对标分析报告](📊_OTLP项目2025年10月20日全面对标分析报告.md)
- [语义约定总览](docs/02_Semantic_Conventions/00_语义约定总览.md)
- [项目README](README.md)

---

**END OF DOCUMENT**:
