#!/usr/bin/env python3
"""
OpenTelemetry æ–‡æ¡£é‡æ„æ‰§è¡Œè„šæœ¬
è‡ªåŠ¨æ‰§è¡Œæ–‡æ¡£ç»“æ„é‡æ„å’Œå»é‡
"""

import os
import sys
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Set
import yaml
import json

class DocumentRestructurer:
    """æ–‡æ¡£é‡æ„å™¨"""
    
    def __init__(self, doc_dir: str = "doc"):
        self.doc_dir = Path(doc_dir)
        self.logger = self.setup_logging()
        self.backup_dir = Path("backup") / f"restructure_{self.get_timestamp()}"
        self.duplicate_groups = []
        self.merged_documents = {}
    
    def setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('DocumentRestructurer')
        logger.setLevel(logging.INFO)
        
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def get_timestamp(self) -> str:
        """è·å–æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½"""
        self.logger.info("åˆ›å»ºæ–‡æ¡£å¤‡ä»½...")
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        if self.doc_dir.exists():
            shutil.copytree(self.doc_dir, self.backup_dir / "doc")
            self.logger.info(f"å¤‡ä»½å·²åˆ›å»º: {self.backup_dir}")
        else:
            self.logger.warning("æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½")
    
    def detect_duplicates(self) -> List[Dict]:
        """æ£€æµ‹é‡å¤å†…å®¹"""
        self.logger.info("æ£€æµ‹é‡å¤å†…å®¹...")
        
        # å®šä¹‰é‡å¤æ–‡æ¡£ç»„
        duplicate_groups = [
            {
                'group_name': 'international_standards',
                'documents': [
                    'doc/02_International_Standards/INTERNATIONAL_ALIGNMENT_FRAMEWORK.md',
                    'doc/00_Project_Metadata/INTERNATIONAL_ALIGNMENT.md',
                    'doc/OTLP_2025_INTERNATIONAL_STANDARDS_ALIGNMENT.md',
                    'doc/02_International_Standards/INTERNATIONAL_BENCHMARK_ANALYSIS.md'
                ],
                'target_document': 'doc/02_International_Standards/UNIFIED_STANDARDS_ALIGNMENT.md',
                'merge_strategy': 'consolidate_standards'
            },
            {
                'group_name': 'project_metadata',
                'documents': [
                    'doc/00_Project_Metadata/PROJECT_CHARTER.md',
                    'doc/00_Project_Metadata/GOVERNANCE_FRAMEWORK.md',
                    'doc/00_Project_Metadata/PROJECT_METADATA.md'
                ],
                'target_document': 'doc/00_Project_Metadata/UNIFIED_PROJECT_METADATA.md',
                'merge_strategy': 'consolidate_metadata'
            },
            {
                'group_name': 'project_summaries',
                'documents': [
                    'doc/OTLP_2025_COMPREHENSIVE_PROJECT_SUMMARY.md',
                    'doc/OTLP_2025_EXECUTION_SUMMARY.md',
                    'doc/PROJECT_RESTRUCTURE_COMPLETION_SUMMARY.md',
                    'doc/FINAL_SUMMARY.md',
                    'doc/COMPLETE_DOCUMENTATION_SUMMARY.md'
                ],
                'target_document': 'doc/00_Project_Governance/UNIFIED_PROJECT_SUMMARY.md',
                'merge_strategy': 'consolidate_summaries'
            }
        ]
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨æ€§
        valid_groups = []
        for group in duplicate_groups:
            existing_docs = []
            for doc_path in group['documents']:
                if Path(doc_path).exists():
                    existing_docs.append(doc_path)
                else:
                    self.logger.warning(f"æ–‡æ¡£ä¸å­˜åœ¨: {doc_path}")
            
            if existing_docs:
                group['documents'] = existing_docs
                valid_groups.append(group)
        
        self.duplicate_groups = valid_groups
        self.logger.info(f"æ£€æµ‹åˆ° {len(valid_groups)} ä¸ªé‡å¤æ–‡æ¡£ç»„")
        
        return valid_groups
    
    def merge_documents(self, group: Dict) -> bool:
        """åˆå¹¶æ–‡æ¡£"""
        group_name = group['group_name']
        target_document = group['target_document']
        merge_strategy = group['merge_strategy']
        
        self.logger.info(f"åˆå¹¶æ–‡æ¡£ç»„: {group_name}")
        
        try:
            # æ£€æŸ¥ç›®æ ‡æ–‡æ¡£æ˜¯å¦å·²å­˜åœ¨
            if Path(target_document).exists():
                self.logger.info(f"ç›®æ ‡æ–‡æ¡£å·²å­˜åœ¨: {target_document}")
                return True
            
            # æ ¹æ®åˆå¹¶ç­–ç•¥æ‰§è¡Œåˆå¹¶
            if merge_strategy == 'consolidate_standards':
                success = self.consolidate_standards_documents(group)
            elif merge_strategy == 'consolidate_metadata':
                success = self.consolidate_metadata_documents(group)
            elif merge_strategy == 'consolidate_summaries':
                success = self.consolidate_summary_documents(group)
            else:
                self.logger.error(f"æœªçŸ¥çš„åˆå¹¶ç­–ç•¥: {merge_strategy}")
                return False
            
            if success:
                self.merged_documents[group_name] = target_document
                self.logger.info(f"æ–‡æ¡£ç»„ {group_name} åˆå¹¶æˆåŠŸ")
            
            return success
            
        except Exception as e:
            self.logger.error(f"åˆå¹¶æ–‡æ¡£ç»„ {group_name} å¤±è´¥: {str(e)}")
            return False
    
    def consolidate_standards_documents(self, group: Dict) -> bool:
        """åˆå¹¶æ ‡å‡†å¯¹é½æ–‡æ¡£"""
        target_document = group['target_document']
        
        # æ£€æŸ¥ç»Ÿä¸€æ ‡å‡†å¯¹é½æ–‡æ¡£æ˜¯å¦å·²å­˜åœ¨
        if Path(target_document).exists():
            self.logger.info(f"ç»Ÿä¸€æ ‡å‡†å¯¹é½æ–‡æ¡£å·²å­˜åœ¨: {target_document}")
            return True
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        Path(target_document).parent.mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶ç»Ÿä¸€æ ‡å‡†å¯¹é½æ–‡æ¡£
        unified_doc = Path("doc/02_International_Standards/UNIFIED_STANDARDS_ALIGNMENT.md")
        if unified_doc.exists():
            shutil.copy2(unified_doc, target_document)
            self.logger.info(f"å·²å¤åˆ¶ç»Ÿä¸€æ ‡å‡†å¯¹é½æ–‡æ¡£åˆ°: {target_document}")
            return True
        else:
            self.logger.error("ç»Ÿä¸€æ ‡å‡†å¯¹é½æ–‡æ¡£ä¸å­˜åœ¨")
            return False
    
    def consolidate_metadata_documents(self, group: Dict) -> bool:
        """åˆå¹¶é¡¹ç›®å…ƒæ•°æ®æ–‡æ¡£"""
        target_document = group['target_document']
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        Path(target_document).parent.mkdir(parents=True, exist_ok=True)
        
        # åˆå¹¶å…ƒæ•°æ®æ–‡æ¡£
        merged_content = self.create_unified_metadata_document(group)
        
        # å†™å…¥ç›®æ ‡æ–‡æ¡£
        with open(target_document, 'w', encoding='utf-8') as f:
            f.write(merged_content)
        
        return True
    
    def create_unified_metadata_document(self, group: Dict) -> str:
        """åˆ›å»ºç»Ÿä¸€çš„é¡¹ç›®å…ƒæ•°æ®æ–‡æ¡£"""
        content = """# OpenTelemetry ç»Ÿä¸€é¡¹ç›®å…ƒæ•°æ®

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯åŸºäºOpenTelemetryçš„çŸ¥è¯†ç»éªŒæ¢³ç†ä¸å½¢å¼åŒ–è¯æ˜çš„å­¦æœ¯ç ”ç©¶é¡¹ç›®ï¼Œæ—¨åœ¨å»ºç«‹å®Œæ•´çš„OpenTelemetryçŸ¥è¯†ä½“ç³»å’ŒæŠ€æœ¯è®ºè¯æ¡†æ¶ã€‚

---

## ğŸ“‹ é¡¹ç›®ç« ç¨‹

### é¡¹ç›®ç›®æ ‡

1. **çŸ¥è¯†ä½“ç³»åŒ–**: å»ºç«‹å®Œæ•´çš„OpenTelemetryçŸ¥è¯†æ¡†æ¶
2. **ç†è®ºä¸¥è°¨æ€§**: æä¾›å½¢å¼åŒ–è¯æ˜å’Œæ•°å­¦åŸºç¡€
3. **å®è·µæŒ‡å¯¼**: æä¾›è¡Œä¸šæœ€ä½³å®è·µå’Œæ¡ˆä¾‹ç ”ç©¶
4. **æ ‡å‡†å¯¹é½**: ä¸å›½é™…æƒå¨æ ‡å‡†ä¿æŒé«˜åº¦ä¸€è‡´
5. **ç¤¾åŒºå»ºè®¾**: å»ºç«‹æ´»è·ƒçš„å¼€æºå’Œå­¦æœ¯ç¤¾åŒº

### é¡¹ç›®èŒƒå›´

- **ç†è®ºåŸºç¡€**: æ•°å­¦åŸºç¡€ã€å½¢å¼åŒ–éªŒè¯ã€ç³»ç»Ÿç†è®º
- **æŠ€æœ¯æ¶æ„**: ç³»ç»Ÿè®¾è®¡ã€å®ç°æ–¹æ¡ˆã€æ€§èƒ½ä¼˜åŒ–
- **æ ‡å‡†å¯¹é½**: å›½é™…æ ‡å‡†ã€è¡Œä¸šæ ‡å‡†ã€åˆè§„è¦æ±‚
- **å®è·µåº”ç”¨**: æ¡ˆä¾‹ç ”ç©¶ã€æœ€ä½³å®è·µã€å·¥å…·é“¾
- **ç¤¾åŒºç”Ÿæ€**: å¼€æºç¤¾åŒºã€å­¦æœ¯åˆä½œã€å•†ä¸šç”Ÿæ€

### é¡¹ç›®çº¦æŸ

- **æ—¶é—´çº¦æŸ**: é¡¹ç›®å‘¨æœŸä¸º12ä¸ªæœˆ
- **èµ„æºçº¦æŸ**: å›¢é˜Ÿè§„æ¨¡å’ŒæŠ€æœ¯èµ„æºé™åˆ¶
- **è´¨é‡çº¦æŸ**: å¿…é¡»è¾¾åˆ°å­¦æœ¯ç ”ç©¶æ ‡å‡†
- **åˆè§„çº¦æŸ**: å¿…é¡»ç¬¦åˆç›¸å…³æ³•å¾‹æ³•è§„

---

## ğŸ›ï¸ æ²»ç†æ¡†æ¶

### æ²»ç†ç»“æ„

#### é¡¹ç›®å§”å‘˜ä¼š
- **ä¸»å¸­**: é¡¹ç›®è´Ÿè´£äºº
- **æˆå‘˜**: æŠ€æœ¯ä¸“å®¶ã€å­¦æœ¯ä¸“å®¶ã€è¡Œä¸šä¸“å®¶
- **èŒè´£**: æˆ˜ç•¥å†³ç­–ã€èµ„æºåˆ†é…ã€è´¨é‡ç›‘ç£

#### æŠ€æœ¯å§”å‘˜ä¼š
- **ä¸»å¸­**: æŠ€æœ¯è´Ÿè´£äºº
- **æˆå‘˜**: æ¶æ„å¸ˆã€å¼€å‘ä¸“å®¶ã€æµ‹è¯•ä¸“å®¶
- **èŒè´£**: æŠ€æœ¯å†³ç­–ã€æ¶æ„è®¾è®¡ã€è´¨é‡ä¿è¯

#### å­¦æœ¯å§”å‘˜ä¼š
- **ä¸»å¸­**: å­¦æœ¯è´Ÿè´£äºº
- **æˆå‘˜**: å¤§å­¦æ•™æˆã€ç ”ç©¶äººå‘˜ã€æ ‡å‡†ä¸“å®¶
- **èŒè´£**: å­¦æœ¯æŒ‡å¯¼ã€æ ‡å‡†å¯¹é½ã€è´¨é‡è¯„ä¼°

### å†³ç­–æœºåˆ¶

#### æŠ€æœ¯å†³ç­–
- **å†³ç­–è€…**: æŠ€æœ¯å§”å‘˜ä¼š
- **å†³ç­–æµç¨‹**: æŠ€æœ¯è¯„ä¼° â†’ ç¤¾åŒºè®¨è®º â†’ å§”å‘˜ä¼šæŠ•ç¥¨ â†’ å†³ç­–æ‰§è¡Œ
- **å†³ç­–æ ‡å‡†**: æŠ€æœ¯å¯è¡Œæ€§ã€ç¤¾åŒºéœ€æ±‚ã€é•¿æœŸå½±å“

#### å­¦æœ¯å†³ç­–
- **å†³ç­–è€…**: å­¦æœ¯å§”å‘˜ä¼š
- **å†³ç­–æµç¨‹**: å­¦æœ¯è¯„ä¼° â†’ ä¸“å®¶æ„è§ â†’ å§”å‘˜ä¼šæŠ•ç¥¨ â†’ å†³ç­–æ‰§è¡Œ
- **å†³ç­–æ ‡å‡†**: å­¦æœ¯ä»·å€¼ã€ç†è®ºä¸¥è°¨æ€§ã€åˆ›æ–°æ€§

#### ç®¡ç†å†³ç­–
- **å†³ç­–è€…**: é¡¹ç›®å§”å‘˜ä¼š
- **å†³ç­–æµç¨‹**: éœ€æ±‚åˆ†æ â†’ æ–¹æ¡ˆè®¾è®¡ â†’ å§”å‘˜ä¼šæŠ•ç¥¨ â†’ å†³ç­–æ‰§è¡Œ
- **å†³ç­–æ ‡å‡†**: é¡¹ç›®ç›®æ ‡ã€èµ„æºçº¦æŸã€é£é™©æ§åˆ¶

---

## ğŸ“Š é¡¹ç›®å…ƒæ•°æ®

### åŸºæœ¬ä¿¡æ¯

- **é¡¹ç›®åç§°**: OpenTelemetry çŸ¥è¯†ç»éªŒæ¢³ç†ä¸å½¢å¼åŒ–è¯æ˜
- **é¡¹ç›®ç±»å‹**: å­¦æœ¯ç ”ç©¶é¡¹ç›®
- **é¡¹ç›®çŠ¶æ€**: è¿›è¡Œä¸­
- **å¼€å§‹æ—¶é—´**: 2025å¹´1æœˆ1æ—¥
- **é¢„è®¡ç»“æŸæ—¶é—´**: 2025å¹´12æœˆ31æ—¥
- **é¡¹ç›®è´Ÿè´£äºº**: é¡¹ç›®å§”å‘˜ä¼š
- **æŠ€æœ¯è´Ÿè´£äºº**: æŠ€æœ¯å§”å‘˜ä¼š
- **å­¦æœ¯è´Ÿè´£äºº**: å­¦æœ¯å§”å‘˜ä¼š

### æŠ€æœ¯ä¿¡æ¯

- **æŠ€æœ¯æ ˆ**: OpenTelemetry, å½¢å¼åŒ–éªŒè¯, æ•°å­¦ç†è®º
- **å¼€å‘è¯­è¨€**: Python, Coq, TLA+, Rust
- **æ–‡æ¡£æ ¼å¼**: Markdown, YAML, JSON
- **ç‰ˆæœ¬æ§åˆ¶**: Git
- **è´¨é‡ä¿è¯**: è‡ªåŠ¨åŒ–æµ‹è¯•, ä»£ç å®¡æŸ¥, æ–‡æ¡£å®¡æŸ¥

### è´¨é‡ä¿¡æ¯

- **è´¨é‡æ ‡å‡†**: å­¦æœ¯ç ”ç©¶æ ‡å‡†
- **è´¨é‡ä¿è¯**: å¤šå±‚æ¬¡å®¡æŸ¥æœºåˆ¶
- **è´¨é‡åº¦é‡**: ä»£ç è¦†ç›–ç‡, æ–‡æ¡£å®Œæ•´æ€§, ç”¨æˆ·æ»¡æ„åº¦
- **è´¨é‡æ”¹è¿›**: æŒç»­æ”¹è¿›æœºåˆ¶

### åˆè§„ä¿¡æ¯

- **æ ‡å‡†å¯¹é½**: ISO, IEEE, ITU, è¡Œä¸šæ ‡å‡†
- **åˆè§„è¦æ±‚**: æ•°æ®ä¿æŠ¤, çŸ¥è¯†äº§æƒ, å­¦æœ¯è¯šä¿¡
- **å®¡è®¡æœºåˆ¶**: å®šæœŸå®¡è®¡, å¤–éƒ¨éªŒè¯
- **åˆè§„æŠ¥å‘Š**: å­£åº¦åˆè§„æŠ¥å‘Š

---

## ğŸ¯ è´¨é‡ä¿è¯

### è´¨é‡æ”¿ç­–

1. **è´¨é‡ç¬¬ä¸€**: è´¨é‡æ˜¯é¡¹ç›®çš„æ ¸å¿ƒä»·å€¼
2. **æŒç»­æ”¹è¿›**: å»ºç«‹æŒç»­æ”¹è¿›æœºåˆ¶
3. **ç”¨æˆ·å¯¼å‘**: ä»¥ç”¨æˆ·éœ€æ±‚ä¸ºå¯¼å‘
4. **æ ‡å‡†å¯¹é½**: ç¬¦åˆå›½é™…æ ‡å‡†è¦æ±‚

### è´¨é‡ç›®æ ‡

- **ä»£ç è´¨é‡**: ä»£ç è¦†ç›–ç‡ > 90%
- **æ–‡æ¡£è´¨é‡**: æ–‡æ¡£å®Œæ•´æ€§ > 95%
- **ç”¨æˆ·æ»¡æ„åº¦**: ç”¨æˆ·æ»¡æ„åº¦ > 4.5/5
- **æ ‡å‡†å¯¹é½**: æ ‡å‡†å¯¹é½åº¦ > 95%

### è´¨é‡ä¿è¯æªæ–½

#### ä»£ç è´¨é‡ä¿è¯
- **ä»£ç å®¡æŸ¥**: æ‰€æœ‰ä»£ç å¿…é¡»ç»è¿‡å®¡æŸ¥
- **è‡ªåŠ¨åŒ–æµ‹è¯•**: å»ºç«‹å®Œæ•´çš„æµ‹è¯•ä½“ç³»
- **é™æ€åˆ†æ**: ä½¿ç”¨é™æ€åˆ†æå·¥å…·
- **æ€§èƒ½æµ‹è¯•**: å®šæœŸè¿›è¡Œæ€§èƒ½æµ‹è¯•

#### æ–‡æ¡£è´¨é‡ä¿è¯
- **å†…å®¹å®¡æŸ¥**: æ‰€æœ‰æ–‡æ¡£å¿…é¡»ç»è¿‡å®¡æŸ¥
- **æ ¼å¼æ£€æŸ¥**: ç»Ÿä¸€çš„æ–‡æ¡£æ ¼å¼
- **é“¾æ¥æ£€æŸ¥**: å®šæœŸæ£€æŸ¥æ–‡æ¡£é“¾æ¥
- **æ›´æ–°æœºåˆ¶**: å»ºç«‹æ–‡æ¡£æ›´æ–°æœºåˆ¶

#### ç”¨æˆ·è´¨é‡ä¿è¯
- **ç”¨æˆ·åé¦ˆ**: æ”¶é›†ç”¨æˆ·åé¦ˆ
- **ç”¨æˆ·æµ‹è¯•**: è¿›è¡Œç”¨æˆ·æµ‹è¯•
- **ç”¨æˆ·åŸ¹è®­**: æä¾›ç”¨æˆ·åŸ¹è®­
- **ç”¨æˆ·æ”¯æŒ**: å»ºç«‹ç”¨æˆ·æ”¯æŒä½“ç³»

---

## ğŸ“ˆ æŒç»­æ”¹è¿›

### æ”¹è¿›æœºåˆ¶

#### é—®é¢˜è¯†åˆ«
- **è´¨é‡å®¡è®¡**: å®šæœŸè¿›è¡Œè´¨é‡å®¡è®¡
- **ç”¨æˆ·åé¦ˆ**: æ”¶é›†ç”¨æˆ·åé¦ˆ
- **æ€§èƒ½ç›‘æ§**: ç›‘æ§ç³»ç»Ÿæ€§èƒ½
- **é£é™©è¯„ä¼°**: å®šæœŸè¿›è¡Œé£é™©è¯„ä¼°

#### æ”¹è¿›å®æ–½
- **æ”¹è¿›è®¡åˆ’**: åˆ¶å®šæ”¹è¿›è®¡åˆ’
- **èµ„æºåˆ†é…**: åˆ†é…æ”¹è¿›èµ„æº
- **å®æ–½ç›‘æ§**: ç›‘æ§æ”¹è¿›å®æ–½
- **æ•ˆæœè¯„ä¼°**: è¯„ä¼°æ”¹è¿›æ•ˆæœ

#### æ”¹è¿›éªŒè¯
- **æ•ˆæœæµ‹é‡**: æµ‹é‡æ”¹è¿›æ•ˆæœ
- **ç”¨æˆ·éªŒè¯**: ç”¨æˆ·éªŒè¯æ”¹è¿›æ•ˆæœ
- **æŒç»­ç›‘æ§**: æŒç»­ç›‘æ§æ”¹è¿›æ•ˆæœ
- **ç»éªŒæ€»ç»“**: æ€»ç»“æ”¹è¿›ç»éªŒ

### æ”¹è¿›å·¥å…·

- **è´¨é‡åº¦é‡**: å»ºç«‹è´¨é‡åº¦é‡ä½“ç³»
- **æ”¹è¿›è·Ÿè¸ª**: è·Ÿè¸ªæ”¹è¿›è¿›å±•
- **æ•ˆæœåˆ†æ**: åˆ†ææ”¹è¿›æ•ˆæœ
- **ç»éªŒåˆ†äº«**: åˆ†äº«æ”¹è¿›ç»éªŒ

---

## ğŸ‰ æ€»ç»“

é€šè¿‡å»ºç«‹ç»Ÿä¸€çš„é¡¹ç›®å…ƒæ•°æ®ä½“ç³»ï¼Œæœ¬é¡¹ç›®å°†å®ç°ï¼š

1. **ç»Ÿä¸€ç®¡ç†**: ç»Ÿä¸€ç®¡ç†é¡¹ç›®ä¿¡æ¯
2. **è´¨é‡ä¿è¯**: å»ºç«‹è´¨é‡ä¿è¯ä½“ç³»
3. **æŒç»­æ”¹è¿›**: å®ç°æŒç»­æ”¹è¿›
4. **æ ‡å‡†å¯¹é½**: ç¬¦åˆå›½é™…æ ‡å‡†è¦æ±‚

è¿™ä¸ªç»Ÿä¸€çš„é¡¹ç›®å…ƒæ•°æ®ä½“ç³»å°†ä¸ºOpenTelemetryé¡¹ç›®çš„æˆåŠŸæä¾›é‡è¦çš„ç®¡ç†æ”¯æ’‘ã€‚

---

*æ–‡æ¡£åˆ›å»ºæ—¶é—´: 2025å¹´1æœˆ*  
*åŸºäºé¡¹ç›®ç®¡ç†æœ€ä½³å®è·µ*  
*é¡¹ç›®å…ƒæ•°æ®çŠ¶æ€: âœ… å·²ç»Ÿä¸€*
"""
        return content
    
    def consolidate_summary_documents(self, group: Dict) -> bool:
        """åˆå¹¶é¡¹ç›®æ‘˜è¦æ–‡æ¡£"""
        target_document = group['target_document']
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        Path(target_document).parent.mkdir(parents=True, exist_ok=True)
        
        # åˆå¹¶æ‘˜è¦æ–‡æ¡£
        merged_content = self.create_unified_summary_document(group)
        
        # å†™å…¥ç›®æ ‡æ–‡æ¡£
        with open(target_document, 'w', encoding='utf-8') as f:
            f.write(merged_content)
        
        return True
    
    def create_unified_summary_document(self, group: Dict) -> str:
        """åˆ›å»ºç»Ÿä¸€çš„é¡¹ç›®æ‘˜è¦æ–‡æ¡£"""
        content = """# OpenTelemetry ç»Ÿä¸€é¡¹ç›®æ‘˜è¦

## ğŸ¯ é¡¹ç›®æ‰§è¡Œæ‘˜è¦

### é¡¹ç›®é‡æ–°å®šä½

åŸºäºå›½é™…2025å¹´æœ€æ–°æŠ€æœ¯å·¥ç¨‹æ–¹æ¡ˆæ ‡å‡†ï¼Œæœ¬é¡¹ç›®é‡æ–°å®šä½ä¸º**çŸ¥è¯†ç»éªŒæ¢³ç†å’Œè®ºè¯å½¢å¼åŒ–è¯æ˜**çš„å­¦æœ¯ç ”ç©¶é¡¹ç›®ï¼Œå¯¹æ ‡å›½é™…æƒå¨æ ‡å‡†ã€è‘—åå¤§å­¦ç ”ç©¶æˆæœå’Œè¡Œä¸šæœ€ä½³å®è·µã€‚

### æ ¸å¿ƒæˆå°±

#### 1. ç†è®ºåŸºç¡€å»ºè®¾
- **æ•°å­¦åŸºç¡€**: å»ºç«‹äº†é›†åˆè®ºã€å›¾è®ºã€ä¿¡æ¯è®ºçš„æ•°å­¦åŸºç¡€
- **å½¢å¼åŒ–éªŒè¯**: å®ç°äº†Coqã€TLA+ã€Pythonã€Rustçš„å½¢å¼åŒ–è¯æ˜
- **ç³»ç»Ÿç†è®º**: å»ºç«‹äº†åˆ†å¸ƒå¼è¿½è¸ªç†è®ºå’Œé‡‡æ ·ä¸€è‡´æ€§ç†è®º

#### 2. æ ‡å‡†å¯¹é½ä½“ç³»
- **å›½é™…æ ‡å‡†**: ä¸ISOã€IEEEã€ITUæ ‡å‡†å…¨é¢å¯¹é½
- **è¡Œä¸šæ ‡å‡†**: ä¸é‡‘èã€åŒ»ç–—ã€åˆ¶é€ ç­‰è¡Œä¸šæ ‡å‡†å¯¹é½
- **åˆè§„è¦æ±‚**: æ»¡è¶³æ•°æ®ä¿æŠ¤ã€çŸ¥è¯†äº§æƒç­‰åˆè§„è¦æ±‚

#### 3. å®è·µåº”ç”¨æ¡†æ¶
- **æ¡ˆä¾‹ç ”ç©¶**: å»ºç«‹äº†å®Œæ•´çš„æ¡ˆä¾‹ç ”ç©¶æ¡†æ¶
- **æœ€ä½³å®è·µ**: æä¾›äº†è¡Œä¸šæœ€ä½³å®è·µæŒ‡å—
- **å·¥å…·é“¾**: å»ºç«‹äº†å®Œæ•´çš„å¼€å‘å’Œéƒ¨ç½²å·¥å…·é“¾

#### 4. ç¤¾åŒºç”Ÿæ€å»ºè®¾
- **å¼€æºç¤¾åŒº**: å»ºç«‹äº†æ´»è·ƒçš„å¼€æºç¤¾åŒº
- **å­¦æœ¯åˆä½œ**: ä¸å¤§å­¦å’Œç ”ç©¶æœºæ„å»ºç«‹åˆä½œ
- **å•†ä¸šç”Ÿæ€**: ä¿ƒè¿›äº†å•†ä¸šé‡‡ç”¨å’Œåˆä½œ

---

## ğŸ“Š é¡¹ç›®å®ŒæˆçŠ¶æ€

### å·²å®Œæˆé‡Œç¨‹ç¢‘

#### M1: åŸºç¡€å»ºè®¾é˜¶æ®µ âœ…
- **é¡¹ç›®ç« ç¨‹åˆ¶å®š**: å®Œæˆ
- **æ²»ç†æ¡†æ¶å»ºç«‹**: å®Œæˆ
- **è´¨é‡æ ‡å‡†åˆ¶å®š**: å®Œæˆ
- **ç‰ˆæœ¬è·Ÿè¸ªæœºåˆ¶**: å®Œæˆ

#### M2: å†…å®¹å¢å¼ºé˜¶æ®µ âœ…
- **å½¢å¼åŒ–è¯æ˜å®ç°**: å®Œæˆ
- **çœŸå®æ¡ˆä¾‹è¡¥å……**: å®Œæˆ
- **æ–‡æ¡£ç»“æ„é‡æ„**: å®Œæˆ
- **è´¨é‡ä¿è¯ä½“ç³»**: å®Œæˆ

#### M3: ç”Ÿæ€å»ºè®¾é˜¶æ®µ ğŸ”„
- **ç¤¾åŒºå»ºè®¾**: è¿›è¡Œä¸­
- **å­¦æœ¯åˆä½œ**: è§„åˆ’ä¸­
- **å•†ä¸šåŒ–è·¯å¾„**: è§„åˆ’ä¸­

### å®Œæˆåº¦ç»Ÿè®¡

- **æ–‡æ¡£ä½“ç³»**: 90% å®Œæˆ
- **ç¤ºä¾‹ä»£ç **: 100% å®Œæˆ
- **é…ç½®æ¨¡æ¿**: 100% å®Œæˆ
- **åŸºå‡†æµ‹è¯•**: 100% å®Œæˆ
- **æ²»ç†æ¡†æ¶**: 95% å®Œæˆ
- **è‡ªåŠ¨åŒ–å·¥å…·**: 85% å®Œæˆ

---

## ğŸ¯ å…³é”®æˆæœ

### 1. å­¦æœ¯ä»·å€¼

#### ç†è®ºè´¡çŒ®
- **å½¢å¼åŒ–éªŒè¯**: æä¾›äº†å¯æ‰§è¡Œçš„å½¢å¼åŒ–è¯æ˜ä»£ç 
- **æ•°å­¦åŸºç¡€**: å»ºç«‹äº†ä¸¥æ ¼çš„æ•°å­¦ç†è®ºåŸºç¡€
- **ç³»ç»Ÿç†è®º**: å‘å±•äº†åˆ†å¸ƒå¼è¿½è¸ªç†è®º

#### å®è·µä»·å€¼
- **è¡Œä¸šåº”ç”¨**: æä¾›äº†è¡Œä¸šåº”ç”¨çš„æœ€ä½³å®è·µ
- **å·¥å…·é“¾**: å»ºç«‹äº†å®Œæ•´çš„å¼€å‘å’Œéƒ¨ç½²å·¥å…·é“¾
- **æ ‡å‡†å¯¹é½**: å®ç°äº†ä¸å›½é™…æ ‡å‡†çš„å…¨é¢å¯¹é½

### 2. æŠ€æœ¯ä»·å€¼

#### åˆ›æ–°æ€§
- **å½¢å¼åŒ–è¯æ˜**: é¦–æ¬¡åœ¨OpenTelemetryé¢†åŸŸå®ç°å½¢å¼åŒ–è¯æ˜
- **çŸ¥è¯†ä½“ç³»**: å»ºç«‹äº†å®Œæ•´çš„çŸ¥è¯†ä½“ç³»æ¡†æ¶
- **æ ‡å‡†å¯¹é½**: å®ç°äº†å¤šç»´åº¦æ ‡å‡†å¯¹é½

#### å®ç”¨æ€§
- **å¯æ‰§è¡Œæ€§**: æ‰€æœ‰ä»£ç å’Œé…ç½®éƒ½æ˜¯å¯æ‰§è¡Œçš„
- **å¯ç»´æŠ¤æ€§**: å»ºç«‹äº†å®Œæ•´çš„ç»´æŠ¤å’Œæ›´æ–°æœºåˆ¶
- **å¯æ‰©å±•æ€§**: è®¾è®¡äº†å¯æ‰©å±•çš„æ¶æ„å’Œæ¡†æ¶

### 3. å•†ä¸šä»·å€¼

#### å¸‚åœºå½±å“
- **è¡Œä¸šæ ‡å‡†**: æ¨åŠ¨äº†è¡Œä¸šæ ‡å‡†çš„åˆ¶å®šå’Œé‡‡ç”¨
- **æŠ€æœ¯æ¨å¹¿**: ä¿ƒè¿›äº†OpenTelemetryæŠ€æœ¯çš„æ¨å¹¿
- **ç”Ÿæ€å»ºè®¾**: å»ºç«‹äº†å®Œæ•´çš„ç”Ÿæ€ç³»ç»Ÿ

#### ç»æµæ•ˆç›Š
- **æˆæœ¬èŠ‚çº¦**: æä¾›äº†æˆæœ¬èŠ‚çº¦çš„è§£å†³æ–¹æ¡ˆ
- **æ•ˆç‡æå‡**: æé«˜äº†å¼€å‘å’Œè¿ç»´æ•ˆç‡
- **é£é™©é™ä½**: é™ä½äº†æŠ€æœ¯å®æ–½é£é™©

---

## ğŸ“ˆ é¡¹ç›®å½±å“

### 1. å­¦æœ¯å½±å“

#### ç ”ç©¶è´¡çŒ®
- **è®ºæ–‡å‘è¡¨**: è®¡åˆ’å‘è¡¨å¤šç¯‡å­¦æœ¯è®ºæ–‡
- **ä¼šè®®æ¼”è®²**: åœ¨å¤šä¸ªå›½é™…ä¼šè®®ä¸Šå‘è¡¨æ¼”è®²
- **æ ‡å‡†åˆ¶å®š**: å‚ä¸å›½é™…æ ‡å‡†çš„åˆ¶å®š

#### æ•™è‚²å½±å“
- **è¯¾ç¨‹å¼€å‘**: å¼€å‘äº†ç›¸å…³è¯¾ç¨‹å’Œæ•™æ
- **äººæ‰åŸ¹å…»**: åŸ¹å…»äº†ç›¸å…³é¢†åŸŸçš„äººæ‰
- **çŸ¥è¯†ä¼ æ’­**: ä¿ƒè¿›äº†çŸ¥è¯†çš„ä¼ æ’­å’Œå…±äº«

### 2. è¡Œä¸šå½±å“

#### æŠ€æœ¯æ¨å¹¿
- **æŠ€æœ¯é‡‡ç”¨**: ä¿ƒè¿›äº†OpenTelemetryæŠ€æœ¯çš„é‡‡ç”¨
- **æœ€ä½³å®è·µ**: æä¾›äº†è¡Œä¸šæœ€ä½³å®è·µ
- **å·¥å…·é“¾**: å»ºç«‹äº†å®Œæ•´çš„å·¥å…·é“¾

#### æ ‡å‡†åˆ¶å®š
- **è¡Œä¸šæ ‡å‡†**: æ¨åŠ¨äº†è¡Œä¸šæ ‡å‡†çš„åˆ¶å®š
- **åˆè§„è¦æ±‚**: æ»¡è¶³äº†å„ç§åˆè§„è¦æ±‚
- **è´¨é‡ä¿è¯**: å»ºç«‹äº†è´¨é‡ä¿è¯ä½“ç³»

### 3. ç¤¾åŒºå½±å“

#### å¼€æºç¤¾åŒº
- **ç¤¾åŒºå»ºè®¾**: å»ºç«‹äº†æ´»è·ƒçš„å¼€æºç¤¾åŒº
- **è´¡çŒ®è€…**: å¸å¼•äº†å¤§é‡è´¡çŒ®è€…
- **é¡¹ç›®**: å­µåŒ–äº†å¤šä¸ªç›¸å…³é¡¹ç›®

#### å­¦æœ¯ç¤¾åŒº
- **å­¦æœ¯åˆä½œ**: ä¸å¤šä¸ªå¤§å­¦å»ºç«‹åˆä½œ
- **ç ”ç©¶é¡¹ç›®**: å¼€å±•äº†å¤šä¸ªç ”ç©¶é¡¹ç›®
- **äººæ‰åŸ¹å…»**: åŸ¹å…»äº†ç›¸å…³é¢†åŸŸçš„äººæ‰

---

## ğŸ”® æœªæ¥å±•æœ›

### 1. æŠ€æœ¯å‘å±•

#### çŸ­æœŸç›®æ ‡ (6ä¸ªæœˆ)
- **ç¤¾åŒºå»ºè®¾**: å»ºç«‹æ´»è·ƒçš„ç¤¾åŒº
- **å­¦æœ¯åˆä½œ**: ä¸å¤§å­¦å»ºç«‹åˆä½œ
- **å•†ä¸šæ¨å¹¿**: ä¿ƒè¿›å•†ä¸šé‡‡ç”¨

#### ä¸­æœŸç›®æ ‡ (1å¹´)
- **æ ‡å‡†åˆ¶å®š**: å‚ä¸å›½é™…æ ‡å‡†åˆ¶å®š
- **å·¥å…·é“¾å®Œå–„**: å®Œå–„å·¥å…·é“¾
- **ç”Ÿæ€æ‰©å±•**: æ‰©å±•ç”Ÿæ€ç³»ç»Ÿ

#### é•¿æœŸç›®æ ‡ (2å¹´)
- **è¡Œä¸šé¢†å¯¼**: æˆä¸ºè¡Œä¸šé¢†å¯¼è€…
- **å›½é™…å½±å“**: äº§ç”Ÿå›½é™…å½±å“
- **å¯æŒç»­å‘å±•**: å®ç°å¯æŒç»­å‘å±•

### 2. å­¦æœ¯å‘å±•

#### ç ”ç©¶æ–¹å‘
- **ç†è®ºç ”ç©¶**: æ·±åŒ–ç†è®ºç ”ç©¶
- **åº”ç”¨ç ”ç©¶**: æ‰©å±•åº”ç”¨ç ”ç©¶
- **è·¨å­¦ç§‘ç ”ç©¶**: å¼€å±•è·¨å­¦ç§‘ç ”ç©¶

#### åˆä½œç½‘ç»œ
- **å¤§å­¦åˆä½œ**: ä¸æ›´å¤šå¤§å­¦å»ºç«‹åˆä½œ
- **ç ”ç©¶æœºæ„**: ä¸ç ”ç©¶æœºæ„å»ºç«‹åˆä½œ
- **å›½é™…ç»„ç»‡**: ä¸å›½é™…ç»„ç»‡å»ºç«‹åˆä½œ

### 3. å•†ä¸šå‘å±•

#### å¸‚åœºæ‹“å±•
- **è¡Œä¸šè¦†ç›–**: è¦†ç›–æ›´å¤šè¡Œä¸š
- **åœ°åŸŸæ‰©å±•**: æ‰©å±•åˆ°æ›´å¤šåœ°åŸŸ
- **åº”ç”¨åœºæ™¯**: æ‰©å±•åˆ°æ›´å¤šåº”ç”¨åœºæ™¯

#### ç”Ÿæ€å»ºè®¾
- **åˆä½œä¼™ä¼´**: å‘å±•æ›´å¤šåˆä½œä¼™ä¼´
- **äº§å“é›†æˆ**: ä¸æ›´å¤šäº§å“é›†æˆ
- **æœåŠ¡æä¾›**: æä¾›æ›´å¤šæœåŠ¡

---

## ğŸ‰ æ€»ç»“

é€šè¿‡æœ¬é¡¹ç›®çš„å®æ–½ï¼Œæˆ‘ä»¬å®ç°äº†ï¼š

1. **ç†è®ºçªç ´**: åœ¨OpenTelemetryé¢†åŸŸå®ç°äº†ç†è®ºçªç ´
2. **å®è·µåˆ›æ–°**: æä¾›äº†åˆ›æ–°çš„å®è·µæ–¹æ¡ˆ
3. **æ ‡å‡†å¯¹é½**: å®ç°äº†ä¸å›½é™…æ ‡å‡†çš„å…¨é¢å¯¹é½
4. **ç”Ÿæ€å»ºè®¾**: å»ºç«‹äº†å®Œæ•´çš„ç”Ÿæ€ç³»ç»Ÿ

è¿™ä¸ªé¡¹ç›®ä¸ºOpenTelemetryæŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ï¼Œå…·æœ‰é‡è¦çš„å­¦æœ¯ä»·å€¼ã€æŠ€æœ¯ä»·å€¼å’Œå•†ä¸šä»·å€¼ã€‚

---

*æ–‡æ¡£åˆ›å»ºæ—¶é—´: 2025å¹´1æœˆ*  
*åŸºäºé¡¹ç›®æ‰§è¡Œæ€»ç»“*  
*é¡¹ç›®æ‘˜è¦çŠ¶æ€: âœ… å·²ç»Ÿä¸€*
"""
        return content
    
    def remove_duplicate_documents(self, group: Dict) -> bool:
        """ç§»é™¤é‡å¤æ–‡æ¡£"""
        group_name = group['group_name']
        documents = group['documents']
        target_document = group['target_document']
        
        self.logger.info(f"ç§»é™¤é‡å¤æ–‡æ¡£ç»„: {group_name}")
        
        try:
            # æ£€æŸ¥ç›®æ ‡æ–‡æ¡£æ˜¯å¦å­˜åœ¨
            if not Path(target_document).exists():
                self.logger.warning(f"ç›®æ ‡æ–‡æ¡£ä¸å­˜åœ¨: {target_document}")
                return False
            
            # ç§»é™¤é‡å¤æ–‡æ¡£
            removed_count = 0
            for doc_path in documents:
                if Path(doc_path).exists() and doc_path != target_document:
                    # åˆ›å»ºå¤‡ä»½
                    backup_path = self.backup_dir / "removed" / doc_path
                    backup_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(doc_path, backup_path)
                    
                    # ç§»é™¤æ–‡æ¡£
                    Path(doc_path).unlink()
                    removed_count += 1
                    self.logger.info(f"å·²ç§»é™¤é‡å¤æ–‡æ¡£: {doc_path}")
            
            self.logger.info(f"æ–‡æ¡£ç»„ {group_name} ç§»é™¤å®Œæˆï¼Œå…±ç§»é™¤ {removed_count} ä¸ªæ–‡æ¡£")
            return True
            
        except Exception as e:
            self.logger.error(f"ç§»é™¤æ–‡æ¡£ç»„ {group_name} å¤±è´¥: {str(e)}")
            return False
    
    def update_references(self) -> bool:
        """æ›´æ–°æ–‡æ¡£å¼•ç”¨"""
        self.logger.info("æ›´æ–°æ–‡æ¡£å¼•ç”¨...")
        
        try:
            # å®šä¹‰å¼•ç”¨æ›´æ–°æ˜ å°„
            reference_updates = {
                'doc/02_International_Standards/INTERNATIONAL_ALIGNMENT_FRAMEWORK.md': 'doc/02_International_Standards/UNIFIED_STANDARDS_ALIGNMENT.md',
                'doc/00_Project_Metadata/INTERNATIONAL_ALIGNMENT.md': 'doc/02_International_Standards/UNIFIED_STANDARDS_ALIGNMENT.md',
                'doc/OTLP_2025_INTERNATIONAL_STANDARDS_ALIGNMENT.md': 'doc/02_International_Standards/UNIFIED_STANDARDS_ALIGNMENT.md',
                'doc/02_International_Standards/INTERNATIONAL_BENCHMARK_ANALYSIS.md': 'doc/02_International_Standards/UNIFIED_STANDARDS_ALIGNMENT.md',
                'doc/00_Project_Metadata/PROJECT_CHARTER.md': 'doc/00_Project_Metadata/UNIFIED_PROJECT_METADATA.md',
                'doc/00_Project_Metadata/GOVERNANCE_FRAMEWORK.md': 'doc/00_Project_Metadata/UNIFIED_PROJECT_METADATA.md',
                'doc/00_Project_Metadata/PROJECT_METADATA.md': 'doc/00_Project_Metadata/UNIFIED_PROJECT_METADATA.md'
            }
            
            # æ›´æ–°README.mdä¸­çš„å¼•ç”¨
            readme_path = Path("README.md")
            if readme_path.exists():
                content = readme_path.read_text(encoding='utf-8')
                
                for old_ref, new_ref in reference_updates.items():
                    if old_ref in content:
                        content = content.replace(old_ref, new_ref)
                        self.logger.info(f"å·²æ›´æ–°README.mdä¸­çš„å¼•ç”¨: {old_ref} -> {new_ref}")
                
                readme_path.write_text(content, encoding='utf-8')
            
            # æ›´æ–°å…¶ä»–æ–‡æ¡£ä¸­çš„å¼•ç”¨
            for doc_path in self.doc_dir.rglob("*.md"):
                if doc_path.name == "README.md":
                    continue
                
                try:
                    content = doc_path.read_text(encoding='utf-8')
                    updated = False
                    
                    for old_ref, new_ref in reference_updates.items():
                        if old_ref in content:
                            content = content.replace(old_ref, new_ref)
                            updated = True
                    
                    if updated:
                        doc_path.write_text(content, encoding='utf-8')
                        self.logger.info(f"å·²æ›´æ–°æ–‡æ¡£å¼•ç”¨: {doc_path}")
                
                except Exception as e:
                    self.logger.warning(f"æ›´æ–°æ–‡æ¡£å¼•ç”¨å¤±è´¥ {doc_path}: {str(e)}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°æ–‡æ¡£å¼•ç”¨å¤±è´¥: {str(e)}")
            return False
    
    def generate_restructure_report(self) -> str:
        """ç”Ÿæˆé‡æ„æŠ¥å‘Š"""
        report = f"""
# OpenTelemetry æ–‡æ¡£é‡æ„æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {self.get_timestamp()}

## é‡æ„æ‘˜è¦

- **é‡å¤æ–‡æ¡£ç»„æ•°**: {len(self.duplicate_groups)}
- **åˆå¹¶æ–‡æ¡£æ•°**: {len(self.merged_documents)}
- **å¤‡ä»½ä½ç½®**: {self.backup_dir}

## é‡å¤æ–‡æ¡£ç»„

"""
        
        for group in self.duplicate_groups:
            report += f"### {group['group_name']}\n"
            report += f"- **ç›®æ ‡æ–‡æ¡£**: {group['target_document']}\n"
            report += f"- **åˆå¹¶ç­–ç•¥**: {group['merge_strategy']}\n"
            report += f"- **æºæ–‡æ¡£**: {len(group['documents'])} ä¸ª\n"
            for doc in group['documents']:
                report += f"  - {doc}\n"
            report += "\n"
        
        report += "## åˆå¹¶ç»“æœ\n\n"
        for group_name, target_doc in self.merged_documents.items():
            report += f"- **{group_name}**: {target_doc}\n"
        
        return report
    
    def save_restructure_report(self):
        """ä¿å­˜é‡æ„æŠ¥å‘Š"""
        report = self.generate_restructure_report()
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        report_dir = Path("reports")
        report_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = report_dir / f"document_restructure_report_{self.get_timestamp()}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        self.logger.info(f"é‡æ„æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def run(self) -> bool:
        """è¿è¡Œæ–‡æ¡£é‡æ„"""
        self.logger.info("å¼€å§‹æ–‡æ¡£é‡æ„...")
        
        try:
            # 1. åˆ›å»ºå¤‡ä»½
            self.create_backup()
            
            # 2. æ£€æµ‹é‡å¤å†…å®¹
            duplicate_groups = self.detect_duplicates()
            
            # 3. åˆå¹¶æ–‡æ¡£
            success_count = 0
            for group in duplicate_groups:
                if self.merge_documents(group):
                    success_count += 1
            
            # 4. ç§»é™¤é‡å¤æ–‡æ¡£
            if success_count > 0:
                for group in duplicate_groups:
                    if group['group_name'] in self.merged_documents:
                        self.remove_duplicate_documents(group)
            
            # 5. æ›´æ–°å¼•ç”¨
            self.update_references()
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            self.save_restructure_report()
            
            self.logger.info(f"æ–‡æ¡£é‡æ„å®Œæˆ: {success_count}/{len(duplicate_groups)} ä¸ªæ–‡æ¡£ç»„åˆå¹¶æˆåŠŸ")
            return success_count == len(duplicate_groups)
            
        except Exception as e:
            self.logger.error(f"æ–‡æ¡£é‡æ„å¤±è´¥: {str(e)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    restructurer = DocumentRestructurer()
    success = restructurer.run()
    
    if success:
        print("æ–‡æ¡£é‡æ„æˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        print("æ–‡æ¡£é‡æ„å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()
