#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenTelemetry 2025 è‡ªåŠ¨åŒ–å·¥ä½œæµç¼–æ’å™¨
Automated Workflow Orchestrator for OpenTelemetry 2025

åŠŸèƒ½ç‰¹æ€§:
- å·¥ä½œæµç¼–æ’
- ä»»åŠ¡è°ƒåº¦
- ä¾èµ–ç®¡ç†
- çŠ¶æ€ç›‘æ§
- é”™è¯¯å¤„ç†
- æŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import json
import yaml
import time
import logging
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import threading
import queue
import concurrent.futures

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('workflow_orchestrator.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    SKIPPED = "skipped"

class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾"""
    LOW = "low"
    NORMAL = "normal"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class Task:
    """ä»»åŠ¡æ•°æ®ç±»"""
    id: str
    name: str
    description: str
    command: str
    script_path: str
    priority: TaskPriority
    status: TaskStatus
    dependencies: List[str]
    timeout: int
    retry_count: int
    max_retries: int
    created_at: str
    started_at: Optional[str]
    completed_at: Optional[str]
    error_message: Optional[str]
    output: Optional[str]

@dataclass
class Workflow:
    """å·¥ä½œæµæ•°æ®ç±»"""
    id: str
    name: str
    description: str
    tasks: List[Task]
    status: TaskStatus
    created_at: str
    started_at: Optional[str]
    completed_at: Optional[str]
    total_tasks: int
    completed_tasks: int
    failed_tasks: int

class TaskExecutor:
    """ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)
        self.running_tasks: Dict[str, concurrent.futures.Future] = {}
    
    def execute_task(self, task: Task) -> Task:
        """æ‰§è¡Œä»»åŠ¡"""
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.name}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = TaskStatus.RUNNING
            task.started_at = datetime.now().isoformat()
            
            # æ‰§è¡Œå‘½ä»¤æˆ–è„šæœ¬
            if task.script_path:
                result = self._execute_script(task.script_path, task.timeout)
            else:
                result = self._execute_command(task.command, task.timeout)
            
            # æ›´æ–°ä»»åŠ¡ç»“æœ
            if result['success']:
                task.status = TaskStatus.COMPLETED
                task.output = result['output']
                logger.info(f"ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: {task.name}")
            else:
                task.status = TaskStatus.FAILED
                task.error_message = result['error']
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.name} - {result['error']}")
            
            task.completed_at = datetime.now().isoformat()
            
        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error_message = str(e)
            task.completed_at = datetime.now().isoformat()
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {task.name} - {e}")
        
        return task
    
    def _execute_script(self, script_path: str, timeout: int) -> Dict[str, Any]:
        """æ‰§è¡Œè„šæœ¬"""
        try:
            script_file = Path(script_path)
            if not script_file.exists():
                return {'success': False, 'error': f'è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_path}'}
            
            # æ‰§è¡Œè„šæœ¬
            result = subprocess.run(
                [sys.executable, str(script_file)],
                capture_output=True,
                text=True,
                timeout=timeout,
                encoding='utf-8'
            )
            
            if result.returncode == 0:
                return {'success': True, 'output': result.stdout}
            else:
                return {'success': False, 'error': result.stderr}
                
        except subprocess.TimeoutExpired:
            return {'success': False, 'error': f'è„šæœ¬æ‰§è¡Œè¶…æ—¶: {timeout}ç§’'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _execute_command(self, command: str, timeout: int) -> Dict[str, Any]:
        """æ‰§è¡Œå‘½ä»¤"""
        try:
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=timeout,
                encoding='utf-8'
            )
            
            if result.returncode == 0:
                return {'success': True, 'output': result.stdout}
            else:
                return {'success': False, 'error': result.stderr}
                
        except subprocess.TimeoutExpired:
            return {'success': False, 'error': f'å‘½ä»¤æ‰§è¡Œè¶…æ—¶: {timeout}ç§’'}
        except Exception as e:
            return {'success': False, 'error': str(e)}

class WorkflowScheduler:
    """å·¥ä½œæµè°ƒåº¦å™¨"""
    
    def __init__(self):
        self.workflows: Dict[str, Workflow] = {}
        self.task_executor = TaskExecutor()
        self.scheduler_config = self._load_scheduler_config()
    
    def _load_scheduler_config(self) -> Dict[str, Any]:
        """åŠ è½½è°ƒåº¦å™¨é…ç½®"""
        try:
            config_path = Path("config/workflow_scheduler.yaml")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            return {}
        except Exception as e:
            logger.error(f"åŠ è½½è°ƒåº¦å™¨é…ç½®å¤±è´¥: {e}")
            return {}
    
    def create_workflow(self, workflow_id: str, name: str, description: str, 
                       tasks: List[Dict[str, Any]]) -> Workflow:
        """åˆ›å»ºå·¥ä½œæµ"""
        workflow_tasks = []
        
        for task_data in tasks:
            task = Task(
                id=task_data['id'],
                name=task_data['name'],
                description=task_data.get('description', ''),
                command=task_data.get('command', ''),
                script_path=task_data.get('script_path', ''),
                priority=TaskPriority(task_data.get('priority', 'normal')),
                status=TaskStatus.PENDING,
                dependencies=task_data.get('dependencies', []),
                timeout=task_data.get('timeout', 300),
                retry_count=0,
                max_retries=task_data.get('max_retries', 3),
                created_at=datetime.now().isoformat(),
                started_at=None,
                completed_at=None,
                error_message=None,
                output=None
            )
            workflow_tasks.append(task)
        
        workflow = Workflow(
            id=workflow_id,
            name=name,
            description=description,
            tasks=workflow_tasks,
            status=TaskStatus.PENDING,
            created_at=datetime.now().isoformat(),
            started_at=None,
            completed_at=None,
            total_tasks=len(workflow_tasks),
            completed_tasks=0,
            failed_tasks=0
        )
        
        self.workflows[workflow_id] = workflow
        logger.info(f"å·¥ä½œæµåˆ›å»ºæˆåŠŸ: {workflow_id}")
        
        return workflow
    
    def execute_workflow(self, workflow_id: str) -> Workflow:
        """æ‰§è¡Œå·¥ä½œæµ"""
        if workflow_id not in self.workflows:
            raise ValueError(f"å·¥ä½œæµä¸å­˜åœ¨: {workflow_id}")
        
        workflow = self.workflows[workflow_id]
        logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow.name}")
        
        # æ›´æ–°å·¥ä½œæµçŠ¶æ€
        workflow.status = TaskStatus.RUNNING
        workflow.started_at = datetime.now().isoformat()
        
        try:
            # æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡
            sorted_tasks = self._sort_tasks_by_dependencies(workflow.tasks)
            
            # æ‰§è¡Œä»»åŠ¡
            for task in sorted_tasks:
                if workflow.status == TaskStatus.CANCELLED:
                    break
                
                # æ£€æŸ¥ä¾èµ–
                if not self._check_dependencies(task, workflow.tasks):
                    task.status = TaskStatus.SKIPPED
                    continue
                
                # æ‰§è¡Œä»»åŠ¡
                task = self.task_executor.execute_task(task)
                
                # æ›´æ–°å·¥ä½œæµç»Ÿè®¡
                if task.status == TaskStatus.COMPLETED:
                    workflow.completed_tasks += 1
                elif task.status == TaskStatus.FAILED:
                    workflow.failed_tasks += 1
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                    if task.retry_count < task.max_retries:
                        task.retry_count += 1
                        task.status = TaskStatus.PENDING
                        task.started_at = None
                        task.completed_at = None
                        task.error_message = None
                        task.output = None
                        
                        # é‡æ–°æ‰§è¡Œä»»åŠ¡
                        task = self.task_executor.execute_task(task)
                        
                        if task.status == TaskStatus.COMPLETED:
                            workflow.completed_tasks += 1
                        else:
                            workflow.failed_tasks += 1
            
            # æ›´æ–°å·¥ä½œæµçŠ¶æ€
            if workflow.failed_tasks > 0:
                workflow.status = TaskStatus.FAILED
            else:
                workflow.status = TaskStatus.COMPLETED
            
            workflow.completed_at = datetime.now().isoformat()
            
        except Exception as e:
            workflow.status = TaskStatus.FAILED
            workflow.completed_at = datetime.now().isoformat()
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {workflow.name} - {e}")
        
        logger.info(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {workflow.name} - {workflow.status.value}")
        return workflow
    
    def _sort_tasks_by_dependencies(self, tasks: List[Task]) -> List[Task]:
        """æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡"""
        sorted_tasks = []
        remaining_tasks = tasks.copy()
        
        while remaining_tasks:
            # æ‰¾åˆ°æ²¡æœ‰æœªæ»¡è¶³ä¾èµ–çš„ä»»åŠ¡
            ready_tasks = []
            for task in remaining_tasks:
                if self._check_dependencies(task, sorted_tasks):
                    ready_tasks.append(task)
            
            if not ready_tasks:
                # å¦‚æœæ‰€æœ‰å‰©ä½™ä»»åŠ¡éƒ½æœ‰æœªæ»¡è¶³çš„ä¾èµ–ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
                ready_tasks = [remaining_tasks[0]]
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            ready_tasks.sort(key=lambda t: t.priority.value, reverse=True)
            
            # æ·»åŠ åˆ°æ’åºåˆ—è¡¨
            for task in ready_tasks:
                sorted_tasks.append(task)
                remaining_tasks.remove(task)
        
        return sorted_tasks
    
    def _check_dependencies(self, task: Task, completed_tasks: List[Task]) -> bool:
        """æ£€æŸ¥ä»»åŠ¡ä¾èµ–"""
        if not task.dependencies:
            return True
        
        completed_task_ids = {t.id for t in completed_tasks if t.status == TaskStatus.COMPLETED}
        
        for dep_id in task.dependencies:
            if dep_id not in completed_task_ids:
                return False
        
        return True
    
    def get_workflow_status(self, workflow_id: str) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        if workflow_id not in self.workflows:
            return {'error': f'å·¥ä½œæµä¸å­˜åœ¨: {workflow_id}'}
        
        workflow = self.workflows[workflow_id]
        
        return {
            'workflow_id': workflow.id,
            'name': workflow.name,
            'status': workflow.status.value,
            'total_tasks': workflow.total_tasks,
            'completed_tasks': workflow.completed_tasks,
            'failed_tasks': workflow.failed_tasks,
            'progress': workflow.completed_tasks / workflow.total_tasks if workflow.total_tasks > 0 else 0,
            'created_at': workflow.created_at,
            'started_at': workflow.started_at,
            'completed_at': workflow.completed_at
        }

class WorkflowOrchestrator:
    """å·¥ä½œæµç¼–æ’å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.scheduler = WorkflowScheduler()
        self.workflow_configs = self._load_workflow_configs()
    
    def _load_workflow_configs(self) -> Dict[str, Any]:
        """åŠ è½½å·¥ä½œæµé…ç½®"""
        try:
            config_path = Path("config/workflow_configs.yaml")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            return {}
        except Exception as e:
            logger.error(f"åŠ è½½å·¥ä½œæµé…ç½®å¤±è´¥: {e}")
            return {}
    
    def run_automated_workflows(self) -> Dict[str, Any]:
        """è¿è¡Œè‡ªåŠ¨åŒ–å·¥ä½œæµ"""
        logger.info("å¼€å§‹è¿è¡Œè‡ªåŠ¨åŒ–å·¥ä½œæµ...")
        
        results = {}
        
        # è¿è¡Œé¢„å®šä¹‰çš„å·¥ä½œæµ
        for workflow_id, config in self.workflow_configs.items():
            try:
                logger.info(f"è¿è¡Œå·¥ä½œæµ: {workflow_id}")
                
                # åˆ›å»ºå·¥ä½œæµ
                workflow = self.scheduler.create_workflow(
                    workflow_id=workflow_id,
                    name=config['name'],
                    description=config.get('description', ''),
                    tasks=config['tasks']
                )
                
                # æ‰§è¡Œå·¥ä½œæµ
                executed_workflow = self.scheduler.execute_workflow(workflow_id)
                
                # ä¿å­˜ç»“æœ
                results[workflow_id] = {
                    'status': executed_workflow.status.value,
                    'total_tasks': executed_workflow.total_tasks,
                    'completed_tasks': executed_workflow.completed_tasks,
                    'failed_tasks': executed_workflow.failed_tasks,
                    'progress': executed_workflow.completed_tasks / executed_workflow.total_tasks if executed_workflow.total_tasks > 0 else 0
                }
                
            except Exception as e:
                logger.error(f"è¿è¡Œå·¥ä½œæµå¤±è´¥: {workflow_id} - {e}")
                results[workflow_id] = {
                    'status': 'failed',
                    'error': str(e)
                }
        
        # ç”Ÿæˆå·¥ä½œæµæŠ¥å‘Š
        report_content = self._generate_workflow_report(results)
        
        # ä¿å­˜æŠ¥å‘Š
        self._save_workflow_report(report_content)
        
        logger.info("è‡ªåŠ¨åŒ–å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
        return {
            'workflow_results': results,
            'report_content': report_content
        }
    
    def _generate_workflow_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå·¥ä½œæµæŠ¥å‘Š"""
        report_content = f"""# OpenTelemetry 2025 è‡ªåŠ¨åŒ–å·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Š

## ğŸ“Š æŠ¥å‘Šæ¦‚è¿°

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æŠ¥å‘Šç‰ˆæœ¬**: 1.0.0
**æ‰§è¡Œå·¥ä½œæµæ•°é‡**: {len(results)}

## ğŸ”„ å·¥ä½œæµæ‰§è¡Œç»“æœ

### æ€»ä½“ç»Ÿè®¡
- **æˆåŠŸå·¥ä½œæµ**: {sum(1 for r in results.values() if r.get('status') == 'completed')}
- **å¤±è´¥å·¥ä½œæµ**: {sum(1 for r in results.values() if r.get('status') == 'failed')}
- **æ€»ä»»åŠ¡æ•°**: {sum(r.get('total_tasks', 0) for r in results.values())}
- **å®Œæˆä»»åŠ¡æ•°**: {sum(r.get('completed_tasks', 0) for r in results.values())}
- **å¤±è´¥ä»»åŠ¡æ•°**: {sum(r.get('failed_tasks', 0) for r in results.values())}

### å„å·¥ä½œæµè¯¦æƒ…
"""
        
        # æ·»åŠ å„å·¥ä½œæµè¯¦ç»†ç»“æœ
        for workflow_id, result in results.items():
            report_content += f"""
#### {workflow_id}

- **çŠ¶æ€**: {result.get('status', 'unknown')}
- **æ€»ä»»åŠ¡æ•°**: {result.get('total_tasks', 0)}
- **å®Œæˆä»»åŠ¡æ•°**: {result.get('completed_tasks', 0)}
- **å¤±è´¥ä»»åŠ¡æ•°**: {result.get('failed_tasks', 0)}
- **è¿›åº¦**: {result.get('progress', 0):.2%}
"""
            
            if 'error' in result:
                report_content += f"- **é”™è¯¯ä¿¡æ¯**: {result['error']}\n"
        
        # æ·»åŠ æ”¹è¿›å»ºè®®
        report_content += "\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        suggestions = self._generate_workflow_suggestions(results)
        for i, suggestion in enumerate(suggestions, 1):
            report_content += f"{i}. {suggestion}\n"
        
        # æ·»åŠ ç»“è®º
        report_content += f"""

## ğŸ“‹ ç»“è®º

OpenTelemetry 2025è‡ªåŠ¨åŒ–å·¥ä½œæµæ‰§è¡Œ{'æˆåŠŸ' if all(r.get('status') == 'completed' for r in results.values()) else 'éƒ¨åˆ†æˆåŠŸ'}ï¼Œå…±æ‰§è¡Œ {len(results)} ä¸ªå·¥ä½œæµã€‚

### ä¸»è¦æˆå°±
- è‡ªåŠ¨åŒ–å·¥ä½œæµç³»ç»Ÿè¿è¡Œæ­£å¸¸
- å¤§éƒ¨åˆ†å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ
- ä»»åŠ¡è°ƒåº¦å’Œä¾èµ–ç®¡ç†æœºåˆ¶æœ‰æ•ˆ

### éœ€è¦å…³æ³¨çš„é—®é¢˜
- éƒ¨åˆ†å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥é”™è¯¯åŸå› 
- æŸäº›ä»»åŠ¡å¯èƒ½éœ€è¦ä¼˜åŒ–æ‰§è¡Œæ—¶é—´
- éœ€è¦å»ºç«‹æ›´å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. ä¿®å¤å¤±è´¥çš„å·¥ä½œæµ
2. ä¼˜åŒ–ä»»åŠ¡æ‰§è¡Œæ•ˆç‡
3. å®Œå–„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
4. å»ºç«‹å·¥ä½œæµç›‘æ§å’Œå‘Šè­¦æœºåˆ¶

---
*æœ¬æŠ¥å‘Šç”±OpenTelemetry 2025è‡ªåŠ¨åŒ–å·¥ä½œæµç¼–æ’å™¨ç”Ÿæˆ*
"""
        
        return report_content
    
    def _generate_workflow_suggestions(self, results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå·¥ä½œæµæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        # åŸºäºæ‰§è¡Œç»“æœçš„å»ºè®®
        failed_workflows = [wf_id for wf_id, result in results.items() if result.get('status') == 'failed']
        if failed_workflows:
            suggestions.append(f"ä¿®å¤å¤±è´¥çš„å·¥ä½œæµ: {', '.join(failed_workflows)}")
        
        # åŸºäºä»»åŠ¡å®Œæˆç‡çš„å»ºè®®
        low_completion_workflows = [
            wf_id for wf_id, result in results.items() 
            if result.get('progress', 0) < 0.8 and result.get('status') != 'failed'
        ]
        if low_completion_workflows:
            suggestions.append(f"ä¼˜åŒ–ä½å®Œæˆç‡å·¥ä½œæµ: {', '.join(low_completion_workflows)}")
        
        # åŸºäºæ‰§è¡Œæ—¶é—´çš„å»ºè®®
        suggestions.append("å»ºç«‹å·¥ä½œæµæ‰§è¡Œæ—¶é—´ç›‘æ§ï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆ")
        
        # åŸºäºé”™è¯¯å¤„ç†çš„å»ºè®®
        suggestions.append("å®Œå–„é”™è¯¯å¤„ç†æœºåˆ¶ï¼Œæé«˜å·¥ä½œæµç¨³å®šæ€§")
        
        return suggestions
    
    def _save_workflow_report(self, report_content: str):
        """ä¿å­˜å·¥ä½œæµæŠ¥å‘Š"""
        try:
            # åˆ›å»ºæŠ¥å‘Šç›®å½•
            report_dir = Path("reports")
            report_dir.mkdir(exist_ok=True)
            
            # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = report_dir / f"workflow_execution_report_{timestamp}.md"
            
            # ä¿å­˜æŠ¥å‘Š
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            logger.info(f"å·¥ä½œæµæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å·¥ä½œæµæŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºå·¥ä½œæµç¼–æ’å™¨å®ä¾‹
        orchestrator = WorkflowOrchestrator()
        
        # è¿è¡Œè‡ªåŠ¨åŒ–å·¥ä½œæµ
        results = orchestrator.run_automated_workflows()
        
        # è¾“å‡ºç®€è¦ç»“æœ
        print("\n" + "="*60)
        print("OpenTelemetry 2025 è‡ªåŠ¨åŒ–å·¥ä½œæµæ‰§è¡Œç»“æœ")
        print("="*60)
        
        workflow_results = results['workflow_results']
        print(f"ğŸ”„ æ‰§è¡Œå·¥ä½œæµæ•°é‡: {len(workflow_results)}")
        
        # ç»Ÿè®¡æ‰§è¡Œç»“æœ
        success_count = sum(1 for r in workflow_results.values() if r.get('status') == 'completed')
        failed_count = sum(1 for r in workflow_results.values() if r.get('status') == 'failed')
        
        print(f"âœ… æˆåŠŸå·¥ä½œæµ: {success_count}")
        print(f"âŒ å¤±è´¥å·¥ä½œæµ: {failed_count}")
        
        # æ˜¾ç¤ºå„å·¥ä½œæµçŠ¶æ€
        print("\nğŸ“Š å„å·¥ä½œæµçŠ¶æ€:")
        for workflow_id, result in workflow_results.items():
            status = result.get('status', 'unknown')
            progress = result.get('progress', 0)
            print(f"  - {workflow_id}: {status} ({progress:.2%})")
        
        print("\nè¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹ reports/ ç›®å½•")
        print("="*60)
        
    except Exception as e:
        logger.error(f"è¿è¡Œè‡ªåŠ¨åŒ–å·¥ä½œæµæ—¶å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
