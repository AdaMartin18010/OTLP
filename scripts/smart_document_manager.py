#!/usr/bin/env python3
"""
OpenTelemetry 2025 æ™ºèƒ½æ–‡æ¡£ç®¡ç†ç³»ç»Ÿ
è‡ªåŠ¨ç»´æŠ¤æ–‡æ¡£ç»“æ„ã€ç”Ÿæˆç›®å½•ã€æ›´æ–°å¯¼èˆª
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import yaml
from datetime import datetime
import hashlib

class SmartDocumentManager:
    def __init__(self, doc_root: str = "doc"):
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ä½œä¸ºé¡¹ç›®æ ¹ç›®å½•
        script_dir = Path(__file__).parent
        project_root = script_dir.parent
        self.doc_root = project_root / doc_root
        self.cache_file = script_dir / ".document_cache.json"
        self.config_file = script_dir / "document_config.yaml"
        self.load_config()
        self.load_cache()
        
    def load_config(self):
        """åŠ è½½é…ç½®"""
        default_config = {
            "auto_update": True,
            "generate_toc": True,
            "update_navigation": True,
            "backup_changes": True,
            "exclude_patterns": [
                "*.tmp",
                "*.bak",
                ".git/*",
                "node_modules/*"
            ],
            "module_mapping": {
                "00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª": "é¡¹ç›®æ¦‚è§ˆ",
                "01_ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜": "ç†è®ºåŸºç¡€",
                "02_OTLPæ ‡å‡†æ·±åº¦åˆ†æ": "æ ‡å‡†åˆ†æ",
                "03_è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ": "æœ€ä½³å®è·µ",
                "04_å½¢å¼è®ºè¯ä¸è¯æ˜ä½“ç³»": "å½¢å¼è®ºè¯",
                "05_æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·": "æ‰¹åˆ¤åˆ†æ",
                "06_å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°": "å­¦æœ¯ç ”ç©¶",
                "07_å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ": "å®æ–½æŒ‡å—",
                "08_å¯æŒç»­å‘å±•è®¡åˆ’": "å¯æŒç»­å‘å±•",
                "09_é™„å½•ä¸å‚è€ƒèµ„æ–™": "å‚è€ƒèµ„æ–™"
            }
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.config = yaml.safe_load(f)
            except:
                self.config = default_config
        else:
            self.config = default_config
            self.save_config()
    
    def save_config(self):
        """ä¿å­˜é…ç½®"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
    
    def load_cache(self):
        """åŠ è½½ç¼“å­˜"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
            except:
                self.cache = {"files": {}, "last_scan": None}
        else:
            self.cache = {"files": {}, "last_scan": None}
    
    def save_cache(self):
        """ä¿å­˜ç¼“å­˜"""
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)
    
    def get_file_hash(self, file_path: Path) -> str:
        """è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return ""
    
    def scan_documents(self) -> Dict:
        """æ‰«ææ–‡æ¡£ç»“æ„"""
        print("ğŸ” æ‰«ææ–‡æ¡£ç»“æ„...")
        documents = {}
        changed_files = []
        
        for item in sorted(self.doc_root.iterdir()):
            if item.is_dir() and not item.name.startswith('.'):
                module_info = self._scan_module(item)
                documents[item.name] = module_info
                
                # æ£€æŸ¥æ–‡ä»¶å˜åŒ–
                for file_info in module_info.get('files', []):
                    file_path = Path(file_info['path'])
                    current_hash = self.get_file_hash(file_path)
                    cached_hash = self.cache.get('files', {}).get(str(file_path), '')
                    
                    if current_hash != cached_hash:
                        changed_files.append(str(file_path))
                        self.cache['files'][str(file_path)] = current_hash
        
        self.cache['last_scan'] = datetime.now().isoformat()
        self.save_cache()
        
        print(f"ğŸ“ æ‰«æäº† {len(documents)} ä¸ªæ¨¡å—")
        print(f"ğŸ”„ å‘ç° {len(changed_files)} ä¸ªæ–‡ä»¶æœ‰å˜åŒ–")
        
        return documents, changed_files
    
    def _scan_module(self, module_path: Path) -> Dict:
        """æ‰«ææ¨¡å—"""
        module_info = {
            'name': module_path.name,
            'display_name': self.config['module_mapping'].get(module_path.name, module_path.name),
            'files': [],
            'submodules': {},
            'readme': None,
            'stats': {
                'total_files': 0,
                'total_size': 0,
                'last_modified': None
            }
        }
        
        for item in sorted(module_path.iterdir()):
            if item.is_file() and item.suffix == '.md':
                file_info = self._analyze_file(item)
                module_info['files'].append(file_info)
                module_info['stats']['total_files'] += 1
                module_info['stats']['total_size'] += file_info['size']
                
                if item.name.lower() in ['readme.md', 'index.md']:
                    module_info['readme'] = file_info
                    
            elif item.is_dir() and not item.name.startswith('.'):
                submodule_info = self._scan_module(item)
                module_info['submodules'][item.name] = submodule_info
                module_info['stats']['total_files'] += submodule_info['stats']['total_files']
                module_info['stats']['total_size'] += submodule_info['stats']['total_size']
        
        return module_info
    
    def _analyze_file(self, file_path: Path) -> Dict:
        """åˆ†ææ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–å…ƒæ•°æ®
            title = self._extract_title(content, file_path)
            created_time = self._extract_metadata(content, 'åˆ›å»ºæ—¶é—´')
            version = self._extract_metadata(content, 'æ–‡æ¡£ç‰ˆæœ¬')
            status = self._extract_metadata(content, 'çŠ¶æ€')
            maintainer = self._extract_metadata(content, 'ç»´æŠ¤è€…')
            
            # åˆ†æå†…å®¹
            word_count = len(content.split())
            line_count = len(content.splitlines())
            
            return {
                'name': file_path.name,
                'path': str(file_path.relative_to(self.doc_root)),
                'title': title,
                'created_time': created_time or "æœªçŸ¥",
                'version': version or "1.0.0",
                'status': status or "æ´»è·ƒ",
                'maintainer': maintainer or "æœªçŸ¥",
                'size': file_path.stat().st_size,
                'word_count': word_count,
                'line_count': line_count,
                'modified': datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                'hash': self.get_file_hash(file_path)
            }
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")
            return {
                'name': file_path.name,
                'path': str(file_path.relative_to(self.doc_root)),
                'title': file_path.stem,
                'created_time': "æœªçŸ¥",
                'version': "1.0.0",
                'status': "æœªçŸ¥",
                'maintainer': "æœªçŸ¥",
                'size': 0,
                'word_count': 0,
                'line_count': 0,
                'modified': "æœªçŸ¥",
                'hash': ""
            }
    
    def _extract_title(self, content: str, file_path: Path) -> str:
        """æå–æ ‡é¢˜"""
        # å°è¯•æå–ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        if title_match:
            return title_match.group(1).strip()
        
        # å°è¯•æå–ç¬¬ä¸€ä¸ªäºŒçº§æ ‡é¢˜
        title_match = re.search(r'^##\s+(.+)$', content, re.MULTILINE)
        if title_match:
            return title_match.group(1).strip()
        
        return file_path.stem
    
    def _extract_metadata(self, content: str, key: str) -> Optional[str]:
        """æå–å…ƒæ•°æ®"""
        pattern = rf'\*\*{re.escape(key)}\*\*:\s*(.+)'
        match = re.search(pattern, content)
        return match.group(1).strip() if match else None
    
    def generate_comprehensive_toc(self, documents: Dict) -> str:
        """ç”Ÿæˆç»¼åˆç›®å½•"""
        lines = [
            "# OpenTelemetry 2025 çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®å®Œæ•´ç›®å½•",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
            f"**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0",
            f"**ç»´æŠ¤è€…**: OpenTelemetry 2025 æ™ºèƒ½æ–‡æ¡£ç®¡ç†ç³»ç»Ÿ",
            f"**çŠ¶æ€**: çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®",
            f"**ç›®å½•èŒƒå›´**: å®Œæ•´æ–‡æ¡£ä½“ç³»ç›®å½•",
            "",
            "## ğŸ¯ ç›®å½•æ¦‚è§ˆ",
            "",
            "### é¡¹ç›®ç»Ÿè®¡",
            ""
        ]
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_modules = len(documents)
        total_files = sum(module['stats']['total_files'] for module in documents.values())
        total_size = sum(module['stats']['total_size'] for module in documents.values())
        
        lines.extend([
            f"- **æ€»æ¨¡å—æ•°**: {total_modules}",
            f"- **æ€»æ–‡æ¡£æ•°**: {total_files}",
            f"- **æ€»å¤§å°**: {total_size / 1024 / 1024:.1f} MB",
            f"- **å¹³å‡æ¯æ¨¡å—æ–‡æ¡£æ•°**: {total_files / total_modules:.1f}",
            "",
            "### æ¨¡å—æ¦‚è§ˆ",
            ""
        ])
        
        # æ¨¡å—æ¦‚è§ˆ
        for module_name, module_info in documents.items():
            display_name = module_info['display_name']
            file_count = module_info['stats']['total_files']
            size_mb = module_info['stats']['total_size'] / 1024 / 1024
            lines.append(f"- **{display_name}** ({module_name}) - {file_count} ä¸ªæ–‡æ¡£ ({size_mb:.1f} MB)")
        
        lines.extend([
            "",
            "## ğŸ“š è¯¦ç»†ç›®å½•ç»“æ„",
            ""
        ])
        
        # è¯¦ç»†ç›®å½•
        for module_name, module_info in documents.items():
            lines.extend(self._generate_module_toc(module_name, module_info, 0))
        
        # æ·»åŠ å¿«é€Ÿå¯¼èˆª
        lines.extend(self._generate_quick_navigation(documents))
        
        return "\n".join(lines)
    
    def _generate_module_toc(self, name: str, module_info: Dict, level: int) -> List[str]:
        """ç”Ÿæˆæ¨¡å—ç›®å½•"""
        lines = []
        indent = "  " * level
        
        # æ¨¡å—æ ‡é¢˜
        if level == 0:
            display_name = module_info['display_name']
            lines.append(f"### {display_name} ({name})")
            lines.append("")
            
            # æ¨¡å—ç»Ÿè®¡
            stats = module_info['stats']
            lines.append(f"**æ¨¡å—ç»Ÿè®¡**: {stats['total_files']} ä¸ªæ–‡æ¡£, {stats['total_size'] / 1024 / 1024:.1f} MB")
            lines.append("")
        else:
            lines.append(f"{indent}- **{name}**")
            lines.append("")
        
        # READMEæ–‡ä»¶
        if module_info.get('readme'):
            readme = module_info['readme']
            lines.append(f"{indent}  - ğŸ“– [{readme['title']}]({readme['path']}) - æ¨¡å—å…¥å£")
            lines.append("")
        
        # ä¸»è¦æ–‡æ¡£
        main_files = [f for f in module_info.get('files', []) 
                     if f != module_info.get('readme') and 
                     not any(keyword in f['name'].lower() 
                            for keyword in ['readme', 'index', 'toc', 'summary'])]
        
        if main_files:
            lines.append(f"{indent}  **æ ¸å¿ƒæ–‡æ¡£**:")
            for file_info in main_files:
                lines.append(f"{indent}  - [{file_info['title']}]({file_info['path']})")
            lines.append("")
        
        # å­æ¨¡å—
        for submodule_name, submodule_info in module_info.get('submodules', {}).items():
            lines.extend(self._generate_module_toc(submodule_name, submodule_info, level + 1))
        
        return lines
    
    def _generate_quick_navigation(self, documents: Dict) -> List[str]:
        """ç”Ÿæˆå¿«é€Ÿå¯¼èˆª"""
        lines = [
            "## ğŸ—ºï¸ å¿«é€Ÿå¯¼èˆª",
            "",
            "### æŒ‰ä¸»é¢˜å¯¼èˆª",
            ""
        ]
        
        # æŒ‰ä¸»é¢˜åˆ†ç±»
        theme_mapping = {
            "ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ": ["00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª"],
            "ğŸ§® ç†è®ºåŸºç¡€": ["01_ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜", "04_å½¢å¼è®ºè¯ä¸è¯æ˜ä½“ç³»"],
            "ğŸ“Š æ ‡å‡†åˆ†æ": ["02_OTLPæ ‡å‡†æ·±åº¦åˆ†æ", "03_è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ"],
            "ğŸ”¬ å­¦æœ¯ç ”ç©¶": ["06_å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°"],
            "ğŸ” æ‰¹åˆ¤åˆ†æ": ["05_æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·"],
            "ğŸ› ï¸ å®æ–½æŒ‡å—": ["07_å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ"],
            "ğŸŒ± å¯æŒç»­å‘å±•": ["08_å¯æŒç»­å‘å±•è®¡åˆ’"],
            "ğŸ“š å‚è€ƒèµ„æ–™": ["09_é™„å½•ä¸å‚è€ƒèµ„æ–™"]
        }
        
        for theme, modules in theme_mapping.items():
            lines.append(f"#### {theme}")
            for module in modules:
                if module in documents:
                    module_info = documents[module]
                    display_name = module_info['display_name']
                    file_count = module_info['stats']['total_files']
                    lines.append(f"- [{display_name}]({module}/) - {file_count} ä¸ªæ–‡æ¡£")
            lines.append("")
        
        lines.extend([
            "### æŒ‰ç”¨æˆ·ç±»å‹å¯¼èˆª",
            "",
            "#### ğŸ‘¨â€ğŸ”¬ ç ”ç©¶äººå‘˜",
            "- [ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜](01_ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜/)",
            "- [å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°](06_å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°/)",
            "- [æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·](05_æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·/)",
            "",
            "#### ğŸ‘¨â€ğŸ’» å·¥ç¨‹å¸ˆ",
            "- [OTLPæ ‡å‡†æ·±åº¦åˆ†æ](02_OTLPæ ‡å‡†æ·±åº¦åˆ†æ/)",
            "- [å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ](07_å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ/)",
            "- [è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ](03_è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ/)",
            "",
            "#### ğŸ‘¨â€ğŸ’¼ ç®¡ç†è€…",
            "- [é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª](00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª/)",
            "- [å¯æŒç»­å‘å±•è®¡åˆ’](08_å¯æŒç»­å‘å±•è®¡åˆ’/)",
            "- [é™„å½•ä¸å‚è€ƒèµ„æ–™](09_é™„å½•ä¸å‚è€ƒèµ„æ–™/)",
            "",
            "---",
            "",
            f"**ç›®å½•ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
            f"**ç›®å½•ç‰ˆæœ¬**: 2.0.0",
            f"**ç»´æŠ¤è€…**: OpenTelemetry 2025 æ™ºèƒ½æ–‡æ¡£ç®¡ç†ç³»ç»Ÿ",
            f"**ä¸‹æ¬¡è‡ªåŠ¨æ›´æ–°**: {(datetime.now().replace(day=datetime.now().day+1)).strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        ])
        
        return lines
    
    def update_navigation_file(self, documents: Dict):
        """æ›´æ–°ä¸»å¯¼èˆªæ–‡ä»¶"""
        nav_file = self.doc_root / "00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª" / "æ–‡æ¡£å¯¼èˆªä¸ç´¢å¼•.md"
        
        if not nav_file.exists():
            print(f"âš ï¸ å¯¼èˆªæ–‡ä»¶ä¸å­˜åœ¨: {nav_file}")
            return
        
        # ç”Ÿæˆæ–°çš„å¯¼èˆªå†…å®¹
        nav_content = self.generate_navigation_content(documents)
        
        # å¤‡ä»½åŸæ–‡ä»¶
        if self.config.get('backup_changes', True):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = nav_file.with_suffix(f'.md.backup_{timestamp}')
            if backup_file.exists():
                backup_file.unlink()
            nav_file.rename(backup_file)
            print(f"ğŸ“¦ å·²å¤‡ä»½åŸæ–‡ä»¶: {backup_file}")
        
        # å†™å…¥æ–°å†…å®¹
        with open(nav_file, 'w', encoding='utf-8') as f:
            f.write(nav_content)
        
        print(f"âœ… å·²æ›´æ–°å¯¼èˆªæ–‡ä»¶: {nav_file}")
    
    def generate_navigation_content(self, documents: Dict) -> str:
        """ç”Ÿæˆå¯¼èˆªå†…å®¹"""
        lines = [
            "# OpenTelemetry 2025 çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®æ–‡æ¡£å¯¼èˆª",
            "",
            "## ğŸ“Š å¯¼èˆªæ¦‚è§ˆ",
            "",
            f"**åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
            f"**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0",
            f"**ç»´æŠ¤è€…**: OpenTelemetry 2025 å­¦æœ¯ç ”ç©¶å›¢é˜Ÿ",
            f"**çŠ¶æ€**: çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®",
            f"**å¯¼èˆªèŒƒå›´**: å®Œæ•´æ–‡æ¡£ä½“ç³»å¯¼èˆª",
            "",
            "## ğŸ¯ å¯¼èˆªç›®æ ‡",
            "",
            "### ä¸»è¦ç›®æ ‡",
            "",
            "1. **å®Œæ•´å¯¼èˆª**: æä¾›å®Œæ•´çš„æ–‡æ¡£ä½“ç³»å¯¼èˆª",
            "2. **å¿«é€Ÿå®šä½**: æ”¯æŒå¿«é€Ÿå®šä½æ‰€éœ€å†…å®¹",
            "3. **é€»è¾‘æ¸…æ™°**: æä¾›æ¸…æ™°çš„é€»è¾‘ç»“æ„",
            "4. **æ˜“äºç»´æŠ¤**: æ”¯æŒæ˜“äºç»´æŠ¤çš„å¯¼èˆªç»“æ„",
            "5. **ç”¨æˆ·å‹å¥½**: æä¾›ç”¨æˆ·å‹å¥½çš„å¯¼èˆªä½“éªŒ",
            "",
            "### æˆåŠŸæ ‡å‡†",
            "",
            "- **å¯¼èˆªå®Œæ•´æ€§**: 100%æ–‡æ¡£è¦†ç›–",
            "- **å®šä½å‡†ç¡®æ€§**: å¿«é€Ÿå‡†ç¡®çš„å†…å®¹å®šä½",
            "- **ç»“æ„æ¸…æ™°æ€§**: æ¸…æ™°çš„é€»è¾‘ç»“æ„",
            "- **ç»´æŠ¤ä¾¿åˆ©æ€§**: æ˜“äºç»´æŠ¤å’Œæ›´æ–°",
            "- **ç”¨æˆ·ä½“éªŒ**: è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒ",
            "",
            "## ğŸ—ºï¸ å®Œæ•´æ–‡æ¡£å¯¼èˆª",
            ""
        ]
        
        # ç”Ÿæˆæ¨¡å—å¯¼èˆª
        for module_name, module_info in documents.items():
            lines.extend(self._generate_module_navigation(module_name, module_info))
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        lines.extend(self._generate_navigation_statistics(documents))
        
        return "\n".join(lines)
    
    def _generate_module_navigation(self, module_name: str, module_info: Dict) -> List[str]:
        """ç”Ÿæˆæ¨¡å—å¯¼èˆª"""
        lines = []
        display_name = module_info['display_name']
        
        # æ¨¡å—æ ‡é¢˜
        lines.append(f"### {display_name}")
        lines.append("")
        
        # æ¨¡å—æè¿°
        if module_info.get('readme'):
            readme = module_info['readme']
            lines.append(f"**æ¨¡å—å…¥å£**: [{readme['title']}]({readme['path']})")
            lines.append("")
        
        # ä¸»è¦æ–‡æ¡£
        main_files = [f for f in module_info.get('files', []) 
                     if f != module_info.get('readme') and 
                     not any(keyword in f['name'].lower() 
                            for keyword in ['readme', 'index', 'toc', 'summary'])]
        
        if main_files:
            lines.append("#### æ ¸å¿ƒæ–‡æ¡£")
            lines.append("")
            for file_info in main_files[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                lines.append(f"- [{file_info['title']}]({file_info['path']})")
            
            if len(main_files) > 10:
                lines.append(f"- ... è¿˜æœ‰ {len(main_files) - 10} ä¸ªæ–‡æ¡£")
            lines.append("")
        
        # å­æ¨¡å—
        if module_info.get('submodules'):
            lines.append("#### å­æ¨¡å—")
            lines.append("")
            for submodule_name, submodule_info in module_info['submodules'].items():
                lines.append(f"##### {submodule_name}")
                lines.append("")
                
                sub_files = submodule_info.get('files', [])
                for file_info in sub_files[:5]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    lines.append(f"- [{file_info['title']}]({file_info['path']})")
                
                if len(sub_files) > 5:
                    lines.append(f"- ... è¿˜æœ‰ {len(sub_files) - 5} ä¸ªæ–‡æ¡£")
                lines.append("")
        
        lines.append("")
        return lines
    
    def _generate_navigation_statistics(self, documents: Dict) -> List[str]:
        """ç”Ÿæˆå¯¼èˆªç»Ÿè®¡ä¿¡æ¯"""
        lines = [
            "## ğŸ“Š æ–‡æ¡£ç»Ÿè®¡",
            "",
            "### æ€»ä½“ç»Ÿè®¡",
            ""
        ]
        
        total_modules = len(documents)
        total_files = sum(module['stats']['total_files'] for module in documents.values())
        total_size = sum(module['stats']['total_size'] for module in documents.values())
        
        lines.extend([
            f"- **æ€»æ¨¡å—æ•°**: {total_modules}",
            f"- **æ€»æ–‡æ¡£æ•°**: {total_files}",
            f"- **æ€»å¤§å°**: {total_size / 1024 / 1024:.1f} MB",
            f"- **æœ€åæ›´æ–°**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
            "",
            "### æ¨¡å—ç»Ÿè®¡",
            ""
        ])
        
        for module_name, module_info in documents.items():
            display_name = module_info['display_name']
            file_count = module_info['stats']['total_files']
            size_mb = module_info['stats']['total_size'] / 1024 / 1024
            lines.append(f"- **{display_name}**: {file_count} ä¸ªæ–‡æ¡£ ({size_mb:.1f} MB)")
        
        lines.extend([
            "",
            "## ğŸ”— å¿«é€Ÿé“¾æ¥",
            "",
            "### æŒ‰ä¸»é¢˜å¯¼èˆª",
            ""
        ])
        
        # æŒ‰ä¸»é¢˜åˆ†ç±»
        theme_links = self._generate_theme_links(documents)
        lines.extend(theme_links)
        
        lines.extend([
            "",
            "### æŒ‰ç”¨æˆ·ç±»å‹å¯¼èˆª",
            "",
            "#### ç ”ç©¶äººå‘˜",
            "- [ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜](01_ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜/)",
            "- [å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°](06_å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°/)",
            "- [æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·](05_æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·/)",
            "",
            "#### å·¥ç¨‹å¸ˆ",
            "- [OTLPæ ‡å‡†æ·±åº¦åˆ†æ](02_OTLPæ ‡å‡†æ·±åº¦åˆ†æ/)",
            "- [å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ](07_å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ/)",
            "- [è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ](03_è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ/)",
            "",
            "#### ç®¡ç†è€…",
            "- [é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª](00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª/)",
            "- [å¯æŒç»­å‘å±•è®¡åˆ’](08_å¯æŒç»­å‘å±•è®¡åˆ’/)",
            "- [é™„å½•ä¸å‚è€ƒèµ„æ–™](09_é™„å½•ä¸å‚è€ƒèµ„æ–™/)",
            "",
            "---",
            "",
            f"**æ–‡æ¡£åˆ›å»ºå®Œæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
            f"**æ–‡æ¡£ç‰ˆæœ¬**: 2.0.0",
            f"**ç»´æŠ¤è€…**: OpenTelemetry 2025 å­¦æœ¯ç ”ç©¶å›¢é˜Ÿ",
            f"**ä¸‹æ¬¡å®¡æŸ¥**: {(datetime.now().replace(month=datetime.now().month+1) if datetime.now().month < 12 else datetime.now().replace(year=datetime.now().year+1, month=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')}"
        ])
        
        return lines
    
    def _generate_theme_links(self, documents: Dict) -> List[str]:
        """ç”Ÿæˆä¸»é¢˜é“¾æ¥"""
        theme_mapping = {
            "ç†è®ºåŸºç¡€": ["01_ç†è®ºåŸºç¡€ä¸å½¢å¼åŒ–è¯æ˜", "04_å½¢å¼è®ºè¯ä¸è¯æ˜ä½“ç³»"],
            "æ ‡å‡†åˆ†æ": ["02_OTLPæ ‡å‡†æ·±åº¦åˆ†æ", "03_è¡Œä¸šæ ‡å‡†ä¸æœ€ä½³å®è·µ"],
            "å­¦æœ¯ç ”ç©¶": ["06_å­¦æœ¯ç ”ç©¶ä¸ç†è®ºåˆ›æ–°"],
            "æ‰¹åˆ¤åˆ†æ": ["05_æ‰¹åˆ¤æ€§åˆ†æä¸è¯„ä»·"],
            "å®æ–½æŒ‡å—": ["07_å®æ–½æŒ‡å—ä¸æ“ä½œæ‰‹å†Œ"],
            "å¯æŒç»­å‘å±•": ["08_å¯æŒç»­å‘å±•è®¡åˆ’"],
            "å‚è€ƒèµ„æ–™": ["09_é™„å½•ä¸å‚è€ƒèµ„æ–™"]
        }
        
        lines = []
        for theme, modules in theme_mapping.items():
            lines.append(f"#### {theme}")
            for module in modules:
                if module in documents:
                    module_info = documents[module]
                    display_name = module_info['display_name']
                    lines.append(f"- [{display_name}]({module}/)")
            lines.append("")
        
        return lines
    
    def generate_statistics_report(self, documents: Dict) -> str:
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        lines = [
            "# OpenTelemetry 2025 é¡¹ç›®æ–‡æ¡£ç»Ÿè®¡æŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
            f"**æŠ¥å‘Šç‰ˆæœ¬**: 2.0.0",
            "",
            "## ğŸ“Š æ€»ä½“ç»Ÿè®¡",
            ""
        ]
        
        total_modules = len(documents)
        total_files = sum(module['stats']['total_files'] for module in documents.values())
        total_size = sum(module['stats']['total_size'] for module in documents.values())
        
        lines.extend([
            f"- **æ€»æ¨¡å—æ•°**: {total_modules}",
            f"- **æ€»æ–‡æ¡£æ•°**: {total_files}",
            f"- **æ€»å¤§å°**: {total_size / 1024 / 1024:.1f} MB",
            f"- **å¹³å‡æ¯æ¨¡å—æ–‡æ¡£æ•°**: {total_files / total_modules:.1f}",
            f"- **å¹³å‡æ–‡æ¡£å¤§å°**: {total_size / total_files / 1024:.1f} KB",
            "",
            "## ğŸ“ æ¨¡å—è¯¦ç»†ç»Ÿè®¡",
            ""
        ])
        
        for module_name, module_info in documents.items():
            display_name = module_info['display_name']
            stats = module_info['stats']
            submodule_count = len(module_info.get('submodules', {}))
            
            lines.extend([
                f"### {display_name} ({module_name})",
                f"- **æ–‡æ¡£æ•°é‡**: {stats['total_files']}",
                f"- **å­æ¨¡å—æ•°é‡**: {submodule_count}",
                f"- **æ€»å¤§å°**: {stats['total_size'] / 1024 / 1024:.1f} MB",
                ""
            ])
            
            # åˆ—å‡ºä¸»è¦æ–‡æ¡£
            main_files = module_info.get('files', [])[:5]
            if main_files:
                lines.append("**ä¸»è¦æ–‡æ¡£**:")
                for file_info in main_files:
                    size_kb = file_info['size'] / 1024
                    lines.append(f"- [{file_info['title']}]({file_info['path']}) ({size_kb:.1f} KB)")
                lines.append("")
        
        return "\n".join(lines)
    
    def run_full_update(self):
        """è¿è¡Œå®Œæ•´æ›´æ–°"""
        print("ğŸš€ OpenTelemetry 2025 æ™ºèƒ½æ–‡æ¡£ç®¡ç†ç³»ç»Ÿ")
        print("=" * 60)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ‰«ææ–‡æ¡£
        documents, changed_files = self.scan_documents()
        
        if not documents:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
            return
        
        # ç”Ÿæˆç›®å½•
        if self.config.get('generate_toc', True):
            print("\nğŸ“ ç”Ÿæˆå®Œæ•´ç›®å½•...")
            toc_content = self.generate_comprehensive_toc(documents)
            
            toc_file = self.doc_root / "00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª" / "è‡ªåŠ¨ç”Ÿæˆå®Œæ•´ç›®å½•.md"
            with open(toc_file, 'w', encoding='utf-8') as f:
                f.write(toc_content)
            print(f"âœ… å·²ç”Ÿæˆå®Œæ•´ç›®å½•: {toc_file}")
        
        # æ›´æ–°å¯¼èˆª
        if self.config.get('update_navigation', True):
            print("\nğŸ—ºï¸ æ›´æ–°å¯¼èˆªæ–‡ä»¶...")
            self.update_navigation_file(documents)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        stats_content = self.generate_statistics_report(documents)
        
        stats_file = self.doc_root / "00_é¡¹ç›®æ¦‚è§ˆä¸å¯¼èˆª" / "æ–‡æ¡£ç»Ÿè®¡æŠ¥å‘Š.md"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(stats_content)
        print(f"âœ… å·²ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š: {stats_file}")
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰§è¡Œç»“æœæ±‡æ€»")
        print(f"âœ… æ‰«ææ¨¡å—: {len(documents)}")
        print(f"ğŸ“„ æ€»æ–‡æ¡£æ•°: {sum(module['stats']['total_files'] for module in documents.values())}")
        print(f"ğŸ”„ å˜åŒ–æ–‡ä»¶: {len(changed_files)}")
        print(f"ğŸ“ æ€»å¤§å°: {sum(module['stats']['total_size'] for module in documents.values()) / 1024 / 1024:.1f} MB")
        
        print("\nğŸ‰ æ™ºèƒ½æ–‡æ¡£ç®¡ç†å®Œæˆ!")
        print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

def main():
    """ä¸»å‡½æ•°"""
    manager = SmartDocumentManager()
    manager.run_full_update()

if __name__ == "__main__":
    main()
