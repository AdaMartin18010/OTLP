#!/usr/bin/env python3
"""
OpenTelemetry 2025 è‡ªåŠ¨æ–‡æ¡£æ›´æ–°å™¨
æ£€æµ‹æ–‡æ¡£å˜åŒ–å¹¶è‡ªåŠ¨æ›´æ–°ç›¸å…³å†…å®¹
"""

import os
import re
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import yaml
from datetime import datetime
import hashlib
import difflib

class AutoDocumentUpdater:
    def __init__(self, doc_root: str = "doc"):
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ä½œä¸ºé¡¹ç›®æ ¹ç›®å½•
        script_dir = Path(__file__).parent
        project_root = script_dir.parent
        self.doc_root = project_root / doc_root
        self.cache_file = script_dir / ".document_cache.json"
        self.backup_dir = script_dir / "backups"
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # æ–‡æ¡£æ¨¡æ¿
        self.templates = {
            "standard_doc": {
                "header": """# {title}

## ğŸ“Š {title}æ¦‚è§ˆ

**åˆ›å»ºæ—¶é—´**: {created_time}  
**æ–‡æ¡£ç‰ˆæœ¬**: {version}  
**ç»´æŠ¤è€…**: {maintainer}  
**çŠ¶æ€**: {status}  
**{title}èŒƒå›´**: {scope}

## ğŸ¯ {title}ç›®æ ‡

### ä¸»è¦ç›®æ ‡

1. **ç›®æ ‡1**: {goal1}
2. **ç›®æ ‡2**: {goal2}
3. **ç›®æ ‡3**: {goal3}
4. **ç›®æ ‡4**: {goal4}
5. **ç›®æ ‡5**: {goal5}

### æˆåŠŸæ ‡å‡†

- **æ ‡å‡†1**: {standard1}
- **æ ‡å‡†2**: {standard2}
- **æ ‡å‡†3**: {standard3}
- **æ ‡å‡†4**: {standard4}
- **æ ‡å‡†5**: {standard5}
""",
                "footer": """
## ğŸ“š æ€»ç»“

{title}ä¸ºOpenTelemetry 2025çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®æä¾›äº†é‡è¦çš„{value}ï¼Œé€šè¿‡ç³»ç»Ÿæ€§çš„{approach}ï¼Œç¡®ä¿äº†{quality}ã€‚

### ä¸»è¦è´¡çŒ®

1. **è´¡çŒ®1**: {contribution1}
2. **è´¡çŒ®2**: {contribution2}
3. **è´¡çŒ®3**: {contribution3}
4. **è´¡çŒ®4**: {contribution4}
5. **è´¡çŒ®5**: {contribution5}

### æŠ€æœ¯ä»·å€¼

1. **ä»·å€¼1**: {value1}
2. **ä»·å€¼2**: {value2}
3. **ä»·å€¼3**: {value3}
4. **ä»·å€¼4**: {value4}

### åº”ç”¨æŒ‡å¯¼

1. **æŒ‡å¯¼1**: {guidance1}
2. **æŒ‡å¯¼2**: {guidance2}
3. **æŒ‡å¯¼3**: {guidance3}
4. **æŒ‡å¯¼4**: {guidance4}

{title}ä¸ºOTLPæ ‡å‡†çš„{impact}æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚

---

**æ–‡æ¡£åˆ›å»ºå®Œæˆæ—¶é—´**: {created_time}  
**æ–‡æ¡£ç‰ˆæœ¬**: {version}  
**ç»´æŠ¤è€…**: {maintainer}  
**ä¸‹æ¬¡å®¡æŸ¥**: {next_review}
"""
            }
        }
        
        self.load_cache()
    
    def load_cache(self):
        """åŠ è½½ç¼“å­˜"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
            except:
                self.cache = {"files": {}, "last_scan": None, "backups": []}
        else:
            self.cache = {"files": {}, "last_scan": None, "backups": []}
    
    def save_cache(self):
        """ä¿å­˜ç¼“å­˜"""
        with open(self.cache_file, 'w', encoding='utf-8') as f:
            json.dump(self.cache, f, ensure_ascii=False, indent=2)
    
    def get_file_hash(self, file_path: Path) -> str:
        """è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return ""
    
    def backup_file(self, file_path: Path) -> Path:
        """å¤‡ä»½æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
        backup_path = self.backup_dir / backup_name
        
        shutil.copy2(file_path, backup_path)
        
        # è®°å½•å¤‡ä»½
        self.cache["backups"].append({
            "original": str(file_path),
            "backup": str(backup_path),
            "timestamp": timestamp,
            "size": file_path.stat().st_size
        })
        
        # ä¿æŒæœ€è¿‘10ä¸ªå¤‡ä»½
        if len(self.cache["backups"]) > 10:
            old_backup = self.cache["backups"].pop(0)
            old_backup_path = Path(old_backup["backup"])
            if old_backup_path.exists():
                old_backup_path.unlink()
        
        return backup_path
    
    def detect_changes(self) -> List[Tuple[Path, str, str]]:
        """æ£€æµ‹æ–‡ä»¶å˜åŒ–"""
        changes = []
        
        for md_file in self.doc_root.rglob("*.md"):
            current_hash = self.get_file_hash(md_file)
            cached_hash = self.cache.get("files", {}).get(str(md_file), "")
            
            if current_hash != cached_hash:
                changes.append((md_file, cached_hash, current_hash))
                self.cache["files"][str(md_file)] = current_hash
        
        self.cache["last_scan"] = datetime.now().isoformat()
        self.save_cache()
        
        return changes
    
    def analyze_document_structure(self, file_path: Path) -> Dict:
        """åˆ†ææ–‡æ¡£ç»“æ„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–æ ‡é¢˜
            title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
            title = title_match.group(1).strip() if title_match else file_path.stem
            
            # æå–å…ƒæ•°æ®
            metadata = {
                'title': title,
                'created_time': self._extract_metadata(content, 'åˆ›å»ºæ—¶é—´'),
                'version': self._extract_metadata(content, 'æ–‡æ¡£ç‰ˆæœ¬'),
                'maintainer': self._extract_metadata(content, 'ç»´æŠ¤è€…'),
                'status': self._extract_metadata(content, 'çŠ¶æ€'),
                'scope': self._extract_metadata(content, 'èŒƒå›´') or self._extract_metadata(content, 'åˆ†æèŒƒå›´'),
            }
            
            # åˆ†æç»“æ„å®Œæ•´æ€§
            structure_analysis = {
                'has_header': bool(re.search(r'^#\s+', content, re.MULTILINE)),
                'has_overview': bool(re.search(r'##\s+.*æ¦‚è§ˆ', content)),
                'has_goals': bool(re.search(r'##\s+.*ç›®æ ‡', content)),
                'has_summary': bool(re.search(r'##\s+.*æ€»ç»“', content)),
                'has_footer': bool(re.search(r'---\s*$', content, re.MULTILINE)),
                'section_count': len(re.findall(r'^##\s+', content, re.MULTILINE)),
                'subsection_count': len(re.findall(r'^###\s+', content, re.MULTILINE)),
            }
            
            return {
                'metadata': metadata,
                'structure': structure_analysis,
                'content_length': len(content),
                'line_count': len(content.splitlines())
            }
            
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åˆ†ææ–‡æ¡£ {file_path}: {e}")
            return {}
    
    def _extract_metadata(self, content: str, key: str) -> Optional[str]:
        """æå–å…ƒæ•°æ®"""
        pattern = rf'\*\*{re.escape(key)}\*\*:\s*(.+)'
        match = re.search(pattern, content)
        return match.group(1).strip() if match else None
    
    def fix_document_structure(self, file_path: Path, analysis: Dict) -> bool:
        """ä¿®å¤æ–‡æ¡£ç»“æ„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å¤‡ä»½åŸæ–‡ä»¶
            self.backup_file(file_path)
            
            # ä¿®å¤æ ‡é¢˜
            if not analysis['structure']['has_header']:
                title = analysis['metadata']['title']
                content = f"# {title}\n\n{content}"
            
            # ä¿®å¤æ¦‚è§ˆéƒ¨åˆ†
            if not analysis['structure']['has_overview']:
                overview = self._generate_overview_section(analysis['metadata'])
                content = self._insert_section(content, overview, after_title=True)
            
            # ä¿®å¤ç›®æ ‡éƒ¨åˆ†
            if not analysis['structure']['has_goals']:
                goals = self._generate_goals_section(analysis['metadata'])
                content = self._insert_section(content, goals, after_overview=True)
            
            # ä¿®å¤æ€»ç»“éƒ¨åˆ†
            if not analysis['structure']['has_summary']:
                summary = self._generate_summary_section(analysis['metadata'])
                content = self._insert_section(content, summary, before_footer=True)
            
            # ä¿®å¤é¡µè„š
            if not analysis['structure']['has_footer']:
                footer = self._generate_footer_section(analysis['metadata'])
                content += f"\n{footer}"
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return True
            
        except Exception as e:
            print(f"é”™è¯¯: ä¿®å¤æ–‡æ¡£ {file_path} å¤±è´¥: {e}")
            return False
    
    def _generate_overview_section(self, metadata: Dict) -> str:
        """ç”Ÿæˆæ¦‚è§ˆéƒ¨åˆ†"""
        title = metadata['title']
        created_time = metadata['created_time'] or datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        version = metadata['version'] or "2.0.0"
        maintainer = metadata['maintainer'] or "OpenTelemetry 2025 å›¢é˜Ÿ"
        status = metadata['status'] or "çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®"
        scope = metadata['scope'] or f"{title}åˆ†æ"
        
        return f"""## ğŸ“Š {title}æ¦‚è§ˆ

**åˆ›å»ºæ—¶é—´**: {created_time}  
**æ–‡æ¡£ç‰ˆæœ¬**: {version}  
**ç»´æŠ¤è€…**: {maintainer}  
**çŠ¶æ€**: {status}  
**{title}èŒƒå›´**: {scope}

"""
    
    def _generate_goals_section(self, metadata: Dict) -> str:
        """ç”Ÿæˆç›®æ ‡éƒ¨åˆ†"""
        title = metadata['title']
        
        return f"""## ğŸ¯ {title}ç›®æ ‡

### ä¸»è¦ç›®æ ‡

1. **ç›®æ ‡1**: å®ç°{title}çš„æ ¸å¿ƒåŠŸèƒ½
2. **ç›®æ ‡2**: ç¡®ä¿{title}çš„è´¨é‡å’Œå¯é æ€§
3. **ç›®æ ‡3**: æä¾›{title}çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
4. **ç›®æ ‡4**: å»ºç«‹{title}çš„æœ€ä½³å®è·µ
5. **ç›®æ ‡5**: æ¨åŠ¨{title}çš„æŒç»­æ”¹è¿›

### æˆåŠŸæ ‡å‡†

- **æ ‡å‡†1**: 100%åŠŸèƒ½å®ç°
- **æ ‡å‡†2**: é«˜è´¨é‡æ ‡å‡†è¾¾æˆ
- **æ ‡å‡†3**: å®Œæ•´è§£å†³æ–¹æ¡ˆæä¾›
- **æ ‡å‡†4**: æœ€ä½³å®è·µå»ºç«‹
- **æ ‡å‡†5**: æŒç»­æ”¹è¿›æœºåˆ¶

"""
    
    def _generate_summary_section(self, metadata: Dict) -> str:
        """ç”Ÿæˆæ€»ç»“éƒ¨åˆ†"""
        title = metadata['title']
        
        return f"""## ğŸ“š æ€»ç»“

{title}ä¸ºOpenTelemetry 2025çŸ¥è¯†ç†è®ºæ¨¡å‹åˆ†ææ¢³ç†é¡¹ç›®æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ï¼Œé€šè¿‡ç³»ç»Ÿæ€§çš„åˆ†æå’Œç ”ç©¶ï¼Œç¡®ä¿äº†é¡¹ç›®çš„è´¨é‡å’Œå¯é æ€§ã€‚

### ä¸»è¦è´¡çŒ®

1. **è´¡çŒ®1**: æä¾›äº†å®Œæ•´çš„{title}è§£å†³æ–¹æ¡ˆ
2. **è´¡çŒ®2**: å»ºç«‹äº†{title}çš„æœ€ä½³å®è·µ
3. **è´¡çŒ®3**: æ¨åŠ¨äº†{title}çš„æŠ€æœ¯åˆ›æ–°
4. **è´¡çŒ®4**: ç¡®ä¿äº†{title}çš„è´¨é‡æ ‡å‡†
5. **è´¡çŒ®5**: å»ºç«‹äº†{title}çš„æŒç»­æ”¹è¿›æœºåˆ¶

### æŠ€æœ¯ä»·å€¼

1. **ç†è®ºä»·å€¼**: ä¸º{title}æä¾›ç†è®ºåŸºç¡€
2. **å®è·µä»·å€¼**: ä¸ºå®é™…åº”ç”¨æä¾›æŒ‡å¯¼
3. **åˆ›æ–°ä»·å€¼**: æ¨åŠ¨{title}æŠ€æœ¯åˆ›æ–°
4. **è´¨é‡ä»·å€¼**: ä¸º{title}è´¨é‡æä¾›ä¿è¯

### åº”ç”¨æŒ‡å¯¼

1. **å®æ–½æŒ‡å¯¼**: ä¸º{title}å®æ–½æä¾›è¯¦ç»†æŒ‡å¯¼
2. **ä¼˜åŒ–æŒ‡å¯¼**: ä¸º{title}ä¼˜åŒ–æä¾›ç­–ç•¥æ–¹æ³•
3. **ç»´æŠ¤æŒ‡å¯¼**: ä¸º{title}ç»´æŠ¤æä¾›æœ€ä½³å®è·µ
4. **æ‰©å±•æŒ‡å¯¼**: ä¸º{title}æ‰©å±•æä¾›æ–¹å‘å»ºè®®

{title}ä¸ºOTLPæ ‡å‡†çš„æˆåŠŸåº”ç”¨æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚

"""
    
    def _generate_footer_section(self, metadata: Dict) -> str:
        """ç”Ÿæˆé¡µè„šéƒ¨åˆ†"""
        created_time = metadata['created_time'] or datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        version = metadata['version'] or "2.0.0"
        maintainer = metadata['maintainer'] or "OpenTelemetry 2025 å›¢é˜Ÿ"
        next_review = (datetime.now().replace(month=datetime.now().month+1) if datetime.now().month < 12 
                      else datetime.now().replace(year=datetime.now().year+1, month=1)).strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        return f"""---

**æ–‡æ¡£åˆ›å»ºå®Œæˆæ—¶é—´**: {created_time}  
**æ–‡æ¡£ç‰ˆæœ¬**: {version}  
**ç»´æŠ¤è€…**: {maintainer}  
**ä¸‹æ¬¡å®¡æŸ¥**: {next_review}
"""
    
    def _insert_section(self, content: str, section: str, after_title: bool = False, 
                       after_overview: bool = False, before_footer: bool = False) -> str:
        """æ’å…¥ç« èŠ‚"""
        lines = content.splitlines()
        
        if after_title:
            # åœ¨ç¬¬ä¸€ä¸ªæ ‡é¢˜åæ’å…¥
            for i, line in enumerate(lines):
                if line.startswith('# '):
                    lines.insert(i + 1, "")
                    lines.insert(i + 2, section.strip())
                    break
        elif after_overview:
            # åœ¨æ¦‚è§ˆç« èŠ‚åæ’å…¥
            for i, line in enumerate(lines):
                if 'æ¦‚è§ˆ' in line and line.startswith('##'):
                    # æ‰¾åˆ°æ¦‚è§ˆç« èŠ‚çš„ç»“æŸä½ç½®
                    j = i + 1
                    while j < len(lines) and not (lines[j].startswith('##') and not lines[j].startswith('###')):
                        j += 1
                    lines.insert(j, "")
                    lines.insert(j + 1, section.strip())
                    break
        elif before_footer:
            # åœ¨é¡µè„šå‰æ’å…¥
            for i, line in enumerate(lines):
                if line.strip() == '---':
                    lines.insert(i, "")
                    lines.insert(i + 1, section.strip())
                    break
        
        return '\n'.join(lines)
    
    def update_cross_references(self, changed_files: List[Path]):
        """æ›´æ–°äº¤å‰å¼•ç”¨"""
        print("ğŸ”— æ›´æ–°äº¤å‰å¼•ç”¨...")
        
        # æ‰«ææ‰€æœ‰æ–‡æ¡£ï¼Œå»ºç«‹å¼•ç”¨å…³ç³»
        all_documents = {}
        for md_file in self.doc_root.rglob("*.md"):
            analysis = self.analyze_document_structure(md_file)
            if analysis:
                all_documents[str(md_file)] = analysis
        
        # ä¸ºæ¯ä¸ªå˜åŒ–çš„æ–‡ä»¶æ›´æ–°å¼•ç”¨
        for changed_file in changed_files:
            self._update_file_references(changed_file, all_documents)
    
    def _update_file_references(self, file_path: Path, all_documents: Dict):
        """æ›´æ–°æ–‡ä»¶å¼•ç”¨"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾å¯èƒ½çš„å¼•ç”¨
            references = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
            
            updated = False
            for ref_text, ref_path in references:
                if ref_path.endswith('.md'):
                    # æ£€æŸ¥å¼•ç”¨è·¯å¾„æ˜¯å¦å­˜åœ¨
                    ref_file = self.doc_root / ref_path
                    if not ref_file.exists():
                        # å°è¯•æ‰¾åˆ°æ­£ç¡®çš„è·¯å¾„
                        correct_path = self._find_correct_path(ref_path, all_documents)
                        if correct_path:
                            # æ›´æ–°å¼•ç”¨
                            old_ref = f"[{ref_text}]({ref_path})"
                            new_ref = f"[{ref_text}]({correct_path})"
                            content = content.replace(old_ref, new_ref)
                            updated = True
            
            if updated:
                # å¤‡ä»½å¹¶ä¿å­˜
                self.backup_file(file_path)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… å·²æ›´æ–°å¼•ç”¨: {file_path}")
                
        except Exception as e:
            print(f"è­¦å‘Š: æ›´æ–°å¼•ç”¨å¤±è´¥ {file_path}: {e}")
    
    def _find_correct_path(self, ref_path: str, all_documents: Dict) -> Optional[str]:
        """æŸ¥æ‰¾æ­£ç¡®çš„å¼•ç”¨è·¯å¾„"""
        ref_name = Path(ref_path).name
        
        for doc_path, doc_info in all_documents.items():
            if Path(doc_path).name == ref_name:
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                return str(Path(doc_path).relative_to(self.doc_root))
        
        return None
    
    def run_auto_update(self):
        """è¿è¡Œè‡ªåŠ¨æ›´æ–°"""
        print("ğŸš€ OpenTelemetry 2025 è‡ªåŠ¨æ–‡æ¡£æ›´æ–°å™¨")
        print("=" * 60)
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ£€æµ‹å˜åŒ–
        print("\nğŸ” æ£€æµ‹æ–‡æ¡£å˜åŒ–...")
        changes = self.detect_changes()
        
        if not changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°æ–‡æ¡£å˜åŒ–")
            return
        
        print(f"ğŸ”„ å‘ç° {len(changes)} ä¸ªæ–‡ä»¶æœ‰å˜åŒ–")
        
        # å¤„ç†æ¯ä¸ªå˜åŒ–çš„æ–‡ä»¶
        fixed_count = 0
        for file_path, old_hash, new_hash in changes:
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {file_path}")
            
            # åˆ†ææ–‡æ¡£ç»“æ„
            analysis = self.analyze_document_structure(file_path)
            if not analysis:
                continue
            
            # æ£€æŸ¥ç»“æ„å®Œæ•´æ€§
            structure = analysis['structure']
            needs_fix = not all([
                structure['has_header'],
                structure['has_overview'],
                structure['has_goals'],
                structure['has_summary'],
                structure['has_footer']
            ])
            
            if needs_fix:
                print(f"ğŸ”§ ä¿®å¤æ–‡æ¡£ç»“æ„: {file_path}")
                if self.fix_document_structure(file_path, analysis):
                    fixed_count += 1
                    print(f"âœ… å·²ä¿®å¤: {file_path}")
                else:
                    print(f"âŒ ä¿®å¤å¤±è´¥: {file_path}")
            else:
                print(f"âœ… ç»“æ„å®Œæ•´: {file_path}")
        
        # æ›´æ–°äº¤å‰å¼•ç”¨
        changed_files = [file_path for file_path, _, _ in changes]
        self.update_cross_references(changed_files)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰§è¡Œç»“æœæ±‡æ€»")
        print(f"ğŸ”„ å˜åŒ–æ–‡ä»¶: {len(changes)}")
        print(f"ğŸ”§ ä¿®å¤æ–‡ä»¶: {fixed_count}")
        print(f"ğŸ“¦ å¤‡ä»½æ–‡ä»¶: {len(self.cache['backups'])}")
        
        print("\nğŸ‰ è‡ªåŠ¨æ–‡æ¡£æ›´æ–°å®Œæˆ!")
        print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

def main():
    """ä¸»å‡½æ•°"""
    updater = AutoDocumentUpdater()
    updater.run_auto_update()

if __name__ == "__main__":
    main()
