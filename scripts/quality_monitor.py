#!/usr/bin/env python3
"""
OpenTelemetry 2025å¹´é¡¹ç›®è´¨é‡ç›‘æ§ç³»ç»Ÿ
åŸºäºå›½é™…æ ‡å‡†å¯¹é½å’ŒçŸ¥è¯†ä½“ç³»çš„è´¨é‡ä¿è¯ç³»ç»Ÿ
"""

import os
import yaml
import json
import time
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional

class QualityMonitor:
    def __init__(self, config_path: str = "config/quality_monitor.yaml"):
        self.config = self.load_config(config_path)
        self.base_path = Path("doc")
        self.metrics = {}
        self.report_history = []
    
    def load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½è´¨é‡ç›‘æ§é…ç½®"""
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return self.get_default_config()
    
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "quality_standards": {
                "documentation": {
                    "min_length": 100,
                    "max_age_days": 30,
                    "required_sections": ["æ¦‚è¿°", "æ ¸å¿ƒå†…å®¹", "å‚è€ƒæ–‡çŒ®"]
                },
                "standards_alignment": {
                    "coverage_threshold": 100,
                    "update_frequency_days": 30
                },
                "knowledge_completeness": {
                    "layers_required": 6,
                    "categories_per_layer": 3
                }
            },
            "monitoring": {
                "check_interval_hours": 24,
                "report_frequency": "daily",
                "alert_thresholds": {
                    "quality_score": 80,
                    "completion_rate": 90
                }
            }
        }
    
    def check_documentation_quality(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡æ¡£è´¨é‡"""
        doc_path = Path("doc")
        quality_metrics = {
            "total_documents": 0,
            "valid_documents": 0,
            "outdated_documents": 0,
            "missing_documents": 0,
            "quality_score": 0,
            "details": []
        }
        
        for doc_file in doc_path.rglob("*.md"):
            quality_metrics["total_documents"] += 1
            
            doc_quality = self.analyze_document_quality(doc_file)
            quality_metrics["details"].append(doc_quality)
            
            if doc_quality["is_valid"]:
                quality_metrics["valid_documents"] += 1
            else:
                quality_metrics["missing_documents"] += 1
            
            if doc_quality["is_outdated"]:
                quality_metrics["outdated_documents"] += 1
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        if quality_metrics["total_documents"] > 0:
            quality_metrics["quality_score"] = (
                quality_metrics["valid_documents"] / quality_metrics["total_documents"]
            ) * 100
        
        return quality_metrics
    
    def analyze_document_quality(self, doc_file: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡æ¡£è´¨é‡"""
        try:
            with open(doc_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŸºæœ¬æ£€æŸ¥
            is_valid = len(content.strip()) > 0
            is_outdated = self.is_document_outdated(doc_file)
            
            # å†…å®¹åˆ†æ
            word_count = len(content.split())
            has_required_sections = self.check_required_sections(content)
            has_references = "å‚è€ƒæ–‡çŒ®" in content or "References" in content
            
            # è®¡ç®—æ–‡æ¡£è´¨é‡åˆ†æ•°
            quality_score = 0
            if is_valid:
                quality_score += 40
            if word_count >= 100:
                quality_score += 20
            if has_required_sections:
                quality_score += 20
            if has_references:
                quality_score += 20
            
            return {
                "file_path": str(doc_file),
                "is_valid": is_valid,
                "is_outdated": is_outdated,
                "word_count": word_count,
                "has_required_sections": has_required_sections,
                "has_references": has_references,
                "quality_score": quality_score,
                "last_modified": datetime.fromtimestamp(doc_file.stat().st_mtime).isoformat()
            }
        except Exception as e:
            return {
                "file_path": str(doc_file),
                "is_valid": False,
                "is_outdated": True,
                "error": str(e),
                "quality_score": 0
            }
    
    def is_document_outdated(self, doc_file: Path) -> bool:
        """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦è¿‡æœŸ"""
        try:
            stat = doc_file.stat()
            modified_time = datetime.fromtimestamp(stat.st_mtime)
            max_age = timedelta(days=self.config["quality_standards"]["documentation"]["max_age_days"])
            return datetime.now() - modified_time > max_age
        except:
            return True
    
    def check_required_sections(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…éœ€ç« èŠ‚"""
        required_sections = self.config["quality_standards"]["documentation"]["required_sections"]
        return all(section in content for section in required_sections)
    
    def check_standards_alignment(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ ‡å‡†å¯¹é½æƒ…å†µ"""
        alignment_metrics = {
            "total_standards": 0,
            "aligned_standards": 0,
            "partially_aligned": 0,
            "not_aligned": 0,
            "alignment_rate": 0,
            "details": []
        }
        
        # åŠ è½½æ ‡å‡†å¯¹é½é…ç½®
        standards_config_path = "config/international_standards_alignment.yaml"
        if os.path.exists(standards_config_path):
            with open(standards_config_path, 'r', encoding='utf-8') as f:
                standards_config = yaml.safe_load(f)
            
            # æ£€æŸ¥å„ç±»æ ‡å‡†
            for category, standards in standards_config.items():
                if isinstance(standards, dict):
                    for standard_name, standard_info in standards.items():
                        if isinstance(standard_info, dict) and "alignment_status" in standard_info:
                            alignment_metrics["total_standards"] += 1
                            
                            alignment_status = standard_info.get("alignment_status", "not_aligned")
                            alignment_metrics["details"].append({
                                "category": category,
                                "standard": standard_name,
                                "status": alignment_status,
                                "name": standard_info.get("name", standard_name)
                            })
                            
                            if alignment_status == "100%":
                                alignment_metrics["aligned_standards"] += 1
                            elif "éƒ¨åˆ†" in alignment_status or "partial" in alignment_status.lower():
                                alignment_metrics["partially_aligned"] += 1
                            else:
                                alignment_metrics["not_aligned"] += 1
        
        # è®¡ç®—å¯¹é½ç‡
        if alignment_metrics["total_standards"] > 0:
            alignment_metrics["alignment_rate"] = (
                alignment_metrics["aligned_standards"] / alignment_metrics["total_standards"]
            ) * 100
        
        return alignment_metrics
    
    def check_knowledge_completeness(self) -> Dict[str, Any]:
        """æ£€æŸ¥çŸ¥è¯†å®Œæ•´æ€§"""
        knowledge_metrics = {
            "total_layers": 6,
            "completed_layers": 0,
            "total_categories": 0,
            "completed_categories": 0,
            "completion_rate": 0,
            "details": []
        }
        
        knowledge_path = Path("doc/02_çŸ¥è¯†ä½“ç³»")
        if knowledge_path.exists():
            for layer_path in knowledge_path.iterdir():
                if layer_path.is_dir() and layer_path.name.startswith(("01_", "02_", "03_", "04_", "05_", "06_")):
                    layer_complete = self.is_layer_complete(layer_path)
                    layer_info = {
                        "layer_name": layer_path.name,
                        "is_complete": layer_complete,
                        "categories": []
                    }
                    
                    if layer_complete:
                        knowledge_metrics["completed_layers"] += 1
                    
                    # æ£€æŸ¥åˆ†ç±»å®Œæ•´æ€§
                    categories = [d for d in layer_path.iterdir() if d.is_dir()]
                    knowledge_metrics["total_categories"] += len(categories)
                    
                    for category in categories:
                        category_complete = self.is_category_complete(category)
                        layer_info["categories"].append({
                            "name": category.name,
                            "is_complete": category_complete
                        })
                        
                        if category_complete:
                            knowledge_metrics["completed_categories"] += 1
                    
                    knowledge_metrics["details"].append(layer_info)
        
        # è®¡ç®—å®Œæˆç‡
        if knowledge_metrics["total_layers"] > 0:
            knowledge_metrics["completion_rate"] = (
                knowledge_metrics["completed_layers"] / knowledge_metrics["total_layers"]
            ) * 100
        
        return knowledge_metrics
    
    def is_layer_complete(self, layer_path: Path) -> bool:
        """æ£€æŸ¥å±‚çº§æ˜¯å¦å®Œæ•´"""
        required_files = ["README.md"]
        for file_name in required_files:
            if not (layer_path / file_name).exists():
                return False
        return True
    
    def is_category_complete(self, category_path: Path) -> bool:
        """æ£€æŸ¥åˆ†ç±»æ˜¯å¦å®Œæ•´"""
        required_files = ["README.md"]
        for file_name in required_files:
            if not (category_path / file_name).exists():
                return False
        return True
    
    def check_academic_collaboration(self) -> Dict[str, Any]:
        """æ£€æŸ¥å­¦æœ¯åˆä½œæƒ…å†µ"""
        collaboration_metrics = {
            "total_universities": 0,
            "active_collaborations": 0,
            "total_projects": 0,
            "active_projects": 0,
            "collaboration_rate": 0,
            "details": []
        }
        
        # åŠ è½½å­¦æœ¯åˆä½œé…ç½®
        collaboration_config_path = "config/academic_collaboration.yaml"
        if os.path.exists(collaboration_config_path):
            with open(collaboration_config_path, 'r', encoding='utf-8') as f:
                collaboration_config = yaml.safe_load(f)
            
            universities = collaboration_config.get("universities", {})
            collaboration_metrics["total_universities"] = len(universities)
            
            for uni_name, uni_info in universities.items():
                if isinstance(uni_info, dict):
                    projects = uni_info.get("projects", [])
                    collaboration_metrics["total_projects"] += len(projects)
                    
                    active_projects = [p for p in projects if p.get("status") in ["active", "planning"]]
                    collaboration_metrics["active_projects"] += len(active_projects)
                    
                    if len(active_projects) > 0:
                        collaboration_metrics["active_collaborations"] += 1
                    
                    collaboration_metrics["details"].append({
                        "university": uni_name,
                        "name": uni_info.get("name", uni_name),
                        "total_projects": len(projects),
                        "active_projects": len(active_projects),
                        "status": "active" if len(active_projects) > 0 else "inactive"
                    })
        
        # è®¡ç®—åˆä½œç‡
        if collaboration_metrics["total_universities"] > 0:
            collaboration_metrics["collaboration_rate"] = (
                collaboration_metrics["active_collaborations"] / collaboration_metrics["total_universities"]
            ) * 100
        
        return collaboration_metrics
    
    def generate_quality_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "report_id": self.generate_report_id(),
            "documentation_quality": self.check_documentation_quality(),
            "standards_alignment": self.check_standards_alignment(),
            "knowledge_completeness": self.check_knowledge_completeness(),
            "academic_collaboration": self.check_academic_collaboration()
        }
        
        # è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
        doc_quality = report["documentation_quality"]["quality_score"]
        std_quality = report["standards_alignment"]["alignment_rate"]
        know_quality = report["knowledge_completeness"]["completion_rate"]
        collab_quality = report["academic_collaboration"]["collaboration_rate"]
        
        overall_score = (doc_quality + std_quality + know_quality + collab_quality) / 4
        report["overall_quality_score"] = overall_score
        
        # è´¨é‡ç­‰çº§è¯„ä¼°
        if overall_score >= 90:
            report["quality_grade"] = "A+"
        elif overall_score >= 80:
            report["quality_grade"] = "A"
        elif overall_score >= 70:
            report["quality_grade"] = "B"
        elif overall_score >= 60:
            report["quality_grade"] = "C"
        else:
            report["quality_grade"] = "D"
        
        # æ”¹è¿›å»ºè®®
        report["improvement_recommendations"] = self.generate_improvement_recommendations(report)
        
        return report
    
    def generate_report_id(self) -> str:
        """ç”ŸæˆæŠ¥å‘ŠID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"QR_{timestamp}"
    
    def generate_improvement_recommendations(self, report: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # æ–‡æ¡£è´¨é‡æ”¹è¿›å»ºè®®
        doc_quality = report["documentation_quality"]["quality_score"]
        if doc_quality < 80:
            recommendations.append("æé«˜æ–‡æ¡£è´¨é‡ï¼šå¢åŠ æ–‡æ¡£å†…å®¹ï¼Œç¡®ä¿åŒ…å«å¿…éœ€ç« èŠ‚å’Œå‚è€ƒæ–‡çŒ®")
        
        if report["documentation_quality"]["outdated_documents"] > 0:
            recommendations.append(f"æ›´æ–°è¿‡æœŸæ–‡æ¡£ï¼š{report['documentation_quality']['outdated_documents']}ä¸ªæ–‡æ¡£éœ€è¦æ›´æ–°")
        
        # æ ‡å‡†å¯¹é½æ”¹è¿›å»ºè®®
        std_quality = report["standards_alignment"]["alignment_rate"]
        if std_quality < 100:
            recommendations.append("å®Œå–„æ ‡å‡†å¯¹é½ï¼šç¡®ä¿æ‰€æœ‰æ ‡å‡†100%å¯¹é½")
        
        # çŸ¥è¯†å®Œæ•´æ€§æ”¹è¿›å»ºè®®
        know_quality = report["knowledge_completeness"]["completion_rate"]
        if know_quality < 100:
            recommendations.append("å®Œå–„çŸ¥è¯†ä½“ç³»ï¼šå®Œæˆæ‰€æœ‰å±‚çº§å’Œåˆ†ç±»çš„å†…å®¹")
        
        # å­¦æœ¯åˆä½œæ”¹è¿›å»ºè®®
        collab_quality = report["academic_collaboration"]["collaboration_rate"]
        if collab_quality < 50:
            recommendations.append("åŠ å¼ºå­¦æœ¯åˆä½œï¼šå¢åŠ ä¸å¤§å­¦çš„åˆä½œé¡¹ç›®")
        
        return recommendations
    
    def save_quality_report(self, report: Dict[str, Any]) -> str:
        """ä¿å­˜è´¨é‡æŠ¥å‘Š"""
        report_path = Path("reports/quality_reports")
        report_path.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = report_path / f"quality_report_{report['report_id']}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # æ›´æ–°æœ€æ–°æŠ¥å‘Š
        latest_report = report_path / "latest_quality_report.json"
        with open(latest_report, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æŠ¥å‘Šå†å²
        self.report_history.append(report)
        history_file = report_path / "quality_report_history.json"
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.report_history, f, indent=2, ensure_ascii=False)
        
        return str(report_file)
    
    def print_quality_summary(self, report: Dict[str, Any]):
        """æ‰“å°è´¨é‡æ‘˜è¦"""
        print("=" * 60)
        print("OpenTelemetry 2025å¹´é¡¹ç›®è´¨é‡ç›‘æ§æŠ¥å‘Š")
        print("=" * 60)
        print(f"æŠ¥å‘Šæ—¶é—´: {report['timestamp']}")
        print(f"æŠ¥å‘ŠID: {report['report_id']}")
        print(f"æ€»ä½“è´¨é‡åˆ†æ•°: {report['overall_quality_score']:.2f}")
        print(f"è´¨é‡ç­‰çº§: {report['quality_grade']}")
        print()
        
        print("ğŸ“Š è¯¦ç»†æŒ‡æ ‡:")
        print(f"  æ–‡æ¡£è´¨é‡: {report['documentation_quality']['quality_score']:.2f}")
        print(f"  æ ‡å‡†å¯¹é½: {report['standards_alignment']['alignment_rate']:.2f}")
        print(f"  çŸ¥è¯†å®Œæ•´æ€§: {report['knowledge_completeness']['completion_rate']:.2f}")
        print(f"  å­¦æœ¯åˆä½œ: {report['academic_collaboration']['collaboration_rate']:.2f}")
        print()
        
        print("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»æ–‡æ¡£æ•°: {report['documentation_quality']['total_documents']}")
        print(f"  æœ‰æ•ˆæ–‡æ¡£: {report['documentation_quality']['valid_documents']}")
        print(f"  è¿‡æœŸæ–‡æ¡£: {report['documentation_quality']['outdated_documents']}")
        print(f"  æ€»æ ‡å‡†æ•°: {report['standards_alignment']['total_standards']}")
        print(f"  å·²å¯¹é½æ ‡å‡†: {report['standards_alignment']['aligned_standards']}")
        print(f"  å®Œæˆå±‚çº§: {report['knowledge_completeness']['completed_layers']}/{report['knowledge_completeness']['total_layers']}")
        print(f"  åˆä½œå¤§å­¦: {report['academic_collaboration']['active_collaborations']}/{report['academic_collaboration']['total_universities']}")
        print()
        
        if report["improvement_recommendations"]:
            print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            for i, recommendation in enumerate(report["improvement_recommendations"], 1):
                print(f"  {i}. {recommendation}")
        print()
        print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    monitor = QualityMonitor()
    
    print("å¼€å§‹è´¨é‡ç›‘æ§æ£€æŸ¥...")
    report = monitor.generate_quality_report()
    
    print("ä¿å­˜è´¨é‡æŠ¥å‘Š...")
    report_file = monitor.save_quality_report(report)
    
    print("ç”Ÿæˆè´¨é‡æ‘˜è¦...")
    monitor.print_quality_summary(report)
    
    print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
    if report["overall_quality_score"] < monitor.config["monitoring"]["alert_thresholds"]["quality_score"]:
        print("âš ï¸  è­¦å‘Š: è´¨é‡åˆ†æ•°ä½äºé˜ˆå€¼ï¼Œéœ€è¦å…³æ³¨!")
    
    if report["knowledge_completeness"]["completion_rate"] < monitor.config["monitoring"]["alert_thresholds"]["completion_rate"]:
        print("âš ï¸  è­¦å‘Š: å®Œæˆç‡ä½äºé˜ˆå€¼ï¼Œéœ€è¦å…³æ³¨!")

if __name__ == "__main__":
    main()
