#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenTelemetry 2025 è‡ªåŠ¨åŒ–è´¨é‡ä¿è¯ç³»ç»Ÿ
Automated Quality Assurance System for OpenTelemetry 2025

åŠŸèƒ½ç‰¹æ€§:
- æ–‡æ¡£è´¨é‡æ£€æŸ¥
- æ ‡å‡†å¯¹é½éªŒè¯
- çŸ¥è¯†å®Œæ•´æ€§è¯„ä¼°
- å­¦æœ¯åˆä½œç›‘æ§
- è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ
- æ”¹è¿›å»ºè®®æä¾›
"""

import os
import sys
import json
import yaml
import time
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('quality_assurance.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class QualityLevel(Enum):
    """è´¨é‡çº§åˆ«æšä¸¾"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    CRITICAL = "critical"

@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡æ•°æ®ç±»"""
    completeness: float
    accuracy: float
    consistency: float
    timeliness: float
    overall_score: float
    level: QualityLevel

class DocumentQualityChecker:
    """æ–‡æ¡£è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, base_path: str = "doc"):
        self.base_path = Path(base_path)
        self.quality_thresholds = {
            'completeness': 0.8,
            'accuracy': 0.9,
            'consistency': 0.85,
            'timeliness': 0.7
        }
    
    def check_document_quality(self, doc_path: str) -> QualityMetrics:
        """æ£€æŸ¥æ–‡æ¡£è´¨é‡"""
        try:
            doc_file = self.base_path / doc_path
            
            if not doc_file.exists():
                return QualityMetrics(0, 0, 0, 0, 0, QualityLevel.CRITICAL)
            
            # è¯»å–æ–‡æ¡£å†…å®¹
            content = doc_file.read_text(encoding='utf-8')
            
            # è®¡ç®—å„é¡¹è´¨é‡æŒ‡æ ‡
            completeness = self._calculate_completeness(content)
            accuracy = self._calculate_accuracy(content)
            consistency = self._calculate_consistency(content)
            timeliness = self._calculate_timeliness(doc_file)
            
            # è®¡ç®—æ€»ä½“åˆ†æ•°
            overall_score = (completeness + accuracy + consistency + timeliness) / 4
            
            # ç¡®å®šè´¨é‡çº§åˆ«
            level = self._determine_quality_level(overall_score)
            
            return QualityMetrics(
                completeness=completeness,
                accuracy=accuracy,
                consistency=consistency,
                timeliness=timeliness,
                overall_score=overall_score,
                level=level
            )
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–‡æ¡£è´¨é‡æ—¶å‡ºé”™: {e}")
            return QualityMetrics(0, 0, 0, 0, 0, QualityLevel.CRITICAL)
    
    def _calculate_completeness(self, content: str) -> float:
        """è®¡ç®—å®Œæ•´æ€§åˆ†æ•°"""
        required_sections = [
            '# æ¦‚è¿°', '## æ ¸å¿ƒå†…å®¹', '## åº”ç”¨åœºæ™¯', 
            '## æ€§èƒ½ä¼˜åŒ–', '## æµ‹è¯•ä¸éªŒè¯', '## å‚è€ƒæ–‡çŒ®'
        ]
        
        found_sections = sum(1 for section in required_sections if section in content)
        return found_sections / len(required_sections)
    
    def _calculate_accuracy(self, content: str) -> float:
        """è®¡ç®—å‡†ç¡®æ€§åˆ†æ•°"""
        # æ£€æŸ¥å¸¸è§é”™è¯¯
        errors = 0
        total_checks = 0
        
        # æ£€æŸ¥é“¾æ¥æ ¼å¼
        import re
        links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
        total_checks += len(links)
        
        for link_text, link_url in links:
            if not link_url.startswith(('http', '/', '#')):
                errors += 1
        
        # æ£€æŸ¥ä»£ç å—æ ¼å¼
        code_blocks = content.count('```')
        if code_blocks % 2 != 0:
            errors += 1
            total_checks += 1
        
        return 1.0 - (errors / max(total_checks, 1))
    
    def _calculate_consistency(self, content: str) -> float:
        """è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°"""
        # æ£€æŸ¥æ ‡é¢˜å±‚çº§ä¸€è‡´æ€§
        import re
        headers = re.findall(r'^(#{1,6})\s+(.+)$', content, re.MULTILINE)
        
        if not headers:
            return 1.0
        
        # æ£€æŸ¥æ ‡é¢˜å±‚çº§æ˜¯å¦åˆç†
        levels = [len(header[0]) for header in headers]
        max_level = max(levels)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è·³çº§
        consistency_score = 1.0
        for i in range(1, len(levels)):
            if levels[i] > levels[i-1] + 1:
                consistency_score -= 0.1
        
        return max(0, consistency_score)
    
    def _calculate_timeliness(self, doc_file: Path) -> float:
        """è®¡ç®—æ—¶æ•ˆæ€§åˆ†æ•°"""
        try:
            # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            mtime = doc_file.stat().st_mtime
            current_time = time.time()
            
            # è®¡ç®—æ–‡ä»¶å¹´é¾„ï¼ˆå¤©ï¼‰
            age_days = (current_time - mtime) / (24 * 3600)
            
            # æ ¹æ®æ–‡ä»¶å¹´é¾„è®¡ç®—åˆ†æ•°
            if age_days < 30:
                return 1.0
            elif age_days < 90:
                return 0.8
            elif age_days < 180:
                return 0.6
            elif age_days < 365:
                return 0.4
            else:
                return 0.2
                
        except Exception:
            return 0.0
    
    def _determine_quality_level(self, score: float) -> QualityLevel:
        """ç¡®å®šè´¨é‡çº§åˆ«"""
        if score >= 0.9:
            return QualityLevel.EXCELLENT
        elif score >= 0.8:
            return QualityLevel.GOOD
        elif score >= 0.7:
            return QualityLevel.FAIR
        elif score >= 0.6:
            return QualityLevel.POOR
        else:
            return QualityLevel.CRITICAL

class StandardsAlignmentChecker:
    """æ ‡å‡†å¯¹é½æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.standards_config = self._load_standards_config()
    
    def _load_standards_config(self) -> Dict[str, Any]:
        """åŠ è½½æ ‡å‡†é…ç½®"""
        try:
            config_path = Path("config/international_standards_alignment.yaml")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            return {}
        except Exception as e:
            logger.error(f"åŠ è½½æ ‡å‡†é…ç½®å¤±è´¥: {e}")
            return {}
    
    def check_standards_alignment(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ ‡å‡†å¯¹é½æƒ…å†µ"""
        alignment_results = {}
        
        for standard_name, config in self.standards_config.items():
            alignment_results[standard_name] = {
                'alignment_status': config.get('alignment_status', 'unknown'),
                'implementation_status': config.get('implementation_status', 'unknown'),
                'compliance_score': self._calculate_compliance_score(config),
                'last_updated': config.get('last_updated', 'unknown')
            }
        
        return alignment_results
    
    def _calculate_compliance_score(self, config: Dict[str, Any]) -> float:
        """è®¡ç®—åˆè§„åˆ†æ•°"""
        # åŸºäºé…ç½®è®¡ç®—åˆè§„åˆ†æ•°
        score = 0.0
        
        if config.get('alignment_status') == '100%':
            score += 0.4
        elif config.get('alignment_status') == '80%':
            score += 0.3
        elif config.get('alignment_status') == '60%':
            score += 0.2
        
        if config.get('implementation_status') == 'å·²å®Œæˆ':
            score += 0.3
        elif config.get('implementation_status') == 'è¿›è¡Œä¸­':
            score += 0.2
        elif config.get('implementation_status') == 'è®¡åˆ’ä¸­':
            score += 0.1
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…·ä½“è¦æ±‚
        if config.get('requirements'):
            score += 0.3
        
        return min(1.0, score)

class KnowledgeCompletenessChecker:
    """çŸ¥è¯†å®Œæ•´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self, base_path: str = "doc/02_çŸ¥è¯†ä½“ç³»"):
        self.base_path = Path(base_path)
        self.required_layers = [
            "01_ç†è®ºåŸºç¡€å±‚",
            "02_æ ‡å‡†è§„èŒƒå±‚", 
            "03_æŠ€æœ¯å®ç°å±‚",
            "04_åº”ç”¨å®è·µå±‚",
            "05_è´¨é‡ä¿è¯å±‚",
            "06_ç¤¾åŒºç”Ÿæ€å±‚",
            "07_å­¦æœ¯ç ”ç©¶å±‚"
        ]
    
    def check_knowledge_completeness(self) -> Dict[str, Any]:
        """æ£€æŸ¥çŸ¥è¯†å®Œæ•´æ€§"""
        completeness_results = {}
        
        for layer in self.required_layers:
            layer_path = self.base_path / layer
            completeness_results[layer] = self._check_layer_completeness(layer_path)
        
        # è®¡ç®—æ€»ä½“å®Œæ•´æ€§
        total_completeness = sum(
            result['completeness_score'] for result in completeness_results.values()
        ) / len(completeness_results)
        
        return {
            'layers': completeness_results,
            'total_completeness': total_completeness,
            'missing_components': self._identify_missing_components(completeness_results)
        }
    
    def _check_layer_completeness(self, layer_path: Path) -> Dict[str, Any]:
        """æ£€æŸ¥å±‚çº§å®Œæ•´æ€§"""
        if not layer_path.exists():
            return {
                'exists': False,
                'completeness_score': 0.0,
                'missing_files': ['README.md']
            }
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        required_files = ['README.md']
        existing_files = list(layer_path.glob('**/*.md'))
        
        missing_files = []
        for required_file in required_files:
            if not (layer_path / required_file).exists():
                missing_files.append(required_file)
        
        # è®¡ç®—å®Œæ•´æ€§åˆ†æ•°
        completeness_score = 1.0 - (len(missing_files) / len(required_files))
        
        return {
            'exists': True,
            'completeness_score': completeness_score,
            'missing_files': missing_files,
            'total_files': len(existing_files)
        }
    
    def _identify_missing_components(self, completeness_results: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«ç¼ºå¤±ç»„ä»¶"""
        missing_components = []
        
        for layer_name, result in completeness_results.items():
            if not result['exists']:
                missing_components.append(f"{layer_name} - æ•´ä¸ªå±‚çº§ç¼ºå¤±")
            elif result['missing_files']:
                missing_components.append(f"{layer_name} - ç¼ºå¤±æ–‡ä»¶: {', '.join(result['missing_files'])}")
        
        return missing_components

class QualityReportGenerator:
    """è´¨é‡æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.template_path = Path("templates/quality_report_template.md")
    
    def generate_quality_report(self, quality_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        report_content = f"""# OpenTelemetry 2025 è´¨é‡ä¿è¯æŠ¥å‘Š

## ğŸ“Š æŠ¥å‘Šæ¦‚è¿°

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æŠ¥å‘Šç‰ˆæœ¬**: 1.0.0
**æ£€æŸ¥èŒƒå›´**: æ•´ä¸ªçŸ¥è¯†ä½“ç³»

## ğŸ“ˆ è´¨é‡æŒ‡æ ‡æ€»è§ˆ

### æ–‡æ¡£è´¨é‡
- **å¹³å‡å®Œæ•´æ€§**: {quality_data.get('document_quality', {}).get('average_completeness', 0):.2%}
- **å¹³å‡å‡†ç¡®æ€§**: {quality_data.get('document_quality', {}).get('average_accuracy', 0):.2%}
- **å¹³å‡ä¸€è‡´æ€§**: {quality_data.get('document_quality', {}).get('average_consistency', 0):.2%}
- **å¹³å‡æ—¶æ•ˆæ€§**: {quality_data.get('document_quality', {}).get('average_timeliness', 0):.2%}
- **æ€»ä½“è´¨é‡åˆ†æ•°**: {quality_data.get('document_quality', {}).get('overall_score', 0):.2%}

### æ ‡å‡†å¯¹é½
- **å¯¹é½æ ‡å‡†æ•°é‡**: {len(quality_data.get('standards_alignment', {}))}
- **å®Œå…¨å¯¹é½æ ‡å‡†**: {sum(1 for std in quality_data.get('standards_alignment', {}).values() if std.get('alignment_status') == '100%')}
- **å¹³å‡åˆè§„åˆ†æ•°**: {sum(std.get('compliance_score', 0) for std in quality_data.get('standards_alignment', {}).values()) / max(len(quality_data.get('standards_alignment', {})), 1):.2%}

### çŸ¥è¯†å®Œæ•´æ€§
- **çŸ¥è¯†å±‚çº§æ•°é‡**: {len(quality_data.get('knowledge_completeness', {}).get('layers', {}))}
- **æ€»ä½“å®Œæ•´æ€§**: {quality_data.get('knowledge_completeness', {}).get('total_completeness', 0):.2%}
- **ç¼ºå¤±ç»„ä»¶æ•°é‡**: {len(quality_data.get('knowledge_completeness', {}).get('missing_components', []))}

## ğŸ” è¯¦ç»†åˆ†æ

### æ–‡æ¡£è´¨é‡åˆ†æ
"""
        
        # æ·»åŠ æ–‡æ¡£è´¨é‡è¯¦ç»†åˆ†æ
        doc_quality = quality_data.get('document_quality', {})
        if 'detailed_results' in doc_quality:
            report_content += "\n#### å„æ–‡æ¡£è´¨é‡è¯¦æƒ…\n\n"
            report_content += "| æ–‡æ¡£è·¯å¾„ | å®Œæ•´æ€§ | å‡†ç¡®æ€§ | ä¸€è‡´æ€§ | æ—¶æ•ˆæ€§ | æ€»ä½“åˆ†æ•° | è´¨é‡çº§åˆ« |\n"
            report_content += "|---------|--------|--------|--------|--------|----------|----------|\n"
            
            for doc_path, metrics in doc_quality['detailed_results'].items():
                report_content += f"| {doc_path} | {metrics.completeness:.2%} | {metrics.accuracy:.2%} | {metrics.consistency:.2%} | {metrics.timeliness:.2%} | {metrics.overall_score:.2%} | {metrics.level.value} |\n"
        
        # æ·»åŠ æ ‡å‡†å¯¹é½åˆ†æ
        report_content += "\n### æ ‡å‡†å¯¹é½åˆ†æ\n\n"
        standards = quality_data.get('standards_alignment', {})
        for std_name, std_data in standards.items():
            report_content += f"#### {std_name}\n"
            report_content += f"- **å¯¹é½çŠ¶æ€**: {std_data.get('alignment_status', 'unknown')}\n"
            report_content += f"- **å®æ–½çŠ¶æ€**: {std_data.get('implementation_status', 'unknown')}\n"
            report_content += f"- **åˆè§„åˆ†æ•°**: {std_data.get('compliance_score', 0):.2%}\n"
            report_content += f"- **æœ€åæ›´æ–°**: {std_data.get('last_updated', 'unknown')}\n\n"
        
        # æ·»åŠ çŸ¥è¯†å®Œæ•´æ€§åˆ†æ
        report_content += "\n### çŸ¥è¯†å®Œæ•´æ€§åˆ†æ\n\n"
        knowledge = quality_data.get('knowledge_completeness', {})
        layers = knowledge.get('layers', {})
        
        for layer_name, layer_data in layers.items():
            report_content += f"#### {layer_name}\n"
            report_content += f"- **å­˜åœ¨æ€§**: {'æ˜¯' if layer_data.get('exists') else 'å¦'}\n"
            report_content += f"- **å®Œæ•´æ€§åˆ†æ•°**: {layer_data.get('completeness_score', 0):.2%}\n"
            report_content += f"- **æ–‡ä»¶æ€»æ•°**: {layer_data.get('total_files', 0)}\n"
            if layer_data.get('missing_files'):
                report_content += f"- **ç¼ºå¤±æ–‡ä»¶**: {', '.join(layer_data['missing_files'])}\n"
            report_content += "\n"
        
        # æ·»åŠ æ”¹è¿›å»ºè®®
        report_content += "\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        improvements = self._generate_improvement_suggestions(quality_data)
        for i, improvement in enumerate(improvements, 1):
            report_content += f"{i}. {improvement}\n"
        
        # æ·»åŠ ç»“è®º
        report_content += f"""

## ğŸ“‹ ç»“è®º

åŸºäºæœ¬æ¬¡è´¨é‡æ£€æŸ¥ï¼ŒOpenTelemetry 2025çŸ¥è¯†ä½“ç³»æ•´ä½“è´¨é‡{'ä¼˜ç§€' if quality_data.get('document_quality', {}).get('overall_score', 0) > 0.8 else 'è‰¯å¥½' if quality_data.get('document_quality', {}).get('overall_score', 0) > 0.6 else 'éœ€è¦æ”¹è¿›'}ã€‚

### ä¸»è¦æˆå°±
- çŸ¥è¯†ä½“ç³»ç»“æ„å®Œæ•´ï¼Œè¦†ç›–äº†ä»ç†è®ºåŸºç¡€åˆ°å®é™…åº”ç”¨çš„å„ä¸ªå±‚é¢
- æ ‡å‡†å¯¹é½å·¥ä½œè¿›å±•è‰¯å¥½ï¼Œä¸å›½é™…æ ‡å‡†ä¿æŒé«˜åº¦ä¸€è‡´
- æ–‡æ¡£è´¨é‡æ•´ä½“è¾ƒé«˜ï¼Œå†…å®¹è¯¦å®ï¼Œç»“æ„æ¸…æ™°

### éœ€è¦å…³æ³¨çš„é—®é¢˜
- éƒ¨åˆ†æ–‡æ¡£éœ€è¦æ›´æ–°ä»¥ä¿æŒæ—¶æ•ˆæ€§
- æŸäº›æ ‡å‡†çš„å…·ä½“å®æ–½ç»†èŠ‚éœ€è¦è¿›ä¸€æ­¥å®Œå–„
- çŸ¥è¯†ä½“ç³»çš„æŸäº›ç»„ä»¶éœ€è¦è¡¥å……

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. ä¼˜å…ˆå¤„ç†è´¨é‡çº§åˆ«ä¸º"critical"å’Œ"poor"çš„æ–‡æ¡£
2. å®Œå–„ç¼ºå¤±çš„çŸ¥è¯†ç»„ä»¶
3. åŠ å¼ºæ ‡å‡†å¯¹é½çš„å…·ä½“å®æ–½
4. å»ºç«‹å®šæœŸçš„è´¨é‡æ£€æŸ¥æœºåˆ¶

---
*æœ¬æŠ¥å‘Šç”±OpenTelemetry 2025è‡ªåŠ¨åŒ–è´¨é‡ä¿è¯ç³»ç»Ÿç”Ÿæˆ*
"""
        
        return report_content
    
    def _generate_improvement_suggestions(self, quality_data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        # åŸºäºæ–‡æ¡£è´¨é‡çš„å»ºè®®
        doc_quality = quality_data.get('document_quality', {})
        if doc_quality.get('average_completeness', 0) < 0.8:
            suggestions.append("æé«˜æ–‡æ¡£å®Œæ•´æ€§ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€ç« èŠ‚éƒ½å­˜åœ¨")
        
        if doc_quality.get('average_accuracy', 0) < 0.9:
            suggestions.append("æé«˜æ–‡æ¡£å‡†ç¡®æ€§ï¼Œæ£€æŸ¥é“¾æ¥æ ¼å¼å’Œä»£ç å—è¯­æ³•")
        
        if doc_quality.get('average_timeliness', 0) < 0.7:
            suggestions.append("æ›´æ–°è¿‡æ—¶çš„æ–‡æ¡£ï¼Œä¿æŒå†…å®¹çš„æ—¶æ•ˆæ€§")
        
        # åŸºäºæ ‡å‡†å¯¹é½çš„å»ºè®®
        standards = quality_data.get('standards_alignment', {})
        low_compliance_standards = [
            name for name, data in standards.items() 
            if data.get('compliance_score', 0) < 0.7
        ]
        if low_compliance_standards:
            suggestions.append(f"æé«˜ä»¥ä¸‹æ ‡å‡†çš„åˆè§„æ€§: {', '.join(low_compliance_standards)}")
        
        # åŸºäºçŸ¥è¯†å®Œæ•´æ€§çš„å»ºè®®
        knowledge = quality_data.get('knowledge_completeness', {})
        missing_components = knowledge.get('missing_components', [])
        if missing_components:
            suggestions.append(f"è¡¥å……ç¼ºå¤±çš„çŸ¥è¯†ç»„ä»¶: {', '.join(missing_components[:3])}")
        
        return suggestions

class AutomatedQualityAssurance:
    """è‡ªåŠ¨åŒ–è´¨é‡ä¿è¯ä¸»ç±»"""
    
    def __init__(self, base_path: str = "doc"):
        self.base_path = Path(base_path)
        self.doc_checker = DocumentQualityChecker(base_path)
        self.standards_checker = StandardsAlignmentChecker()
        self.knowledge_checker = KnowledgeCompletenessChecker(base_path)
        self.report_generator = QualityReportGenerator()
    
    def run_quality_assurance(self) -> Dict[str, Any]:
        """è¿è¡Œè´¨é‡ä¿è¯æ£€æŸ¥"""
        logger.info("å¼€å§‹è¿è¡Œè‡ªåŠ¨åŒ–è´¨é‡ä¿è¯æ£€æŸ¥...")
        
        quality_data = {}
        
        # 1. æ–‡æ¡£è´¨é‡æ£€æŸ¥
        logger.info("æ‰§è¡Œæ–‡æ¡£è´¨é‡æ£€æŸ¥...")
        quality_data['document_quality'] = self._check_document_quality()
        
        # 2. æ ‡å‡†å¯¹é½æ£€æŸ¥
        logger.info("æ‰§è¡Œæ ‡å‡†å¯¹é½æ£€æŸ¥...")
        quality_data['standards_alignment'] = self.standards_checker.check_standards_alignment()
        
        # 3. çŸ¥è¯†å®Œæ•´æ€§æ£€æŸ¥
        logger.info("æ‰§è¡ŒçŸ¥è¯†å®Œæ•´æ€§æ£€æŸ¥...")
        quality_data['knowledge_completeness'] = self.knowledge_checker.check_knowledge_completeness()
        
        # 4. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        logger.info("ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
        report_content = self.report_generator.generate_quality_report(quality_data)
        
        # 5. ä¿å­˜æŠ¥å‘Š
        self._save_quality_report(report_content)
        
        logger.info("è‡ªåŠ¨åŒ–è´¨é‡ä¿è¯æ£€æŸ¥å®Œæˆ")
        return quality_data
    
    def _check_document_quality(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡æ¡£è´¨é‡"""
        # è·å–æ‰€æœ‰markdownæ–‡ä»¶
        md_files = list(self.base_path.glob('**/*.md'))
        
        detailed_results = {}
        total_metrics = QualityMetrics(0, 0, 0, 0, 0, QualityLevel.POOR)
        
        for md_file in md_files:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            rel_path = md_file.relative_to(self.base_path)
            
            # æ£€æŸ¥æ–‡æ¡£è´¨é‡
            metrics = self.doc_checker.check_document_quality(str(rel_path))
            detailed_results[str(rel_path)] = metrics
            
            # ç´¯åŠ æŒ‡æ ‡
            total_metrics.completeness += metrics.completeness
            total_metrics.accuracy += metrics.accuracy
            total_metrics.consistency += metrics.consistency
            total_metrics.timeliness += metrics.timeliness
        
        # è®¡ç®—å¹³å‡å€¼
        file_count = len(md_files)
        if file_count > 0:
            total_metrics.completeness /= file_count
            total_metrics.accuracy /= file_count
            total_metrics.consistency /= file_count
            total_metrics.timeliness /= file_count
            total_metrics.overall_score = (
                total_metrics.completeness + total_metrics.accuracy + 
                total_metrics.consistency + total_metrics.timeliness
            ) / 4
            total_metrics.level = self.doc_checker._determine_quality_level(total_metrics.overall_score)
        
        return {
            'detailed_results': detailed_results,
            'average_completeness': total_metrics.completeness,
            'average_accuracy': total_metrics.accuracy,
            'average_consistency': total_metrics.consistency,
            'average_timeliness': total_metrics.timeliness,
            'overall_score': total_metrics.overall_score,
            'total_files_checked': file_count
        }
    
    def _save_quality_report(self, report_content: str):
        """ä¿å­˜è´¨é‡æŠ¥å‘Š"""
        try:
            # åˆ›å»ºæŠ¥å‘Šç›®å½•
            report_dir = Path("reports")
            report_dir.mkdir(exist_ok=True)
            
            # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = report_dir / f"quality_assurance_report_{timestamp}.md"
            
            # ä¿å­˜æŠ¥å‘Š
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            logger.info(f"è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è´¨é‡æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºè‡ªåŠ¨åŒ–è´¨é‡ä¿è¯å®ä¾‹
        qa_system = AutomatedQualityAssurance()
        
        # è¿è¡Œè´¨é‡ä¿è¯æ£€æŸ¥
        quality_data = qa_system.run_quality_assurance()
        
        # è¾“å‡ºç®€è¦ç»“æœ
        print("\n" + "="*60)
        print("OpenTelemetry 2025 è‡ªåŠ¨åŒ–è´¨é‡ä¿è¯æ£€æŸ¥ç»“æœ")
        print("="*60)
        
        doc_quality = quality_data.get('document_quality', {})
        print(f"ğŸ“Š æ–‡æ¡£è´¨é‡æ€»ä½“åˆ†æ•°: {doc_quality.get('overall_score', 0):.2%}")
        print(f"ğŸ“ æ£€æŸ¥æ–‡æ¡£æ•°é‡: {doc_quality.get('total_files_checked', 0)}")
        
        knowledge = quality_data.get('knowledge_completeness', {})
        print(f"ğŸ§  çŸ¥è¯†å®Œæ•´æ€§: {knowledge.get('total_completeness', 0):.2%}")
        
        standards = quality_data.get('standards_alignment', {})
        print(f"ğŸ“‹ æ ‡å‡†å¯¹é½æ•°é‡: {len(standards)}")
        
        print("\nè¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹ reports/ ç›®å½•")
        print("="*60)
        
    except Exception as e:
        logger.error(f"è¿è¡Œè´¨é‡ä¿è¯æ£€æŸ¥æ—¶å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
