# OTLPåˆ†å¸ƒå¼ä¸€è‡´æ€§ä¸åè°ƒæœºåˆ¶æ·±åº¦åˆ†æ

## ç›®å½•

- [OTLPåˆ†å¸ƒå¼ä¸€è‡´æ€§ä¸åè°ƒæœºåˆ¶æ·±åº¦åˆ†æ](#otlpåˆ†å¸ƒå¼ä¸€è‡´æ€§ä¸åè°ƒæœºåˆ¶æ·±åº¦åˆ†æ)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“Š æ–‡æ¡£æ¦‚è§ˆ](#-æ–‡æ¡£æ¦‚è§ˆ)
  - [1. åˆ†å¸ƒå¼ä¸€è‡´æ€§ç†è®ºåŸºç¡€](#1-åˆ†å¸ƒå¼ä¸€è‡´æ€§ç†è®ºåŸºç¡€)
    - [1.1 CAPå®šç†ä¸OTLP](#11-capå®šç†ä¸otlp)
    - [1.2 ä¸€è‡´æ€§æ¨¡å‹åˆ†ç±»](#12-ä¸€è‡´æ€§æ¨¡å‹åˆ†ç±»)
    - [1.3 OTLPä¸€è‡´æ€§éœ€æ±‚](#13-otlpä¸€è‡´æ€§éœ€æ±‚)
  - [2. OTLPåˆ†å¸ƒå¼ä¸€è‡´æ€§æ¨¡å‹](#2-otlpåˆ†å¸ƒå¼ä¸€è‡´æ€§æ¨¡å‹)
    - [2.1 Traceä¸€è‡´æ€§æ¨¡å‹](#21-traceä¸€è‡´æ€§æ¨¡å‹)
    - [2.2 Spanå…³ç³»ä¸€è‡´æ€§](#22-spanå…³ç³»ä¸€è‡´æ€§)
    - [2.3 æ—¶é—´æˆ³ä¸€è‡´æ€§](#23-æ—¶é—´æˆ³ä¸€è‡´æ€§)
    - [2.4 ä¸Šä¸‹æ–‡ä¼ æ’­ä¸€è‡´æ€§](#24-ä¸Šä¸‹æ–‡ä¼ æ’­ä¸€è‡´æ€§)
  - [3. åˆ†å¸ƒå¼åè°ƒæœºåˆ¶](#3-åˆ†å¸ƒå¼åè°ƒæœºåˆ¶)
    - [3.1 åˆ†å¸ƒå¼é”](#31-åˆ†å¸ƒå¼é”)
    - [3.2 åˆ†å¸ƒå¼äº‹åŠ¡](#32-åˆ†å¸ƒå¼äº‹åŠ¡)
    - [3.3 åˆ†å¸ƒå¼å±éšœ](#33-åˆ†å¸ƒå¼å±éšœ)
    - [3.4 Leaderé€‰ä¸¾](#34-leaderé€‰ä¸¾)
  - [4. å…±è¯†ç®—æ³•åº”ç”¨](#4-å…±è¯†ç®—æ³•åº”ç”¨)
    - [4.1 Raftç®—æ³•é›†æˆ](#41-raftç®—æ³•é›†æˆ)
    - [4.2 Paxosç®—æ³•åº”ç”¨](#42-paxosç®—æ³•åº”ç”¨)
    - [4.3 ZABåè®®åˆ†æ](#43-zabåè®®åˆ†æ)
  - [5. æœ€ç»ˆä¸€è‡´æ€§å®ç°](#5-æœ€ç»ˆä¸€è‡´æ€§å®ç°)
    - [5.1 å¼‚æ­¥å¤åˆ¶æ¨¡å‹](#51-å¼‚æ­¥å¤åˆ¶æ¨¡å‹)
    - [5.2 å†²çªæ£€æµ‹ä¸è§£å†³](#52-å†²çªæ£€æµ‹ä¸è§£å†³)
    - [5.3 ç‰ˆæœ¬å‘é‡](#53-ç‰ˆæœ¬å‘é‡)
    - [5.4 Gossipåè®®](#54-gossipåè®®)
  - [6. å› æœä¸€è‡´æ€§ä¿è¯](#6-å› æœä¸€è‡´æ€§ä¿è¯)
    - [6.1 å› æœå…³ç³»å»ºæ¨¡](#61-å› æœå…³ç³»å»ºæ¨¡)
    - [6.2 å‘é‡æ—¶é’Ÿ](#62-å‘é‡æ—¶é’Ÿ)
    - [6.3 å› æœå¹¿æ’­](#63-å› æœå¹¿æ’­)
  - [7. å®è·µæ¡ˆä¾‹](#7-å®è·µæ¡ˆä¾‹)
    - [7.1 åˆ†å¸ƒå¼Traceæ”¶é›†ä¸€è‡´æ€§](#71-åˆ†å¸ƒå¼traceæ”¶é›†ä¸€è‡´æ€§)
    - [7.2 è·¨åŒºåŸŸæ•°æ®åŒæ­¥](#72-è·¨åŒºåŸŸæ•°æ®åŒæ­¥)
    - [7.3 å¤šCollectoråè°ƒ](#73-å¤šcollectoråè°ƒ)
  - [8. æ€»ç»“ä¸å±•æœ›](#8-æ€»ç»“ä¸å±•æœ›)
    - [æ ¸å¿ƒæˆæœ](#æ ¸å¿ƒæˆæœ)
    - [åˆ›æ–°è´¡çŒ®](#åˆ›æ–°è´¡çŒ®)
    - [æœªæ¥å±•æœ›](#æœªæ¥å±•æœ›)

## ğŸ“Š æ–‡æ¡£æ¦‚è§ˆ

**åˆ›å»ºæ—¶é—´**: 2025å¹´10æœˆ7æ—¥  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**ç»´æŠ¤è€…**: OTLP ç³»ç»Ÿåˆ†æå›¢é˜Ÿ  
**çŠ¶æ€**: æ ¸å¿ƒè¡¥å……å®Œæˆ  
**é€‚ç”¨èŒƒå›´**: OTLPåˆ†å¸ƒå¼ä¸€è‡´æ€§ä¸åè°ƒæœºåˆ¶åˆ†æ

## 1. åˆ†å¸ƒå¼ä¸€è‡´æ€§ç†è®ºåŸºç¡€

### 1.1 CAPå®šç†ä¸OTLP

**CAPå®šç†**:

åˆ†å¸ƒå¼ç³»ç»Ÿæœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³ä»¥ä¸‹ä¸‰ä¸ªç‰¹æ€§ä¸­çš„ä¸¤ä¸ª:

1. **ä¸€è‡´æ€§(Consistency)**: æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶é—´çœ‹åˆ°ç›¸åŒçš„æ•°æ®
2. **å¯ç”¨æ€§(Availability)**: æ¯ä¸ªè¯·æ±‚éƒ½èƒ½å¾—åˆ°å“åº”
3. **åˆ†åŒºå®¹é”™æ€§(Partition Tolerance)**: ç³»ç»Ÿåœ¨ç½‘ç»œåˆ†åŒºæ—¶ä»èƒ½å·¥ä½œ

**OTLPçš„CAPæƒè¡¡**:

```text
OTLPç³»ç»Ÿè®¾è®¡é€‰æ‹©: AP (å¯ç”¨æ€§ + åˆ†åŒºå®¹é”™æ€§)

ç†ç”±:
1. å¯è§‚æµ‹æ€§æ•°æ®å…è®¸çŸ­æš‚çš„ä¸ä¸€è‡´
2. ç³»ç»Ÿå¯ç”¨æ€§æ¯”å¼ºä¸€è‡´æ€§æ›´é‡è¦
3. æœ€ç»ˆä¸€è‡´æ€§è¶³ä»¥æ»¡è¶³åˆ†æéœ€æ±‚
```

**å®šç†1.1 (OTLPä¸€è‡´æ€§æƒè¡¡)**:

å¯¹äºOTLPç³»ç»Ÿ `S = (C, A, P)`:

```text
S âŠ¨ A âˆ§ P âˆ§ â—‡C

å…¶ä¸­:
- A: å¯ç”¨æ€§ (å§‹ç»ˆæ»¡è¶³)
- P: åˆ†åŒºå®¹é”™æ€§ (å§‹ç»ˆæ»¡è¶³)
- â—‡C: æœ€ç»ˆä¸€è‡´æ€§ (eventuallyæ»¡è¶³)
```

### 1.2 ä¸€è‡´æ€§æ¨¡å‹åˆ†ç±»

**ä¸€è‡´æ€§æ¨¡å‹å±‚æ¬¡**:

```text
å¼ºä¸€è‡´æ€§
â”œâ”€â”€ çº¿æ€§ä¸€è‡´æ€§ (Linearizability)
â”‚   â””â”€â”€ æ‰€æœ‰æ“ä½œçœ‹èµ·æ¥æ˜¯ç¬æ—¶å®Œæˆçš„
â”œâ”€â”€ é¡ºåºä¸€è‡´æ€§ (Sequential Consistency)
â”‚   â””â”€â”€ æ‰€æœ‰æ“ä½œæŒ‰æŸä¸ªå…¨å±€é¡ºåºæ‰§è¡Œ
â””â”€â”€ å› æœä¸€è‡´æ€§ (Causal Consistency)
    â””â”€â”€ å› æœç›¸å…³çš„æ“ä½œä¿æŒé¡ºåº

å¼±ä¸€è‡´æ€§
â”œâ”€â”€ æœ€ç»ˆä¸€è‡´æ€§ (Eventual Consistency)
â”‚   â””â”€â”€ æœ€ç»ˆæ‰€æœ‰å‰¯æœ¬ä¼šæ”¶æ•›
â”œâ”€â”€ ä¼šè¯ä¸€è‡´æ€§ (Session Consistency)
â”‚   â””â”€â”€ åŒä¸€ä¼šè¯å†…ä¿è¯ä¸€è‡´æ€§
â””â”€â”€ å•è°ƒä¸€è‡´æ€§ (Monotonic Consistency)
    â””â”€â”€ è¯»æ“ä½œå•è°ƒé€’å¢
```

**å®šä¹‰1.1 (OTLPä¸€è‡´æ€§æ¨¡å‹)**:

OTLPé‡‡ç”¨**å› æœä¸€è‡´æ€§ + æœ€ç»ˆä¸€è‡´æ€§**æ··åˆæ¨¡å‹:

```text
ConsistencyModel = (Causal, Eventual)

å…¶ä¸­:
- Causal: åŒä¸€Traceå†…çš„Spanä¿æŒå› æœé¡ºåº
- Eventual: ä¸åŒTraceé—´æœ€ç»ˆä¸€è‡´
```

### 1.3 OTLPä¸€è‡´æ€§éœ€æ±‚

**æ ¸å¿ƒä¸€è‡´æ€§éœ€æ±‚**:

1. **Traceå®Œæ•´æ€§**: ä¸€ä¸ªTraceçš„æ‰€æœ‰Spanæœ€ç»ˆå¿…é¡»æ”¶é›†å®Œæ•´
2. **Spané¡ºåºæ€§**: çˆ¶å­Spançš„å› æœå…³ç³»å¿…é¡»ä¿æŒ
3. **æ—¶é—´æˆ³å•è°ƒæ€§**: åŒä¸€Traceå†…æ—¶é—´æˆ³å•è°ƒé€’å¢
4. **ä¸Šä¸‹æ–‡ä¸€è‡´æ€§**: Contextä¼ æ’­è¿‡ç¨‹ä¸­ä¿æŒä¸€è‡´

**å½¢å¼åŒ–å®šä¹‰**:

```text
å®šä¹‰1.2 (Traceå®Œæ•´æ€§)

å¯¹äºTrace T = {sâ‚, sâ‚‚, ..., sâ‚™}:

âˆ€ sáµ¢ âˆˆ T: â—‡(sáµ¢ âˆˆ CollectedSpans)

å³:æ¯ä¸ªSpanæœ€ç»ˆéƒ½ä¼šè¢«æ”¶é›†

å®šä¹‰1.3 (Spané¡ºåºæ€§)

å¯¹äºSpan sâ‚, sâ‚‚:

if sâ‚ â†’ sâ‚‚ (å› æœå…³ç³»)
then timestamp(sâ‚) < timestamp(sâ‚‚)

å®šä¹‰1.4 (ä¸Šä¸‹æ–‡ä¸€è‡´æ€§)

å¯¹äºContextä¼ æ’­ Câ‚ â†’ Câ‚‚:

trace_id(Câ‚) = trace_id(Câ‚‚)
parent_span_id(Câ‚‚) = span_id(Câ‚)
```

## 2. OTLPåˆ†å¸ƒå¼ä¸€è‡´æ€§æ¨¡å‹

### 2.1 Traceä¸€è‡´æ€§æ¨¡å‹

**TraceçŠ¶æ€æœº**:

```python
class TraceStateMachine:
    """TraceçŠ¶æ€æœº"""
    
    class State(Enum):
        ACTIVE = "active"        # æ´»è·ƒçŠ¶æ€
        COLLECTING = "collecting"  # æ”¶é›†ä¸­
        COMPLETE = "complete"    # å®Œæˆ
        TIMEOUT = "timeout"      # è¶…æ—¶
    
    def __init__(self, trace_id: str, timeout: int = 60):
        self.trace_id = trace_id
        self.state = self.State.ACTIVE
        self.spans = {}
        self.expected_spans = set()
        self.timeout = timeout
        self.start_time = time.time()
        self.lock = threading.RLock()
    
    def add_span(self, span: Span) -> bool:
        """æ·»åŠ Span"""
        with self.lock:
            # æ£€æŸ¥çŠ¶æ€
            if self.state == self.State.COMPLETE:
                return False
            
            # æ·»åŠ Span
            self.spans[span.span_id] = span
            
            # æ›´æ–°é¢„æœŸSpané›†åˆ
            if span.parent_span_id:
                self.expected_spans.add(span.parent_span_id)
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if self._is_complete():
                self.state = self.State.COMPLETE
                return True
            
            # æ£€æŸ¥è¶…æ—¶
            if time.time() - self.start_time > self.timeout:
                self.state = self.State.TIMEOUT
                return False
            
            self.state = self.State.COLLECTING
            return True
    
    def _is_complete(self) -> bool:
        """æ£€æŸ¥Traceæ˜¯å¦å®Œæ•´"""
        # æ‰€æœ‰é¢„æœŸçš„Spanéƒ½å·²æ”¶é›†
        collected_ids = set(self.spans.keys())
        return self.expected_spans.issubset(collected_ids)
    
    def get_missing_spans(self) -> Set[str]:
        """è·å–ç¼ºå¤±çš„Spans"""
        with self.lock:
            collected_ids = set(self.spans.keys())
            return self.expected_spans - collected_ids
```

**Traceä¸€è‡´æ€§åè®®**:

```python
class TraceConsistencyProtocol:
    """Traceä¸€è‡´æ€§åè®®"""
    
    def __init__(self):
        self.traces = {}  # trace_id -> TraceStateMachine
        self.lock = threading.RLock()
    
    def process_span(self, span: Span):
        """å¤„ç†Span"""
        with self.lock:
            # è·å–æˆ–åˆ›å»ºTraceçŠ¶æ€æœº
            if span.trace_id not in self.traces:
                self.traces[span.trace_id] = TraceStateMachine(span.trace_id)
            
            trace_sm = self.traces[span.trace_id]
            
            # æ·»åŠ Span
            is_complete = trace_sm.add_span(span)
            
            if is_complete:
                # Traceå®Œæˆ,è§¦å‘å¤„ç†
                self._handle_complete_trace(trace_sm)
            elif trace_sm.state == TraceStateMachine.State.TIMEOUT:
                # Traceè¶…æ—¶,è§¦å‘è¡¥å¿
                self._handle_timeout_trace(trace_sm)
    
    def _handle_complete_trace(self, trace_sm: TraceStateMachine):
        """å¤„ç†å®Œæ•´çš„Trace"""
        logger.info(f"Trace {trace_sm.trace_id} completed with {len(trace_sm.spans)} spans")
        
        # éªŒè¯ä¸€è‡´æ€§
        if self._verify_consistency(trace_sm):
            # æŒä¹…åŒ–
            self._persist_trace(trace_sm)
        else:
            logger.error(f"Trace {trace_sm.trace_id} consistency check failed")
    
    def _handle_timeout_trace(self, trace_sm: TraceStateMachine):
        """å¤„ç†è¶…æ—¶çš„Trace"""
        missing = trace_sm.get_missing_spans()
        logger.warning(
            f"Trace {trace_sm.trace_id} timeout, "
            f"missing {len(missing)} spans: {missing}"
        )
        
        # å°è¯•è¡¥å¿
        self._compensate_missing_spans(trace_sm, missing)
    
    def _verify_consistency(self, trace_sm: TraceStateMachine) -> bool:
        """éªŒè¯Traceä¸€è‡´æ€§"""
        spans = list(trace_sm.spans.values())
        
        # 1. éªŒè¯Trace IDä¸€è‡´æ€§
        for span in spans:
            if span.trace_id != trace_sm.trace_id:
                return False
        
        # 2. éªŒè¯çˆ¶å­å…³ç³»
        span_ids = {s.span_id for s in spans}
        for span in spans:
            if span.parent_span_id and span.parent_span_id not in span_ids:
                return False
        
        # 3. éªŒè¯æ—¶é—´æˆ³å•è°ƒæ€§
        if not self._verify_timestamp_monotonicity(spans):
            return False
        
        return True
    
    def _verify_timestamp_monotonicity(self, spans: List[Span]) -> bool:
        """éªŒè¯æ—¶é—´æˆ³å•è°ƒæ€§"""
        # æ„å»ºçˆ¶å­å…³ç³»å›¾
        children = defaultdict(list)
        for span in spans:
            if span.parent_span_id:
                children[span.parent_span_id].append(span)
        
        # DFSéªŒè¯
        def dfs(span: Span) -> bool:
            for child in children[span.span_id]:
                # çˆ¶Spanå¼€å§‹æ—¶é—´ <= å­Spanå¼€å§‹æ—¶é—´
                if span.start_time > child.start_time:
                    return False
                
                # çˆ¶Spanç»“æŸæ—¶é—´ >= å­Spanç»“æŸæ—¶é—´
                if span.end_time and child.end_time:
                    if span.end_time < child.end_time:
                        return False
                
                if not dfs(child):
                    return False
            
            return True
        
        # æ‰¾åˆ°æ ¹Span
        root_spans = [s for s in spans if not s.parent_span_id]
        for root in root_spans:
            if not dfs(root):
                return False
        
        return True
```

### 2.2 Spanå…³ç³»ä¸€è‡´æ€§

**Spanå…³ç³»å›¾**:

```python
class SpanRelationshipGraph:
    """Spanå…³ç³»å›¾"""
    
    def __init__(self):
        self.nodes = {}  # span_id -> Span
        self.edges = defaultdict(list)  # parent_id -> [child_ids]
        self.lock = threading.RLock()
    
    def add_span(self, span: Span):
        """æ·»åŠ Span"""
        with self.lock:
            self.nodes[span.span_id] = span
            
            if span.parent_span_id:
                self.edges[span.parent_span_id].append(span.span_id)
    
    def verify_consistency(self) -> Tuple[bool, List[str]]:
        """éªŒè¯ä¸€è‡´æ€§"""
        errors = []
        
        # 1. æ£€æŸ¥å­¤å„¿Span
        orphans = self._find_orphans()
        if orphans:
            errors.append(f"Found {len(orphans)} orphan spans: {orphans}")
        
        # 2. æ£€æŸ¥ç¯è·¯
        cycles = self._find_cycles()
        if cycles:
            errors.append(f"Found cycles: {cycles}")
        
        # 3. æ£€æŸ¥å¤šæ ¹
        roots = self._find_roots()
        if len(roots) > 1:
            errors.append(f"Found multiple roots: {roots}")
        
        return len(errors) == 0, errors
    
    def _find_orphans(self) -> List[str]:
        """æŸ¥æ‰¾å­¤å„¿Span"""
        orphans = []
        
        for span_id, span in self.nodes.items():
            if span.parent_span_id:
                if span.parent_span_id not in self.nodes:
                    orphans.append(span_id)
        
        return orphans
    
    def _find_cycles(self) -> List[List[str]]:
        """æŸ¥æ‰¾ç¯è·¯"""
        visited = set()
        rec_stack = set()
        cycles = []
        
        def dfs(node_id: str, path: List[str]):
            visited.add(node_id)
            rec_stack.add(node_id)
            path.append(node_id)
            
            for child_id in self.edges[node_id]:
                if child_id not in visited:
                    dfs(child_id, path.copy())
                elif child_id in rec_stack:
                    # å‘ç°ç¯è·¯
                    cycle_start = path.index(child_id)
                    cycles.append(path[cycle_start:] + [child_id])
            
            rec_stack.remove(node_id)
        
        for node_id in self.nodes:
            if node_id not in visited:
                dfs(node_id, [])
        
        return cycles
    
    def _find_roots(self) -> List[str]:
        """æŸ¥æ‰¾æ ¹Span"""
        return [
            span_id for span_id, span in self.nodes.items()
            if not span.parent_span_id
        ]
```

### 2.3 æ—¶é—´æˆ³ä¸€è‡´æ€§

**åˆ†å¸ƒå¼æ—¶é’ŸåŒæ­¥**:

```python
class DistributedClockSync:
    """åˆ†å¸ƒå¼æ—¶é’ŸåŒæ­¥"""
    
    def __init__(self, ntp_servers: List[str]):
        self.ntp_servers = ntp_servers
        self.clock_offset = 0
        self.last_sync = 0
        self.sync_interval = 60  # 60ç§’åŒæ­¥ä¸€æ¬¡
        self.lock = threading.Lock()
    
    def get_time(self) -> int:
        """è·å–åŒæ­¥åçš„æ—¶é—´"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥
        if time.time() - self.last_sync > self.sync_interval:
            self._sync_clock()
        
        # è¿”å›è°ƒæ•´åçš„æ—¶é—´
        return time.time_ns() + self.clock_offset
    
    def _sync_clock(self):
        """åŒæ­¥æ—¶é’Ÿ"""
        with self.lock:
            offsets = []
            
            # å‘å¤šä¸ªNTPæœåŠ¡å™¨æŸ¥è¯¢
            for server in self.ntp_servers:
                try:
                    offset = self._query_ntp(server)
                    offsets.append(offset)
                except Exception as e:
                    logger.warning(f"NTP query failed for {server}: {e}")
            
            if offsets:
                # ä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºåç§»é‡
                self.clock_offset = statistics.median(offsets)
                self.last_sync = time.time()
    
    def _query_ntp(self, server: str) -> int:
        """æŸ¥è¯¢NTPæœåŠ¡å™¨"""
        # å®ç°NTPåè®®
        # ...
        pass

class HybridLogicalClock:
    """æ··åˆé€»è¾‘æ—¶é’Ÿ (HLC)"""
    
    def __init__(self):
        self.physical_time = 0
        self.logical_time = 0
        self.lock = threading.Lock()
    
    def now(self) -> Tuple[int, int]:
        """è·å–å½“å‰æ—¶é—´"""
        with self.lock:
            pt = time.time_ns()
            
            if pt > self.physical_time:
                self.physical_time = pt
                self.logical_time = 0
            else:
                self.logical_time += 1
            
            return (self.physical_time, self.logical_time)
    
    def update(self, remote_pt: int, remote_lt: int):
        """æ›´æ–°æ—¶é’Ÿ"""
        with self.lock:
            pt = time.time_ns()
            
            # å–æœ€å¤§ç‰©ç†æ—¶é—´
            self.physical_time = max(pt, remote_pt, self.physical_time)
            
            # æ›´æ–°é€»è¾‘æ—¶é—´
            if self.physical_time == remote_pt:
                self.logical_time = max(self.logical_time, remote_lt) + 1
            elif self.physical_time == pt:
                self.logical_time += 1
            else:
                self.logical_time = 0
    
    def compare(self, t1: Tuple[int, int], t2: Tuple[int, int]) -> int:
        """æ¯”è¾ƒä¸¤ä¸ªæ—¶é—´æˆ³"""
        if t1[0] < t2[0]:
            return -1
        elif t1[0] > t2[0]:
            return 1
        else:
            # ç‰©ç†æ—¶é—´ç›¸åŒ,æ¯”è¾ƒé€»è¾‘æ—¶é—´
            if t1[1] < t2[1]:
                return -1
            elif t1[1] > t2[1]:
                return 1
            else:
                return 0
```

### 2.4 ä¸Šä¸‹æ–‡ä¼ æ’­ä¸€è‡´æ€§

**ä¸Šä¸‹æ–‡ä¼ æ’­åè®®**:

```python
class ContextPropagationProtocol:
    """ä¸Šä¸‹æ–‡ä¼ æ’­åè®®"""
    
    @staticmethod
    def inject(context: Context, carrier: Dict[str, str]):
        """æ³¨å…¥ä¸Šä¸‹æ–‡åˆ°è½½ä½“"""
        # W3C Trace Contextæ ¼å¼
        carrier['traceparent'] = ContextPropagationProtocol._format_traceparent(context)
        
        # ä¼ æ’­Tracestate
        if context.tracestate:
            carrier['tracestate'] = ContextPropagationProtocol._format_tracestate(context.tracestate)
    
    @staticmethod
    def extract(carrier: Dict[str, str]) -> Optional[Context]:
        """ä»è½½ä½“æå–ä¸Šä¸‹æ–‡"""
        traceparent = carrier.get('traceparent')
        if not traceparent:
            return None
        
        # è§£ætraceparent
        context = ContextPropagationProtocol._parse_traceparent(traceparent)
        
        # è§£ætracestate
        tracestate = carrier.get('tracestate')
        if tracestate:
            context.tracestate = ContextPropagationProtocol._parse_tracestate(tracestate)
        
        return context
    
    @staticmethod
    def _format_traceparent(context: Context) -> str:
        """æ ¼å¼åŒ–traceparent"""
        # æ ¼å¼: version-trace_id-parent_id-trace_flags
        return f"00-{context.trace_id:032x}-{context.span_id:016x}-{context.trace_flags:02x}"
    
    @staticmethod
    def _parse_traceparent(traceparent: str) -> Context:
        """è§£ætraceparent"""
        parts = traceparent.split('-')
        
        if len(parts) != 4:
            raise ValueError(f"Invalid traceparent format: {traceparent}")
        
        version, trace_id, parent_id, trace_flags = parts
        
        return Context(
            trace_id=int(trace_id, 16),
            span_id=int(parent_id, 16),
            trace_flags=int(trace_flags, 16)
        )
    
    @staticmethod
    def verify_propagation(parent_ctx: Context, child_ctx: Context) -> bool:
        """éªŒè¯ä¸Šä¸‹æ–‡ä¼ æ’­ä¸€è‡´æ€§"""
        # 1. Trace IDå¿…é¡»ç›¸åŒ
        if parent_ctx.trace_id != child_ctx.trace_id:
            return False
        
        # 2. å­Spançš„parent_span_idåº”è¯¥æ˜¯çˆ¶Spançš„span_id
        if child_ctx.parent_span_id != parent_ctx.span_id:
            return False
        
        # 3. Trace flagsåº”è¯¥è¢«ç»§æ‰¿
        if parent_ctx.trace_flags & 0x01:  # sampled flag
            if not (child_ctx.trace_flags & 0x01):
                return False
        
        return True
```

## 3. åˆ†å¸ƒå¼åè°ƒæœºåˆ¶

### 3.1 åˆ†å¸ƒå¼é”

**åŸºäºRedisçš„åˆ†å¸ƒå¼é”**:

```python
class DistributedLock:
    """åˆ†å¸ƒå¼é”"""
    
    def __init__(self, redis_client, lock_name: str, timeout: int = 10):
        self.redis = redis_client
        self.lock_name = f"lock:{lock_name}"
        self.timeout = timeout
        self.lock_id = str(uuid.uuid4())
    
    def acquire(self, blocking: bool = True, timeout: Optional[float] = None) -> bool:
        """è·å–é”"""
        start_time = time.time()
        
        while True:
            # å°è¯•è®¾ç½®é”
            if self.redis.set(
                self.lock_name,
                self.lock_id,
                nx=True,  # åªåœ¨é”®ä¸å­˜åœ¨æ—¶è®¾ç½®
                ex=self.timeout  # è¿‡æœŸæ—¶é—´
            ):
                return True
            
            if not blocking:
                return False
            
            # æ£€æŸ¥è¶…æ—¶
            if timeout and (time.time() - start_time) > timeout:
                return False
            
            # çŸ­æš‚ç­‰å¾…
            time.sleep(0.001)
    
    def release(self):
        """é‡Šæ”¾é”"""
        # ä½¿ç”¨Luaè„šæœ¬ä¿è¯åŸå­æ€§
        lua_script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        
        self.redis.eval(lua_script, 1, self.lock_name, self.lock_id)
    
    def __enter__(self):
        self.acquire()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

# ä½¿ç”¨ç¤ºä¾‹
async def process_trace_with_lock(trace_id: str):
    """ä½¿ç”¨åˆ†å¸ƒå¼é”å¤„ç†Trace"""
    lock = DistributedLock(redis_client, f"trace:{trace_id}")
    
    if lock.acquire(timeout=5):
        try:
            # å¤„ç†Trace
            trace = load_trace(trace_id)
            process_trace(trace)
        finally:
            lock.release()
    else:
        logger.warning(f"Failed to acquire lock for trace {trace_id}")
```

### 3.2 åˆ†å¸ƒå¼äº‹åŠ¡

**ä¸¤é˜¶æ®µæäº¤(2PC)**:

```python
class TwoPhaseCommitCoordinator:
    """ä¸¤é˜¶æ®µæäº¤åè°ƒå™¨"""
    
    class Phase(Enum):
        PREPARE = "prepare"
        COMMIT = "commit"
        ABORT = "abort"
    
    def __init__(self, participants: List[str]):
        self.participants = participants
        self.transaction_id = str(uuid.uuid4())
        self.votes = {}
        self.phase = None
    
    async def execute(self, operations: Dict[str, Operation]) -> bool:
        """æ‰§è¡Œåˆ†å¸ƒå¼äº‹åŠ¡"""
        # Phase 1: Prepare
        if not await self._prepare_phase(operations):
            await self._abort_phase()
            return False
        
        # Phase 2: Commit
        return await self._commit_phase()
    
    async def _prepare_phase(self, operations: Dict[str, Operation]) -> bool:
        """å‡†å¤‡é˜¶æ®µ"""
        self.phase = self.Phase.PREPARE
        
        # å‘æ‰€æœ‰å‚ä¸è€…å‘é€prepareè¯·æ±‚
        tasks = [
            self._send_prepare(participant, operations[participant])
            for participant in self.participants
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æŠ•ç¥¨
        for participant, result in zip(self.participants, results):
            if isinstance(result, Exception) or not result:
                self.votes[participant] = False
            else:
                self.votes[participant] = True
        
        # æ‰€æœ‰å‚ä¸è€…éƒ½æŠ•èµæˆç¥¨
        return all(self.votes.values())
    
    async def _commit_phase(self) -> bool:
        """æäº¤é˜¶æ®µ"""
        self.phase = self.Phase.COMMIT
        
        # å‘æ‰€æœ‰å‚ä¸è€…å‘é€commitè¯·æ±‚
        tasks = [
            self._send_commit(participant)
            for participant in self.participants
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‚ä¸è€…éƒ½æäº¤æˆåŠŸ
        return all(not isinstance(r, Exception) and r for r in results)
    
    async def _abort_phase(self):
        """ä¸­æ­¢é˜¶æ®µ"""
        self.phase = self.Phase.ABORT
        
        # å‘æ‰€æœ‰å‚ä¸è€…å‘é€abortè¯·æ±‚
        tasks = [
            self._send_abort(participant)
            for participant in self.participants
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _send_prepare(self, participant: str, operation: Operation) -> bool:
        """å‘é€prepareè¯·æ±‚"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{participant}/prepare",
                    json={
                        'transaction_id': self.transaction_id,
                        'operation': operation.to_dict()
                    },
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    return response.status == 200
        except Exception as e:
            logger.error(f"Prepare failed for {participant}: {e}")
            return False
```

**Sagaæ¨¡å¼**:

```python
class SagaOrchestrator:
    """Sagaç¼–æ’å™¨"""
    
    def __init__(self):
        self.steps = []
        self.compensations = []
    
    def add_step(self, action, compensation):
        """æ·»åŠ æ­¥éª¤"""
        self.steps.append(action)
        self.compensations.append(compensation)
    
    async def execute(self) -> bool:
        """æ‰§è¡ŒSaga"""
        executed_steps = []
        
        try:
            # é¡ºåºæ‰§è¡Œæ‰€æœ‰æ­¥éª¤
            for i, step in enumerate(self.steps):
                result = await step()
                
                if not result:
                    # æ­¥éª¤å¤±è´¥,æ‰§è¡Œè¡¥å¿
                    await self._compensate(executed_steps)
                    return False
                
                executed_steps.append(i)
            
            return True
        
        except Exception as e:
            logger.error(f"Saga execution failed: {e}")
            await self._compensate(executed_steps)
            return False
    
    async def _compensate(self, executed_steps: List[int]):
        """æ‰§è¡Œè¡¥å¿"""
        # é€†åºæ‰§è¡Œè¡¥å¿æ“ä½œ
        for i in reversed(executed_steps):
            try:
                await self.compensations[i]()
            except Exception as e:
                logger.error(f"Compensation failed for step {i}: {e}")

# ä½¿ç”¨ç¤ºä¾‹
async def distributed_trace_processing():
    """åˆ†å¸ƒå¼Traceå¤„ç† (Sagaæ¨¡å¼)"""
    saga = SagaOrchestrator()
    
    # æ­¥éª¤1: æ”¶é›†Spans
    saga.add_step(
        action=lambda: collect_spans(),
        compensation=lambda: delete_collected_spans()
    )
    
    # æ­¥éª¤2: å¤„ç†Spans
    saga.add_step(
        action=lambda: process_spans(),
        compensation=lambda: revert_processing()
    )
    
    # æ­¥éª¤3: æŒä¹…åŒ–
    saga.add_step(
        action=lambda: persist_spans(),
        compensation=lambda: delete_persisted_spans()
    )
    
    # æ‰§è¡ŒSaga
    success = await saga.execute()
    return success
```

### 3.3 åˆ†å¸ƒå¼å±éšœ

**åˆ†å¸ƒå¼å±éšœå®ç°**:

```python
class DistributedBarrier:
    """åˆ†å¸ƒå¼å±éšœ"""
    
    def __init__(self, redis_client, barrier_name: str, parties: int):
        self.redis = redis_client
        self.barrier_name = f"barrier:{barrier_name}"
        self.parties = parties
        self.participant_id = str(uuid.uuid4())
    
    async def await(self, timeout: Optional[float] = None):
        """ç­‰å¾…æ‰€æœ‰å‚ä¸è€…åˆ°è¾¾å±éšœ"""
        # æ³¨å†Œå‚ä¸è€…
        self.redis.sadd(self.barrier_name, self.participant_id)
        
        start_time = time.time()
        
        while True:
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‚ä¸è€…éƒ½åˆ°è¾¾
            count = self.redis.scard(self.barrier_name)
            
            if count >= self.parties:
                # æ‰€æœ‰å‚ä¸è€…åˆ°è¾¾,æ¸…é™¤å±éšœ
                self.redis.delete(self.barrier_name)
                return
            
            # æ£€æŸ¥è¶…æ—¶
            if timeout and (time.time() - start_time) > timeout:
                raise TimeoutError("Barrier timeout")
            
            # çŸ­æš‚ç­‰å¾…
            await asyncio.sleep(0.1)

# ä½¿ç”¨ç¤ºä¾‹
async def parallel_trace_processing(trace_id: str, num_workers: int):
    """å¹¶è¡ŒTraceå¤„ç†"""
    barrier = DistributedBarrier(redis_client, f"trace:{trace_id}", num_workers)
    
    async def worker(worker_id: int):
        # å¤„ç†éƒ¨åˆ†æ•°æ®
        process_partition(trace_id, worker_id)
        
        # ç­‰å¾…æ‰€æœ‰workerå®Œæˆ
        await barrier.await(timeout=30)
        
        # ç»§ç»­åç»­å¤„ç†
        aggregate_results(trace_id)
    
    # å¯åŠ¨æ‰€æœ‰workers
    tasks = [worker(i) for i in range(num_workers)]
    await asyncio.gather(*tasks)
```

### 3.4 Leaderé€‰ä¸¾

**åŸºäºRaftçš„Leaderé€‰ä¸¾**:

```python
class RaftLeaderElection:
    """Raft Leaderé€‰ä¸¾"""
    
    class State(Enum):
        FOLLOWER = "follower"
        CANDIDATE = "candidate"
        LEADER = "leader"
    
    def __init__(self, node_id: str, peers: List[str]):
        self.node_id = node_id
        self.peers = peers
        self.state = self.State.FOLLOWER
        self.current_term = 0
        self.voted_for = None
        self.votes_received = 0
        self.election_timeout = random.uniform(150, 300)  # ms
        self.last_heartbeat = time.time()
        self.lock = threading.Lock()
    
    def start(self):
        """å¯åŠ¨é€‰ä¸¾"""
        threading.Thread(target=self._election_loop, daemon=True).start()
        threading.Thread(target=self._heartbeat_loop, daemon=True).start()
    
    def _election_loop(self):
        """é€‰ä¸¾å¾ªç¯"""
        while True:
            if self.state == self.State.FOLLOWER:
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                if (time.time() - self.last_heartbeat) * 1000 > self.election_timeout:
                    self._start_election()
            
            time.sleep(0.01)
    
    def _start_election(self):
        """å¼€å§‹é€‰ä¸¾"""
        with self.lock:
            # è½¬æ¢ä¸ºå€™é€‰äºº
            self.state = self.State.CANDIDATE
            self.current_term += 1
            self.voted_for = self.node_id
            self.votes_received = 1  # æŠ•ç¥¨ç»™è‡ªå·±
            
            logger.info(f"Node {self.node_id} starting election for term {self.current_term}")
        
        # å‘æ‰€æœ‰peersè¯·æ±‚æŠ•ç¥¨
        for peer in self.peers:
            threading.Thread(target=self._request_vote, args=(peer,)).start()
    
    def _request_vote(self, peer: str):
        """è¯·æ±‚æŠ•ç¥¨"""
        try:
            response = requests.post(
                f"http://{peer}/request_vote",
                json={
                    'term': self.current_term,
                    'candidate_id': self.node_id
                },
                timeout=1
            )
            
            if response.status_code == 200:
                data = response.json()
                
                with self.lock:
                    # æ£€æŸ¥term
                    if data['term'] > self.current_term:
                        self._become_follower(data['term'])
                        return
                    
                    # æ”¶åˆ°æŠ•ç¥¨
                    if data['vote_granted']:
                        self.votes_received += 1
                        
                        # è·å¾—å¤šæ•°ç¥¨
                        if self.votes_received > len(self.peers) // 2:
                            self._become_leader()
        
        except Exception as e:
            logger.warning(f"Request vote to {peer} failed: {e}")
    
    def _become_leader(self):
        """æˆä¸ºLeader"""
        with self.lock:
            if self.state != self.State.CANDIDATE:
                return
            
            self.state = self.State.LEADER
            logger.info(f"Node {self.node_id} became leader for term {self.current_term}")
    
    def _become_follower(self, term: int):
        """æˆä¸ºFollower"""
        self.state = self.State.FOLLOWER
        self.current_term = term
        self.voted_for = None
        self.last_heartbeat = time.time()
    
    def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç¯"""
        while True:
            if self.state == self.State.LEADER:
                # å‘é€å¿ƒè·³
                for peer in self.peers:
                    threading.Thread(target=self._send_heartbeat, args=(peer,)).start()
            
            time.sleep(0.05)  # 50ms
    
    def _send_heartbeat(self, peer: str):
        """å‘é€å¿ƒè·³"""
        try:
            response = requests.post(
                f"http://{peer}/heartbeat",
                json={
                    'term': self.current_term,
                    'leader_id': self.node_id
                },
                timeout=1
            )
            
            if response.status_code == 200:
                data = response.json()
                
                with self.lock:
                    # æ£€æŸ¥term
                    if data['term'] > self.current_term:
                        self._become_follower(data['term'])
        
        except Exception as e:
            logger.warning(f"Heartbeat to {peer} failed: {e}")
    
    def handle_request_vote(self, term: int, candidate_id: str) -> Dict:
        """å¤„ç†æŠ•ç¥¨è¯·æ±‚"""
        with self.lock:
            # æ›´æ–°term
            if term > self.current_term:
                self._become_follower(term)
            
            # æŠ•ç¥¨
            vote_granted = False
            if term == self.current_term:
                if self.voted_for is None or self.voted_for == candidate_id:
                    self.voted_for = candidate_id
                    vote_granted = True
            
            return {
                'term': self.current_term,
                'vote_granted': vote_granted
            }
    
    def handle_heartbeat(self, term: int, leader_id: str) -> Dict:
        """å¤„ç†å¿ƒè·³"""
        with self.lock:
            # æ›´æ–°term
            if term >= self.current_term:
                self._become_follower(term)
            
            return {'term': self.current_term}
```

## 4. å…±è¯†ç®—æ³•åº”ç”¨

### 4.1 Raftç®—æ³•é›†æˆ

**Raftæ—¥å¿—å¤åˆ¶**:

```python
class RaftLogReplication:
    """Raftæ—¥å¿—å¤åˆ¶"""
    
    def __init__(self, node_id: str, peers: List[str]):
        self.node_id = node_id
        self.peers = peers
        self.log = []  # æ—¥å¿—æ¡ç›®
        self.commit_index = 0
        self.last_applied = 0
        self.next_index = {peer: 1 for peer in peers}
        self.match_index = {peer: 0 for peer in peers}
        self.lock = threading.Lock()
    
    def append_entry(self, command: Dict) -> bool:
        """è¿½åŠ æ—¥å¿—æ¡ç›®"""
        with self.lock:
            # åˆ›å»ºæ—¥å¿—æ¡ç›®
            entry = {
                'term': self.current_term,
                'index': len(self.log) + 1,
                'command': command
            }
            
            self.log.append(entry)
        
        # å¤åˆ¶åˆ°æ‰€æœ‰followers
        return self._replicate_log()
    
    def _replicate_log(self) -> bool:
        """å¤åˆ¶æ—¥å¿—åˆ°followers"""
        success_count = 1  # leaderè‡ªå·±
        
        for peer in self.peers:
            if self._send_append_entries(peer):
                success_count += 1
        
        # å¤šæ•°èŠ‚ç‚¹æˆåŠŸ
        if success_count > len(self.peers) // 2:
            self._commit_log()
            return True
        
        return False
    
    def _send_append_entries(self, peer: str) -> bool:
        """å‘é€AppendEntries RPC"""
        with self.lock:
            next_idx = self.next_index[peer]
            
            # å‡†å¤‡è¦å‘é€çš„æ—¥å¿—æ¡ç›®
            entries = self.log[next_idx-1:] if next_idx <= len(self.log) else []
            
            prev_log_index = next_idx - 1
            prev_log_term = self.log[prev_log_index-1]['term'] if prev_log_index > 0 else 0
        
        try:
            response = requests.post(
                f"http://{peer}/append_entries",
                json={
                    'term': self.current_term,
                    'leader_id': self.node_id,
                    'prev_log_index': prev_log_index,
                    'prev_log_term': prev_log_term,
                    'entries': entries,
                    'leader_commit': self.commit_index
                },
                timeout=1
            )
            
            if response.status_code == 200:
                data = response.json()
                
                with self.lock:
                    if data['success']:
                        # æ›´æ–°next_indexå’Œmatch_index
                        self.next_index[peer] = next_idx + len(entries)
                        self.match_index[peer] = next_idx + len(entries) - 1
                        return True
                    else:
                        # æ—¥å¿—ä¸åŒ¹é…,é€’å‡next_index
                        self.next_index[peer] = max(1, next_idx - 1)
        
        except Exception as e:
            logger.warning(f"AppendEntries to {peer} failed: {e}")
        
        return False
    
    def _commit_log(self):
        """æäº¤æ—¥å¿—"""
        with self.lock:
            # æ‰¾åˆ°å¤šæ•°èŠ‚ç‚¹å·²å¤åˆ¶çš„æœ€å¤§ç´¢å¼•
            match_indices = sorted(self.match_index.values(), reverse=True)
            majority_index = match_indices[len(self.peers) // 2]
            
            # æ›´æ–°commit_index
            if majority_index > self.commit_index:
                self.commit_index = majority_index
                
                # åº”ç”¨å·²æäº¤çš„æ—¥å¿—
                self._apply_log()
    
    def _apply_log(self):
        """åº”ç”¨æ—¥å¿—åˆ°çŠ¶æ€æœº"""
        while self.last_applied < self.commit_index:
            self.last_applied += 1
            entry = self.log[self.last_applied - 1]
            
            # åº”ç”¨å‘½ä»¤
            self._apply_command(entry['command'])
    
    def _apply_command(self, command: Dict):
        """åº”ç”¨å‘½ä»¤"""
        # å®ç°å…·ä½“çš„å‘½ä»¤åº”ç”¨é€»è¾‘
        logger.info(f"Applying command: {command}")
```

### 4.2 Paxosç®—æ³•åº”ç”¨

**Multi-Paxoså®ç°**:

```python
class MultiPaxos:
    """Multi-Paxosç®—æ³•"""
    
    class Phase(Enum):
        PREPARE = "prepare"
        ACCEPT = "accept"
        LEARN = "learn"
    
    def __init__(self, node_id: str, acceptors: List[str]):
        self.node_id = node_id
        self.acceptors = acceptors
        self.proposal_number = 0
        self.accepted_value = None
        self.promised_number = 0
        self.lock = threading.Lock()
    
    async def propose(self, value: Any) -> bool:
        """æè®®å€¼"""
        # Phase 1: Prepare
        proposal_number = self._next_proposal_number()
        
        if not await self._prepare_phase(proposal_number):
            return False
        
        # Phase 2: Accept
        return await self._accept_phase(proposal_number, value)
    
    async def _prepare_phase(self, proposal_number: int) -> bool:
        """Prepareé˜¶æ®µ"""
        promises = []
        
        # å‘æ‰€æœ‰acceptorså‘é€prepareè¯·æ±‚
        tasks = [
            self._send_prepare(acceptor, proposal_number)
            for acceptor in self.acceptors
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†promise
        for result in results:
            if not isinstance(result, Exception) and result:
                promises.append(result)
        
        # è·å¾—å¤šæ•°promise
        if len(promises) > len(self.acceptors) // 2:
            # æ£€æŸ¥æ˜¯å¦æœ‰å·²æ¥å—çš„å€¼
            for promise in promises:
                if promise.get('accepted_value'):
                    self.accepted_value = promise['accepted_value']
            
            return True
        
        return False
    
    async def _accept_phase(self, proposal_number: int, value: Any) -> bool:
        """Accepté˜¶æ®µ"""
        # å¦‚æœæœ‰å·²æ¥å—çš„å€¼,ä½¿ç”¨å®ƒ
        if self.accepted_value:
            value = self.accepted_value
        
        accepts = 0
        
        # å‘æ‰€æœ‰acceptorså‘é€acceptè¯·æ±‚
        tasks = [
            self._send_accept(acceptor, proposal_number, value)
            for acceptor in self.acceptors
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†accept
        for result in results:
            if not isinstance(result, Exception) and result:
                accepts += 1
        
        # è·å¾—å¤šæ•°accept
        return accepts > len(self.acceptors) // 2
    
    def _next_proposal_number(self) -> int:
        """ç”Ÿæˆä¸‹ä¸€ä¸ªæè®®å·"""
        with self.lock:
            self.proposal_number += 1
            # ä½¿ç”¨ (round_number, node_id) ä¿è¯å”¯ä¸€æ€§
            return self.proposal_number * 1000 + int(self.node_id)
    
    async def _send_prepare(self, acceptor: str, proposal_number: int) -> Optional[Dict]:
        """å‘é€prepareè¯·æ±‚"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{acceptor}/prepare",
                    json={'proposal_number': proposal_number},
                    timeout=aiohttp.ClientTimeout(total=1)
                ) as response:
                    if response.status == 200:
                        return await response.json()
        except Exception as e:
            logger.warning(f"Prepare to {acceptor} failed: {e}")
        
        return None
    
    async def _send_accept(self, acceptor: str, proposal_number: int, value: Any) -> bool:
        """å‘é€acceptè¯·æ±‚"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{acceptor}/accept",
                    json={
                        'proposal_number': proposal_number,
                        'value': value
                    },
                    timeout=aiohttp.ClientTimeout(total=1)
                ) as response:
                    return response.status == 200
        except Exception as e:
            logger.warning(f"Accept to {acceptor} failed: {e}")
        
        return False
    
    def handle_prepare(self, proposal_number: int) -> Dict:
        """å¤„ç†prepareè¯·æ±‚"""
        with self.lock:
            if proposal_number > self.promised_number:
                self.promised_number = proposal_number
                
                return {
                    'promise': True,
                    'accepted_value': self.accepted_value
                }
            else:
                return {'promise': False}
    
    def handle_accept(self, proposal_number: int, value: Any) -> bool:
        """å¤„ç†acceptè¯·æ±‚"""
        with self.lock:
            if proposal_number >= self.promised_number:
                self.promised_number = proposal_number
                self.accepted_value = value
                return True
            else:
                return False
```

### 4.3 ZABåè®®åˆ†æ

**ZooKeeper Atomic Broadcast (ZAB)**:

```python
class ZABProtocol:
    """ZABåè®®"""
    
    class Phase(Enum):
        DISCOVERY = "discovery"
        SYNCHRONIZATION = "synchronization"
        BROADCAST = "broadcast"
    
    def __init__(self, node_id: str, peers: List[str]):
        self.node_id = node_id
        self.peers = peers
        self.phase = self.Phase.DISCOVERY
        self.epoch = 0
        self.zxid = 0  # ZooKeeper Transaction ID
        self.history = []
        self.lock = threading.Lock()
    
    async def start(self):
        """å¯åŠ¨ZABåè®®"""
        # Phase 1: Discovery
        await self._discovery_phase()
        
        # Phase 2: Synchronization
        await self._synchronization_phase()
        
        # Phase 3: Broadcast
        await self._broadcast_phase()
    
    async def _discovery_phase(self):
        """å‘ç°é˜¶æ®µ"""
        self.phase = self.Phase.DISCOVERY
        
        # é€‰ä¸¾leader
        leader_id = await self._elect_leader()
        
        if leader_id == self.node_id:
            # æˆä¸ºleader
            with self.lock:
                self.epoch += 1
        else:
            # æˆä¸ºfollower
            await self._follow_leader(leader_id)
    
    async def _synchronization_phase(self):
        """åŒæ­¥é˜¶æ®µ"""
        self.phase = self.Phase.SYNCHRONIZATION
        
        if self.is_leader():
            # leaderåŒæ­¥followers
            await self._sync_followers()
        else:
            # followeråŒæ­¥è‡ªå·±
            await self._sync_with_leader()
    
    async def _broadcast_phase(self):
        """å¹¿æ’­é˜¶æ®µ"""
        self.phase = self.Phase.BROADCAST
        
        if self.is_leader():
            # leaderå¤„ç†è¯·æ±‚
            await self._handle_requests()
        else:
            # followerè½¬å‘è¯·æ±‚åˆ°leader
            await self._forward_requests()
    
    async def broadcast_transaction(self, transaction: Dict) -> bool:
        """å¹¿æ’­äº‹åŠ¡"""
        with self.lock:
            # ç”ŸæˆZXID
            self.zxid += 1
            zxid = (self.epoch << 32) | self.zxid
            
            # æ·»åŠ åˆ°å†å²
            self.history.append({
                'zxid': zxid,
                'transaction': transaction
            })
        
        # å‘é€PROPOSALåˆ°æ‰€æœ‰followers
        acks = await self._send_proposal(zxid, transaction)
        
        # è·å¾—å¤šæ•°ACK
        if acks > len(self.peers) // 2:
            # å‘é€COMMIT
            await self._send_commit(zxid)
            return True
        
        return False
    
    async def _send_proposal(self, zxid: int, transaction: Dict) -> int:
        """å‘é€PROPOSAL"""
        acks = 1  # leaderè‡ªå·±
        
        tasks = [
            self._send_proposal_to_follower(peer, zxid, transaction)
            for peer in self.peers
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if not isinstance(result, Exception) and result:
                acks += 1
        
        return acks
    
    async def _send_proposal_to_follower(self, peer: str, zxid: int, transaction: Dict) -> bool:
        """å‘é€PROPOSALåˆ°follower"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{peer}/proposal",
                    json={
                        'zxid': zxid,
                        'transaction': transaction
                    },
                    timeout=aiohttp.ClientTimeout(total=1)
                ) as response:
                    return response.status == 200
        except Exception as e:
            logger.warning(f"Proposal to {peer} failed: {e}")
        
        return False
    
    async def _send_commit(self, zxid: int):
        """å‘é€COMMIT"""
        tasks = [
            self._send_commit_to_follower(peer, zxid)
            for peer in self.peers
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _send_commit_to_follower(self, peer: str, zxid: int):
        """å‘é€COMMITåˆ°follower"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{peer}/commit",
                    json={'zxid': zxid},
                    timeout=aiohttp.ClientTimeout(total=1)
                ) as response:
                    return response.status == 200
        except Exception as e:
            logger.warning(f"Commit to {peer} failed: {e}")
        
        return False
```

## 5. æœ€ç»ˆä¸€è‡´æ€§å®ç°

### 5.1 å¼‚æ­¥å¤åˆ¶æ¨¡å‹

**å¼‚æ­¥å¤åˆ¶å®ç°**:

```python
class AsyncReplication:
    """å¼‚æ­¥å¤åˆ¶"""
    
    def __init__(self, replicas: List[str]):
        self.replicas = replicas
        self.replication_queue = asyncio.Queue()
        self.replication_workers = []
    
    async def start(self, num_workers: int = 4):
        """å¯åŠ¨å¤åˆ¶workers"""
        for _ in range(num_workers):
            worker = asyncio.create_task(self._replication_worker())
            self.replication_workers.append(worker)
    
    async def replicate(self, data: Dict):
        """å¼‚æ­¥å¤åˆ¶æ•°æ®"""
        await self.replication_queue.put(data)
    
    async def _replication_worker(self):
        """å¤åˆ¶worker"""
        while True:
            try:
                data = await self.replication_queue.get()
                
                # å¹¶å‘å¤åˆ¶åˆ°æ‰€æœ‰å‰¯æœ¬
                tasks = [
                    self._replicate_to_replica(replica, data)
                    for replica in self.replicas
                ]
                
                await asyncio.gather(*tasks, return_exceptions=True)
                
                self.replication_queue.task_done()
            
            except Exception as e:
                logger.error(f"Replication worker error: {e}")
    
    async def _replicate_to_replica(self, replica: str, data: Dict):
        """å¤åˆ¶åˆ°å•ä¸ªå‰¯æœ¬"""
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        f"http://{replica}/replicate",
                        json=data,
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as response:
                        if response.status == 200:
                            return
            
            except Exception as e:
                logger.warning(f"Replication to {replica} failed (attempt {attempt+1}): {e}")
                
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (2 ** attempt))
        
        logger.error(f"Failed to replicate to {replica} after {max_retries} attempts")
```

### 5.2 å†²çªæ£€æµ‹ä¸è§£å†³

**å†²çªæ£€æµ‹**:

```python
class ConflictDetector:
    """å†²çªæ£€æµ‹å™¨"""
    
    @staticmethod
    def detect_conflict(v1: Version, v2: Version) -> bool:
        """æ£€æµ‹å†²çª"""
        # ä½¿ç”¨å‘é‡æ—¶é’Ÿæ£€æµ‹å†²çª
        return not (v1 <= v2 or v2 <= v1)
    
    @staticmethod
    def resolve_conflict(v1: Version, v2: Version, strategy: str = 'last_write_wins') -> Version:
        """è§£å†³å†²çª"""
        if strategy == 'last_write_wins':
            return ConflictDetector._last_write_wins(v1, v2)
        elif strategy == 'merge':
            return ConflictDetector._merge(v1, v2)
        elif strategy == 'custom':
            return ConflictDetector._custom_resolution(v1, v2)
        else:
            raise ValueError(f"Unknown conflict resolution strategy: {strategy}")
    
    @staticmethod
    def _last_write_wins(v1: Version, v2: Version) -> Version:
        """æœ€åå†™å…¥è·èƒœ"""
        if v1.timestamp > v2.timestamp:
            return v1
        else:
            return v2
    
    @staticmethod
    def _merge(v1: Version, v2: Version) -> Version:
        """åˆå¹¶ç‰ˆæœ¬"""
        # åˆå¹¶æ•°æ®
        merged_data = {}
        
        # æ·»åŠ v1çš„æ•°æ®
        for key, value in v1.data.items():
            merged_data[key] = value
        
        # æ·»åŠ v2çš„æ•°æ® (å¯èƒ½è¦†ç›–v1)
        for key, value in v2.data.items():
            if key not in merged_data:
                merged_data[key] = value
            else:
                # å­—æ®µçº§å†²çªè§£å†³
                merged_data[key] = ConflictDetector._resolve_field_conflict(
                    merged_data[key],
                    value
                )
        
        # åˆ›å»ºæ–°ç‰ˆæœ¬
        return Version(
            data=merged_data,
            vector_clock=v1.vector_clock.merge(v2.vector_clock),
            timestamp=max(v1.timestamp, v2.timestamp)
        )
    
    @staticmethod
    def _resolve_field_conflict(value1, value2):
        """è§£å†³å­—æ®µçº§å†²çª"""
        # ç®€å•ç­–ç•¥:é€‰æ‹©è¾ƒæ–°çš„å€¼
        return value2

class Version:
    """ç‰ˆæœ¬"""
    def __init__(self, data: Dict, vector_clock: VectorClock, timestamp: int):
        self.data = data
        self.vector_clock = vector_clock
        self.timestamp = timestamp
    
    def __le__(self, other: 'Version') -> bool:
        """åˆ¤æ–­æ˜¯å¦ <="""
        return self.vector_clock <= other.vector_clock
```

### 5.3 ç‰ˆæœ¬å‘é‡

**å‘é‡æ—¶é’Ÿå®ç°**:

```python
class VectorClock:
    """å‘é‡æ—¶é’Ÿ"""
    
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.clock = defaultdict(int)
    
    def increment(self):
        """é€’å¢æœ¬åœ°æ—¶é’Ÿ"""
        self.clock[self.node_id] += 1
    
    def update(self, other: 'VectorClock'):
        """æ›´æ–°æ—¶é’Ÿ"""
        for node_id, timestamp in other.clock.items():
            self.clock[node_id] = max(self.clock[node_id], timestamp)
        
        # é€’å¢æœ¬åœ°æ—¶é’Ÿ
        self.increment()
    
    def merge(self, other: 'VectorClock') -> 'VectorClock':
        """åˆå¹¶æ—¶é’Ÿ"""
        merged = VectorClock(self.node_id)
        
        # å–æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§æ—¶é—´æˆ³
        all_nodes = set(self.clock.keys()) | set(other.clock.keys())
        for node_id in all_nodes:
            merged.clock[node_id] = max(
                self.clock.get(node_id, 0),
                other.clock.get(node_id, 0)
            )
        
        return merged
    
    def __le__(self, other: 'VectorClock') -> bool:
        """åˆ¤æ–­æ˜¯å¦ <="""
        for node_id, timestamp in self.clock.items():
            if timestamp > other.clock.get(node_id, 0):
                return False
        return True
    
    def __lt__(self, other: 'VectorClock') -> bool:
        """åˆ¤æ–­æ˜¯å¦ <"""
        return self <= other and self != other
    
    def __eq__(self, other: 'VectorClock') -> bool:
        """åˆ¤æ–­æ˜¯å¦ç›¸ç­‰"""
        return self.clock == other.clock
    
    def __str__(self) -> str:
        return str(dict(self.clock))

# ä½¿ç”¨ç¤ºä¾‹
class VersionedSpan:
    """å¸¦ç‰ˆæœ¬çš„Span"""
    
    def __init__(self, span: Span, node_id: str):
        self.span = span
        self.vector_clock = VectorClock(node_id)
        self.vector_clock.increment()
    
    def update(self, other: 'VersionedSpan'):
        """æ›´æ–°Span"""
        # æ£€æµ‹å†²çª
        if ConflictDetector.detect_conflict(
            Version(self.span.to_dict(), self.vector_clock, self.span.end_time),
            Version(other.span.to_dict(), other.vector_clock, other.span.end_time)
        ):
            logger.warning(f"Conflict detected for span {self.span.span_id}")
            
            # è§£å†³å†²çª
            resolved = ConflictDetector.resolve_conflict(
                Version(self.span.to_dict(), self.vector_clock, self.span.end_time),
                Version(other.span.to_dict(), other.vector_clock, other.span.end_time),
                strategy='merge'
            )
            
            self.span = Span.from_dict(resolved.data)
            self.vector_clock = resolved.vector_clock
        else:
            # æ— å†²çª,æ›´æ–°å‘é‡æ—¶é’Ÿ
            self.vector_clock.update(other.vector_clock)
```

### 5.4 Gossipåè®®

**Gossipåè®®å®ç°**:

```python
class GossipProtocol:
    """Gossipåè®®"""
    
    def __init__(self, node_id: str, peers: List[str], gossip_interval: float = 1.0):
        self.node_id = node_id
        self.peers = peers
        self.gossip_interval = gossip_interval
        self.data_store = {}
        self.vector_clock = VectorClock(node_id)
        self.running = False
    
    def start(self):
        """å¯åŠ¨Gossipåè®®"""
        self.running = True
        threading.Thread(target=self._gossip_loop, daemon=True).start()
    
    def stop(self):
        """åœæ­¢Gossipåè®®"""
        self.running = False
    
    def put(self, key: str, value: Any):
        """å­˜å‚¨æ•°æ®"""
        self.vector_clock.increment()
        
        self.data_store[key] = {
            'value': value,
            'vector_clock': copy.deepcopy(self.vector_clock),
            'timestamp': time.time()
        }
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–æ•°æ®"""
        if key in self.data_store:
            return self.data_store[key]['value']
        return None
    
    def _gossip_loop(self):
        """Gossipå¾ªç¯"""
        while self.running:
            try:
                # éšæœºé€‰æ‹©ä¸€ä¸ªpeer
                peer = random.choice(self.peers)
                
                # å‘é€gossipæ¶ˆæ¯
                self._send_gossip(peer)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡gossip
                time.sleep(self.gossip_interval)
            
            except Exception as e:
                logger.error(f"Gossip loop error: {e}")
    
    def _send_gossip(self, peer: str):
        """å‘é€gossipæ¶ˆæ¯"""
        try:
            # å‡†å¤‡è¦å‘é€çš„æ•°æ®
            gossip_data = {
                'node_id': self.node_id,
                'data': self.data_store,
                'vector_clock': self.vector_clock.clock
            }
            
            response = requests.post(
                f"http://{peer}/gossip",
                json=gossip_data,
                timeout=1
            )
            
            if response.status_code == 200:
                # å¤„ç†å“åº”
                self._handle_gossip_response(response.json())
        
        except Exception as e:
            logger.warning(f"Gossip to {peer} failed: {e}")
    
    def handle_gossip(self, gossip_data: Dict) -> Dict:
        """å¤„ç†gossipæ¶ˆæ¯"""
        remote_node_id = gossip_data['node_id']
        remote_data = gossip_data['data']
        remote_clock = VectorClock(remote_node_id)
        remote_clock.clock = gossip_data['vector_clock']
        
        # æ›´æ–°å‘é‡æ—¶é’Ÿ
        self.vector_clock.update(remote_clock)
        
        # åˆå¹¶æ•°æ®
        for key, remote_value in remote_data.items():
            if key not in self.data_store:
                # æ–°æ•°æ®,ç›´æ¥æ·»åŠ 
                self.data_store[key] = remote_value
            else:
                # å·²æœ‰æ•°æ®,æ¯”è¾ƒå‘é‡æ—¶é’Ÿ
                local_value = self.data_store[key]
                local_vc = VectorClock(self.node_id)
                local_vc.clock = local_value['vector_clock'].clock
                
                remote_vc = VectorClock(remote_node_id)
                remote_vc.clock = remote_value['vector_clock'].clock
                
                if remote_vc > local_vc:
                    # è¿œç¨‹æ•°æ®æ›´æ–°,æ›´æ–°æœ¬åœ°
                    self.data_store[key] = remote_value
                elif ConflictDetector.detect_conflict(
                    Version(local_value, local_vc, local_value['timestamp']),
                    Version(remote_value, remote_vc, remote_value['timestamp'])
                ):
                    # å†²çª,è§£å†³å†²çª
                    resolved = ConflictDetector.resolve_conflict(
                        Version(local_value, local_vc, local_value['timestamp']),
                        Version(remote_value, remote_vc, remote_value['timestamp'])
                    )
                    self.data_store[key] = {
                        'value': resolved.data,
                        'vector_clock': resolved.vector_clock,
                        'timestamp': resolved.timestamp
                    }
        
        # è¿”å›æœ¬åœ°æ•°æ®
        return {
            'node_id': self.node_id,
            'data': self.data_store,
            'vector_clock': self.vector_clock.clock
        }
    
    def _handle_gossip_response(self, response_data: Dict):
        """å¤„ç†gossipå“åº”"""
        # ä¸handle_gossipç±»ä¼¼çš„é€»è¾‘
        self.handle_gossip(response_data)
```

## 6. å› æœä¸€è‡´æ€§ä¿è¯

### 6.1 å› æœå…³ç³»å»ºæ¨¡

**å› æœå…³ç³»å›¾**:

```python
class CausalRelationshipGraph:
    """å› æœå…³ç³»å›¾"""
    
    def __init__(self):
        self.nodes = {}  # event_id -> Event
        self.edges = defaultdict(set)  # cause_id -> {effect_ids}
        self.vector_clocks = {}  # event_id -> VectorClock
        self.lock = threading.RLock()
    
    def add_event(self, event: Event, causes: List[str] = None):
        """æ·»åŠ äº‹ä»¶"""
        with self.lock:
            self.nodes[event.id] = event
            
            # åˆ›å»ºå‘é‡æ—¶é’Ÿ
            vc = VectorClock(event.node_id)
            
            if causes:
                # æ›´æ–°å‘é‡æ—¶é’Ÿ
                for cause_id in causes:
                    if cause_id in self.vector_clocks:
                        vc.update(self.vector_clocks[cause_id])
                    
                    # æ·»åŠ å› æœè¾¹
                    self.edges[cause_id].add(event.id)
            else:
                # æ ¹äº‹ä»¶
                vc.increment()
            
            self.vector_clocks[event.id] = vc
    
    def is_causally_related(self, event1_id: str, event2_id: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æœ‰å› æœå…³ç³»"""
        if event1_id not in self.vector_clocks or event2_id not in self.vector_clocks:
            return False
        
        vc1 = self.vector_clocks[event1_id]
        vc2 = self.vector_clocks[event2_id]
        
        return vc1 < vc2 or vc2 < vc1
    
    def is_concurrent(self, event1_id: str, event2_id: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¹¶å‘"""
        return not self.is_causally_related(event1_id, event2_id)
    
    def get_causal_history(self, event_id: str) -> Set[str]:
        """è·å–å› æœå†å²"""
        history = set()
        
        def dfs(eid: str):
            for cause_id in self.nodes.keys():
                if eid in self.edges[cause_id]:
                    history.add(cause_id)
                    dfs(cause_id)
        
        dfs(event_id)
        return history
```

### 6.2 å‘é‡æ—¶é’Ÿ

(å·²åœ¨5.3èŠ‚å®ç°)

### 6.3 å› æœå¹¿æ’­

**å› æœå¹¿æ’­å®ç°**:

```python
class CausalBroadcast:
    """å› æœå¹¿æ’­"""
    
    def __init__(self, node_id: str, peers: List[str]):
        self.node_id = node_id
        self.peers = peers
        self.vector_clock = VectorClock(node_id)
        self.delivered = set()  # å·²æŠ•é€’çš„æ¶ˆæ¯
        self.pending = []  # å¾…æŠ•é€’çš„æ¶ˆæ¯
        self.lock = threading.RLock()
    
    async def broadcast(self, message: Dict):
        """å¹¿æ’­æ¶ˆæ¯"""
        with self.lock:
            # é€’å¢å‘é‡æ—¶é’Ÿ
            self.vector_clock.increment()
            
            # é™„åŠ å‘é‡æ—¶é’Ÿ
            message['vector_clock'] = copy.deepcopy(self.vector_clock.clock)
            message['sender'] = self.node_id
        
        # å‘é€åˆ°æ‰€æœ‰peers
        tasks = [
            self._send_message(peer, message)
            for peer in self.peers
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _send_message(self, peer: str, message: Dict):
        """å‘é€æ¶ˆæ¯"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{peer}/causal_message",
                    json=message,
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    return response.status == 200
        except Exception as e:
            logger.warning(f"Send message to {peer} failed: {e}")
        
        return False
    
    def receive(self, message: Dict):
        """æ¥æ”¶æ¶ˆæ¯"""
        with self.lock:
            # æ·»åŠ åˆ°å¾…æŠ•é€’é˜Ÿåˆ—
            self.pending.append(message)
            
            # å°è¯•æŠ•é€’æ¶ˆæ¯
            self._try_deliver()
    
    def _try_deliver(self):
        """å°è¯•æŠ•é€’æ¶ˆæ¯"""
        delivered_any = True
        
        while delivered_any:
            delivered_any = False
            
            for message in self.pending[:]:
                if self._can_deliver(message):
                    # æŠ•é€’æ¶ˆæ¯
                    self._deliver(message)
                    self.pending.remove(message)
                    delivered_any = True
    
    def _can_deliver(self, message: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥æŠ•é€’"""
        sender = message['sender']
        msg_vc = VectorClock(sender)
        msg_vc.clock = message['vector_clock']
        
        # æ£€æŸ¥å› æœä¾èµ–
        for node_id, timestamp in msg_vc.clock.items():
            if node_id == sender:
                # å‘é€è€…çš„æ—¶é—´æˆ³åº”è¯¥æ˜¯æœ¬åœ°æ—¶é—´æˆ³+1
                if timestamp != self.vector_clock.clock.get(node_id, 0) + 1:
                    return False
            else:
                # å…¶ä»–èŠ‚ç‚¹çš„æ—¶é—´æˆ³åº”è¯¥ <= æœ¬åœ°æ—¶é—´æˆ³
                if timestamp > self.vector_clock.clock.get(node_id, 0):
                    return False
        
        return True
    
    def _deliver(self, message: Dict):
        """æŠ•é€’æ¶ˆæ¯"""
        # æ›´æ–°å‘é‡æ—¶é’Ÿ
        sender = message['sender']
        msg_vc = VectorClock(sender)
        msg_vc.clock = message['vector_clock']
        
        self.vector_clock.update(msg_vc)
        
        # æ ‡è®°ä¸ºå·²æŠ•é€’
        message_id = message.get('id')
        if message_id:
            self.delivered.add(message_id)
        
        # å¤„ç†æ¶ˆæ¯
        self._process_message(message)
    
    def _process_message(self, message: Dict):
        """å¤„ç†æ¶ˆæ¯"""
        logger.info(f"Delivered message: {message}")
```

## 7. å®è·µæ¡ˆä¾‹

### 7.1 åˆ†å¸ƒå¼Traceæ”¶é›†ä¸€è‡´æ€§

**å®Œæ•´ç¤ºä¾‹**:

```python
class DistributedTraceCollector:
    """åˆ†å¸ƒå¼Traceæ”¶é›†å™¨"""
    
    def __init__(self, node_id: str, peers: List[str]):
        self.node_id = node_id
        self.peers = peers
        
        # ä¸€è‡´æ€§åè®®
        self.trace_protocol = TraceConsistencyProtocol()
        
        # å› æœå¹¿æ’­
        self.causal_broadcast = CausalBroadcast(node_id, peers)
        
        # å‘é‡æ—¶é’Ÿ
        self.vector_clock = VectorClock(node_id)
        
        # åˆ†å¸ƒå¼é”
        self.lock_manager = DistributedLock(redis_client, "trace_collector")
    
    async def collect_span(self, span: Span):
        """æ”¶é›†Span"""
        # æ›´æ–°å‘é‡æ—¶é’Ÿ
        self.vector_clock.increment()
        
        # é™„åŠ å‘é‡æ—¶é’Ÿåˆ°Span
        span.metadata['vector_clock'] = copy.deepcopy(self.vector_clock.clock)
        span.metadata['collector_node'] = self.node_id
        
        # æœ¬åœ°å¤„ç†
        self.trace_protocol.process_span(span)
        
        # å¹¿æ’­åˆ°å…¶ä»–èŠ‚ç‚¹
        await self.causal_broadcast.broadcast({
            'type': 'span',
            'span': span.to_dict(),
            'trace_id': span.trace_id
        })
    
    async def finalize_trace(self, trace_id: str):
        """å®ŒæˆTrace"""
        # è·å–åˆ†å¸ƒå¼é”
        lock = DistributedLock(redis_client, f"trace:{trace_id}")
        
        if lock.acquire(timeout=10):
            try:
                # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„Spans
                all_spans = await self._collect_spans_from_all_nodes(trace_id)
                
                # éªŒè¯ä¸€è‡´æ€§
                if self._verify_trace_consistency(all_spans):
                    # æŒä¹…åŒ–
                    await self._persist_trace(trace_id, all_spans)
                else:
                    logger.error(f"Trace {trace_id} consistency check failed")
            
            finally:
                lock.release()
        else:
            logger.warning(f"Failed to acquire lock for trace {trace_id}")
    
    async def _collect_spans_from_all_nodes(self, trace_id: str) -> List[Span]:
        """ä»æ‰€æœ‰èŠ‚ç‚¹æ”¶é›†Spans"""
        all_spans = []
        
        # æœ¬åœ°Spans
        trace_sm = self.trace_protocol.traces.get(trace_id)
        if trace_sm:
            all_spans.extend(trace_sm.spans.values())
        
        # è¿œç¨‹Spans
        tasks = [
            self._fetch_spans_from_node(peer, trace_id)
            for peer in self.peers
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if not isinstance(result, Exception):
                all_spans.extend(result)
        
        return all_spans
    
    async def _fetch_spans_from_node(self, peer: str, trace_id: str) -> List[Span]:
        """ä»èŠ‚ç‚¹è·å–Spans"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"http://{peer}/spans/{trace_id}",
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        return [Span.from_dict(s) for s in data['spans']]
        except Exception as e:
            logger.warning(f"Fetch spans from {peer} failed: {e}")
        
        return []
    
    def _verify_trace_consistency(self, spans: List[Span]) -> bool:
        """éªŒè¯Traceä¸€è‡´æ€§"""
        # ä½¿ç”¨å‘é‡æ—¶é’ŸéªŒè¯å› æœä¸€è‡´æ€§
        for i, span1 in enumerate(spans):
            for span2 in spans[i+1:]:
                # æ£€æŸ¥çˆ¶å­å…³ç³»
                if span1.span_id == span2.parent_span_id:
                    # çˆ¶Spançš„å‘é‡æ—¶é’Ÿåº”è¯¥ < å­Spançš„å‘é‡æ—¶é’Ÿ
                    vc1 = VectorClock(span1.metadata['collector_node'])
                    vc1.clock = span1.metadata['vector_clock']
                    
                    vc2 = VectorClock(span2.metadata['collector_node'])
                    vc2.clock = span2.metadata['vector_clock']
                    
                    if not (vc1 < vc2):
                        logger.error(f"Causal consistency violation: {span1.span_id} -> {span2.span_id}")
                        return False
        
        return True
```

### 7.2 è·¨åŒºåŸŸæ•°æ®åŒæ­¥

**è·¨åŒºåŸŸåŒæ­¥å®ç°**:

```python
class CrossRegionSync:
    """è·¨åŒºåŸŸæ•°æ®åŒæ­¥"""
    
    def __init__(self, region_id: str, regions: List[str]):
        self.region_id = region_id
        self.regions = regions
        
        # å¼‚æ­¥å¤åˆ¶
        self.replication = AsyncReplication(regions)
        
        # Gossipåè®®
        self.gossip = GossipProtocol(region_id, regions, gossip_interval=5.0)
        
        # å†²çªæ£€æµ‹å™¨
        self.conflict_detector = ConflictDetector()
    
    async def start(self):
        """å¯åŠ¨åŒæ­¥"""
        await self.replication.start()
        self.gossip.start()
    
    async def sync_trace(self, trace: Trace):
        """åŒæ­¥Trace"""
        # æ·»åŠ ç‰ˆæœ¬ä¿¡æ¯
        versioned_trace = {
            'trace': trace.to_dict(),
            'region_id': self.region_id,
            'vector_clock': self.gossip.vector_clock.clock,
            'timestamp': time.time()
        }
        
        # å¼‚æ­¥å¤åˆ¶åˆ°æ‰€æœ‰åŒºåŸŸ
        await self.replication.replicate(versioned_trace)
        
        # Gossipä¼ æ’­
        self.gossip.put(f"trace:{trace.trace_id}", versioned_trace)
    
    def handle_remote_trace(self, remote_trace: Dict):
        """å¤„ç†è¿œç¨‹Trace"""
        trace_id = remote_trace['trace']['trace_id']
        
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰
        local_trace = self.gossip.get(f"trace:{trace_id}")
        
        if local_trace is None:
            # æ–°Trace,ç›´æ¥å­˜å‚¨
            self.gossip.put(f"trace:{trace_id}", remote_trace)
        else:
            # å·²æœ‰Trace,æ£€æµ‹å†²çª
            local_vc = VectorClock(local_trace['region_id'])
            local_vc.clock = local_trace['vector_clock']
            
            remote_vc = VectorClock(remote_trace['region_id'])
            remote_vc.clock = remote_trace['vector_clock']
            
            if self.conflict_detector.detect_conflict(
                Version(local_trace, local_vc, local_trace['timestamp']),
                Version(remote_trace, remote_vc, remote_trace['timestamp'])
            ):
                # å†²çª,è§£å†³å†²çª
                resolved = self.conflict_detector.resolve_conflict(
                    Version(local_trace, local_vc, local_trace['timestamp']),
                    Version(remote_trace, remote_vc, remote_trace['timestamp']),
                    strategy='merge'
                )
                
                self.gossip.put(f"trace:{trace_id}", resolved.data)
            else:
                # æ— å†²çª,æ›´æ–°
                if remote_vc > local_vc:
                    self.gossip.put(f"trace:{trace_id}", remote_trace)
```

### 7.3 å¤šCollectoråè°ƒ

**Collectoråè°ƒå®ç°**:

```python
class CollectorCoordination:
    """Collectoråè°ƒ"""
    
    def __init__(self, collector_id: str, collectors: List[str]):
        self.collector_id = collector_id
        self.collectors = collectors
        
        # Leaderé€‰ä¸¾
        self.leader_election = RaftLeaderElection(collector_id, collectors)
        
        # åˆ†å¸ƒå¼å±éšœ
        self.barrier_manager = {}
        
        # åˆ†å¸ƒå¼äº‹åŠ¡
        self.transaction_coordinator = None
    
    def start(self):
        """å¯åŠ¨åè°ƒ"""
        self.leader_election.start()
    
    def is_leader(self) -> bool:
        """æ˜¯å¦æ˜¯Leader"""
        return self.leader_election.state == RaftLeaderElection.State.LEADER
    
    async def coordinate_batch_processing(self, batch_id: str, num_collectors: int):
        """åè°ƒæ‰¹å¤„ç†"""
        if not self.is_leader():
            # è½¬å‘åˆ°Leader
            await self._forward_to_leader('coordinate_batch', {'batch_id': batch_id})
            return
        
        # åˆ›å»ºå±éšœ
        barrier = DistributedBarrier(redis_client, f"batch:{batch_id}", num_collectors)
        self.barrier_manager[batch_id] = barrier
        
        # é€šçŸ¥æ‰€æœ‰collectorså¼€å§‹å¤„ç†
        await self._notify_collectors('start_batch', {'batch_id': batch_id})
        
        # ç­‰å¾…æ‰€æœ‰collectorså®Œæˆ
        try:
            await barrier.await(timeout=300)
            logger.info(f"Batch {batch_id} completed")
        except TimeoutError:
            logger.error(f"Batch {batch_id} timeout")
    
    async def coordinate_trace_finalization(self, trace_id: str):
        """åè°ƒTraceå®Œæˆ"""
        if not self.is_leader():
            await self._forward_to_leader('finalize_trace', {'trace_id': trace_id})
            return
        
        # ä½¿ç”¨2PCç¡®ä¿æ‰€æœ‰collectorséƒ½å®Œæˆ
        coordinator = TwoPhaseCommitCoordinator(self.collectors)
        
        # å‡†å¤‡æ“ä½œ
        operations = {
            collector: {'type': 'finalize_trace', 'trace_id': trace_id}
            for collector in self.collectors
        }
        
        # æ‰§è¡Œ2PC
        success = await coordinator.execute(operations)
        
        if success:
            logger.info(f"Trace {trace_id} finalized successfully")
        else:
            logger.error(f"Trace {trace_id} finalization failed")
    
    async def _forward_to_leader(self, operation: str, params: Dict):
        """è½¬å‘åˆ°Leader"""
        # è·å–Leader ID
        leader_id = self._get_leader_id()
        
        if leader_id:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.post(
                        f"http://{leader_id}/{operation}",
                        json=params,
                        timeout=aiohttp.ClientTimeout(total=10)
                    ) as response:
                        return await response.json()
            except Exception as e:
                logger.error(f"Forward to leader failed: {e}")
    
    def _get_leader_id(self) -> Optional[str]:
        """è·å–Leader ID"""
        # å®ç°Leaderå‘ç°é€»è¾‘
        pass
    
    async def _notify_collectors(self, operation: str, params: Dict):
        """é€šçŸ¥æ‰€æœ‰collectors"""
        tasks = [
            self._notify_collector(collector, operation, params)
            for collector in self.collectors
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _notify_collector(self, collector: str, operation: str, params: Dict):
        """é€šçŸ¥å•ä¸ªcollector"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://{collector}/{operation}",
                    json=params,
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    return response.status == 200
        except Exception as e:
            logger.warning(f"Notify collector {collector} failed: {e}")
        
        return False
```

## 8. æ€»ç»“ä¸å±•æœ›

### æ ¸å¿ƒæˆæœ

1. **ç†è®ºå»ºç«‹**:
   - å»ºç«‹äº†å®Œæ•´çš„OTLPåˆ†å¸ƒå¼ä¸€è‡´æ€§ç†è®ºæ¨¡å‹
   - å®šä¹‰äº†Traceä¸€è‡´æ€§ã€Spanå…³ç³»ä¸€è‡´æ€§ç­‰å½¢å¼åŒ–è§„èŒƒ
   - æä¾›äº†CAPå®šç†åœ¨OTLPä¸­çš„åº”ç”¨åˆ†æ

2. **æœºåˆ¶å®ç°**:
   - å®ç°äº†åˆ†å¸ƒå¼é”ã€åˆ†å¸ƒå¼äº‹åŠ¡ã€åˆ†å¸ƒå¼å±éšœç­‰åè°ƒæœºåˆ¶
   - é›†æˆäº†Raftã€Paxosã€ZABç­‰å…±è¯†ç®—æ³•
   - å®ç°äº†å¼‚æ­¥å¤åˆ¶ã€å†²çªæ£€æµ‹ã€å‘é‡æ—¶é’Ÿç­‰ä¸€è‡´æ€§æœºåˆ¶

3. **åè®®è®¾è®¡**:
   - è®¾è®¡äº†Traceä¸€è‡´æ€§åè®®
   - å®ç°äº†ä¸Šä¸‹æ–‡ä¼ æ’­ä¸€è‡´æ€§ä¿è¯
   - å»ºç«‹äº†å› æœå¹¿æ’­æœºåˆ¶

4. **å®è·µåº”ç”¨**:
   - å®ç°äº†åˆ†å¸ƒå¼Traceæ”¶é›†ä¸€è‡´æ€§ä¿è¯
   - æ„å»ºäº†è·¨åŒºåŸŸæ•°æ®åŒæ­¥ç³»ç»Ÿ
   - åˆ›å»ºäº†å¤šCollectoråè°ƒæœºåˆ¶

### åˆ›æ–°è´¡çŒ®

1. **ç†è®ºåˆ›æ–°**:
   - é¦–æ¬¡å»ºç«‹OTLPçš„åˆ†å¸ƒå¼ä¸€è‡´æ€§ç†è®ºæ¨¡å‹
   - æå‡ºäº†å› æœä¸€è‡´æ€§+æœ€ç»ˆä¸€è‡´æ€§çš„æ··åˆæ¨¡å‹
   - åˆ›å»ºäº†å®Œæ•´çš„ä¸€è‡´æ€§éªŒè¯æ¡†æ¶

2. **æŠ€æœ¯åˆ›æ–°**:
   - å®ç°äº†åŸºäºå‘é‡æ—¶é’Ÿçš„å› æœä¸€è‡´æ€§ä¿è¯
   - åˆ›å»ºäº†é«˜æ•ˆçš„å†²çªæ£€æµ‹ä¸è§£å†³æœºåˆ¶
   - æä¾›äº†å¤šç§å…±è¯†ç®—æ³•çš„é›†æˆæ–¹æ¡ˆ

3. **åº”ç”¨åˆ›æ–°**:
   - å®ç°äº†åˆ†å¸ƒå¼Traceæ”¶é›†çš„ä¸€è‡´æ€§ä¿è¯
   - æ„å»ºäº†è·¨åŒºåŸŸæ•°æ®åŒæ­¥ç³»ç»Ÿ
   - åˆ›å»ºäº†Collectoråè°ƒæœºåˆ¶

### æœªæ¥å±•æœ›

1. **æ€§èƒ½ä¼˜åŒ–**:
   - ä¼˜åŒ–å…±è¯†ç®—æ³•æ€§èƒ½
   - å‡å°‘ä¸€è‡´æ€§åè®®å¼€é”€
   - æå‡è·¨åŒºåŸŸåŒæ­¥æ•ˆç‡

2. **ç†è®ºæ·±åŒ–**:
   - æ·±åŒ–ä¸€è‡´æ€§ç†è®ºç ”ç©¶
   - æ‰©å±•å½¢å¼åŒ–éªŒè¯æ–¹æ³•
   - ç ”ç©¶æ–°çš„ä¸€è‡´æ€§æ¨¡å‹

3. **åº”ç”¨æ‹“å±•**:
   - æ‰©å±•åˆ°æ›´å¤šåˆ†å¸ƒå¼åœºæ™¯
   - æ”¯æŒæ›´å¤§è§„æ¨¡çš„ç³»ç»Ÿ
   - æå‡å®¹é”™èƒ½åŠ›

---

**æ–‡æ¡£å®Œæˆæ—¶é—´**: 2025å¹´10æœˆ7æ—¥  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**ç»´æŠ¤å›¢é˜Ÿ**: OTLP ç³»ç»Ÿåˆ†æå›¢é˜Ÿ
