# 自适应资源管理

**文档版本**: 1.0.0  
**创建日期**: 2025年10月7日  
**所属**: 第五部分 - 控制与动态调整  

---

## 目录

- [自适应资源管理](#自适应资源管理)
  - [目录](#目录)
  - [概述](#概述)
  - [5.2.1 资源监控与预测](#521-资源监控与预测)
    - [资源指标采集](#资源指标采集)
    - [负载预测](#负载预测)
  - [5.2.2 水平扩缩容（HPA）](#522-水平扩缩容hpa)
    - [基于指标的HPA](#基于指标的hpa)
    - [预测性HPA](#预测性hpa)
  - [5.2.3 垂直扩缩容（VPA）](#523-垂直扩缩容vpa)
    - [资源推荐](#资源推荐)
    - [动态调整](#动态调整)
  - [5.2.4 资源配额与限流](#524-资源配额与限流)
    - [动态配额](#动态配额)
    - [公平调度](#公平调度)
  - [总结](#总结)

---

## 概述

本文档介绍OTLP的自适应资源管理机制，包括资源监控、预测、自动扩缩容和配额管理。

---

## 5.2.1 资源监控与预测

### 资源指标采集

**全面的资源监控**：

```go
// 资源监控器
type ResourceMonitor struct {
    collectors []MetricCollector
    storage    *MetricsStorage
    interval   time.Duration
}

type MetricCollector interface {
    Collect() ResourceMetrics
}

type ResourceMetrics struct {
    Timestamp time.Time
    
    // CPU指标
    CPUUsage      float64  // 0-1
    CPUThrottled  float64  // 被限流的时间比例
    
    // 内存指标
    MemoryUsage   float64  // 0-1
    MemoryRSS     uint64   // 常驻内存
    MemoryCache   uint64   // 缓存
    
    // 网络指标
    NetworkIn     uint64   // 字节/秒
    NetworkOut    uint64
    
    // I/O指标
    DiskRead      uint64
    DiskWrite     uint64
    IOWait        float64
    
    // 应用指标
    RequestRate   float64  // 请求/秒
    ErrorRate     float64
    P99Latency    time.Duration
    QueueLength   int
}

// CPU采集器
type CPUCollector struct{}

func (cc *CPUCollector) Collect() ResourceMetrics {
    metrics := ResourceMetrics{
        Timestamp: time.Now(),
    }
    
    // 读取/proc/stat
    cpuStats := cc.readCPUStats()
    metrics.CPUUsage = cpuStats.Usage
    metrics.CPUThrottled = cpuStats.Throttled
    
    return metrics
}

// 内存采集器
type MemoryCollector struct{}

func (mc *MemoryCollector) Collect() ResourceMetrics {
    metrics := ResourceMetrics{
        Timestamp: time.Now(),
    }
    
    // 读取/proc/meminfo
    memStats := mc.readMemStats()
    metrics.MemoryUsage = float64(memStats.Used) / float64(memStats.Total)
    metrics.MemoryRSS = memStats.RSS
    metrics.MemoryCache = memStats.Cache
    
    return metrics
}

// 聚合监控器
func (rm *ResourceMonitor) Start() {
    ticker := time.NewTicker(rm.interval)
    defer ticker.Stop()
    
    for range ticker.C {
        aggregated := ResourceMetrics{
            Timestamp: time.Now(),
        }
        
        // 收集所有指标
        for _, collector := range rm.collectors {
            metrics := collector.Collect()
            rm.merge(&aggregated, metrics)
        }
        
        // 存储
        rm.storage.Store(aggregated)
    }
}
```

### 负载预测

**时间序列预测**：

```go
// 负载预测器
type LoadPredictor struct {
    history      *TimeSeriesBuffer
    model        PredictionModel
    horizon      time.Duration  // 预测时间范围
}

type PredictionModel interface {
    Fit(data []float64) error
    Predict(steps int) []float64
}

// ARIMA模型
type ARIMAModel struct {
    p int  // AR阶数
    d int  // 差分阶数
    q int  // MA阶数
    
    arCoeffs []float64  // AR系数
    maCoeffs []float64  // MA系数
}

func (am *ARIMAModel) Fit(data []float64) error {
    // 1. 差分处理
    diffData := am.difference(data, am.d)
    
    // 2. 估计AR参数（Yule-Walker方程）
    am.arCoeffs = am.estimateAR(diffData, am.p)
    
    // 3. 估计MA参数
    residuals := am.calculateResiduals(diffData)
    am.maCoeffs = am.estimateMA(residuals, am.q)
    
    return nil
}

func (am *ARIMAModel) Predict(steps int) []float64 {
    predictions := make([]float64, steps)
    
    for i := 0; i < steps; i++ {
        // AR部分
        arTerm := 0.0
        for j := 0; j < am.p; j++ {
            if i-j-1 >= 0 {
                arTerm += am.arCoeffs[j] * predictions[i-j-1]
            }
        }
        
        // MA部分
        maTerm := 0.0
        // ... MA计算
        
        predictions[i] = arTerm + maTerm
    }
    
    return predictions
}

// 指数平滑（Holt-Winters）
type HoltWintersModel struct {
    alpha  float64  // 水平平滑系数
    beta   float64  // 趋势平滑系数
    gamma  float64  // 季节性平滑系数
    period int      // 季节周期
    
    level      float64
    trend      float64
    seasonal   []float64
}

func (hw *HoltWintersModel) Fit(data []float64) error {
    // 初始化
    hw.level = data[0]
    hw.trend = (data[hw.period] - data[0]) / float64(hw.period)
    hw.seasonal = make([]float64, hw.period)
    
    // 初始季节因子
    for i := 0; i < hw.period; i++ {
        hw.seasonal[i] = data[i] / hw.level
    }
    
    // 迭代更新
    for t := 0; t < len(data); t++ {
        prevLevel := hw.level
        prevTrend := hw.trend
        seasonIdx := t % hw.period
        
        // 更新水平
        hw.level = hw.alpha*(data[t]/hw.seasonal[seasonIdx]) + 
                   (1-hw.alpha)*(prevLevel+prevTrend)
        
        // 更新趋势
        hw.trend = hw.beta*(hw.level-prevLevel) + (1-hw.beta)*prevTrend
        
        // 更新季节性
        hw.seasonal[seasonIdx] = hw.gamma*(data[t]/hw.level) + 
                                 (1-hw.gamma)*hw.seasonal[seasonIdx]
    }
    
    return nil
}

func (hw *HoltWintersModel) Predict(steps int) []float64 {
    predictions := make([]float64, steps)
    
    for i := 0; i < steps; i++ {
        seasonIdx := i % hw.period
        predictions[i] = (hw.level + float64(i+1)*hw.trend) * hw.seasonal[seasonIdx]
    }
    
    return predictions
}

// 使用示例
func (lp *LoadPredictor) PredictLoad(metric string) ([]float64, error) {
    // 1. 获取历史数据
    history := lp.history.GetMetric(metric)
    
    // 2. 拟合模型
    err := lp.model.Fit(history)
    if err != nil {
        return nil, err
    }
    
    // 3. 预测未来
    steps := int(lp.horizon / lp.history.Resolution)
    predictions := lp.model.Predict(steps)
    
    return predictions, nil
}
```

---

## 5.2.2 水平扩缩容（HPA）

### 基于指标的HPA

**Kubernetes HPA实现**：

```go
// HPA控制器
type HPAController struct {
    client        *kubernetes.Clientset
    targetMetric  string
    targetValue   float64
    minReplicas   int32
    maxReplicas   int32
    scaleInterval time.Duration
}

func (hpa *HPAController) Reconcile(deployment *appsv1.Deployment) error {
    // 1. 获取当前副本数
    currentReplicas := *deployment.Spec.Replicas
    
    // 2. 获取当前指标值
    currentMetric, err := hpa.getCurrentMetric(deployment)
    if err != nil {
        return err
    }
    
    // 3. 计算期望副本数
    desiredReplicas := hpa.calculateDesiredReplicas(
        currentReplicas,
        currentMetric,
        hpa.targetValue,
    )
    
    // 4. 限制范围
    desiredReplicas = max(hpa.minReplicas, min(hpa.maxReplicas, desiredReplicas))
    
    // 5. 执行扩缩容
    if desiredReplicas != currentReplicas {
        return hpa.scale(deployment, desiredReplicas)
    }
    
    return nil
}

func (hpa *HPAController) calculateDesiredReplicas(
    current int32,
    currentMetric float64,
    targetMetric float64,
) int32 {
    // 基本公式: desiredReplicas = ceil(currentReplicas * (currentMetric / targetMetric))
    ratio := currentMetric / targetMetric
    desired := float64(current) * ratio
    
    // 向上取整
    return int32(math.Ceil(desired))
}

// 多指标HPA
type MultiMetricHPA struct {
    metrics []MetricSpec
}

type MetricSpec struct {
    Name   string
    Target float64
    Weight float64
}

func (mhpa *MultiMetricHPA) calculateDesiredReplicas(
    current int32,
    metrics map[string]float64,
) int32 {
    weightedSum := 0.0
    totalWeight := 0.0
    
    for _, spec := range mhpa.metrics {
        currentValue := metrics[spec.Name]
        ratio := currentValue / spec.Target
        weightedSum += ratio * spec.Weight
        totalWeight += spec.Weight
    }
    
    avgRatio := weightedSum / totalWeight
    desired := float64(current) * avgRatio
    
    return int32(math.Ceil(desired))
}
```

### 预测性HPA

**基于负载预测的扩缩容**：

```go
// 预测性HPA控制器
type PredictiveHPA struct {
    predictor     *LoadPredictor
    hpaController *HPAController
    leadTime      time.Duration  // 提前量
}

func (phpa *PredictiveHPA) Reconcile(deployment *appsv1.Deployment) error {
    // 1. 预测未来负载
    predictions, err := phpa.predictor.PredictLoad("request_rate")
    if err != nil {
        return err
    }
    
    // 2. 找到预测窗口内的峰值
    peakLoad := phpa.findPeak(predictions)
    
    // 3. 计算所需副本数
    desiredReplicas := phpa.calculateReplicasForLoad(peakLoad)
    
    // 4. 提前扩容
    currentReplicas := *deployment.Spec.Replicas
    if desiredReplicas > currentReplicas {
        log.Printf("Proactive scaling: %d -> %d (predicted peak: %.2f)",
            currentReplicas, desiredReplicas, peakLoad)
        return phpa.hpaController.scale(deployment, desiredReplicas)
    }
    
    return nil
}

func (phpa *PredictiveHPA) findPeak(predictions []float64) float64 {
    peak := 0.0
    for _, value := range predictions {
        if value > peak {
            peak = value
        }
    }
    return peak
}

// 智能扩缩容决策
type SmartScalingDecision struct {
    CurrentReplicas int32
    DesiredReplicas int32
    Confidence      float64
    Reason          string
}

func (phpa *PredictiveHPA) MakeDecision(
    deployment *appsv1.Deployment,
) SmartScalingDecision {
    decision := SmartScalingDecision{
        CurrentReplicas: *deployment.Spec.Replicas,
    }
    
    // 1. 获取当前指标
    currentLoad := phpa.getCurrentLoad()
    
    // 2. 预测未来负载
    predictions, _ := phpa.predictor.PredictLoad("request_rate")
    predictedLoad := predictions[len(predictions)-1]
    
    // 3. 计算置信度
    confidence := phpa.calculateConfidence(predictions)
    decision.Confidence = confidence
    
    // 4. 决策逻辑
    if predictedLoad > currentLoad*1.5 && confidence > 0.8 {
        // 高置信度预测负载增加，提前扩容
        decision.DesiredReplicas = phpa.calculateReplicasForLoad(predictedLoad)
        decision.Reason = "Predicted load increase with high confidence"
    } else if predictedLoad < currentLoad*0.5 && confidence > 0.8 {
        // 高置信度预测负载降低，可以缩容
        decision.DesiredReplicas = phpa.calculateReplicasForLoad(predictedLoad)
        decision.Reason = "Predicted load decrease with high confidence"
    } else {
        // 保持当前副本数
        decision.DesiredReplicas = decision.CurrentReplicas
        decision.Reason = "No significant change predicted or low confidence"
    }
    
    return decision
}
```

---

## 5.2.3 垂直扩缩容（VPA）

### 资源推荐

**VPA推荐引擎**：

```go
// VPA推荐器
type VPARecommender struct {
    history       *ResourceHistoryStore
    targetUtilization float64  // 目标利用率
}

type ResourceRecommendation struct {
    CPU    ResourceQuantity
    Memory ResourceQuantity
}

type ResourceQuantity struct {
    Request string  // 请求量
    Limit   string  // 限制量
}

func (vpa *VPARecommender) Recommend(
    podName string,
    window time.Duration,
) ResourceRecommendation {
    // 1. 获取历史资源使用
    history := vpa.history.GetPodHistory(podName, window)
    
    // 2. 统计分析
    cpuStats := vpa.analyzeUsage(history.CPU)
    memStats := vpa.analyzeUsage(history.Memory)
    
    // 3. 计算推荐值
    recommendation := ResourceRecommendation{
        CPU: vpa.recommendCPU(cpuStats),
        Memory: vpa.recommendMemory(memStats),
    }
    
    return recommendation
}

func (vpa *VPARecommender) analyzeUsage(usage []float64) UsageStats {
    sort.Float64s(usage)
    
    return UsageStats{
        Min:    usage[0],
        Max:    usage[len(usage)-1],
        Median: usage[len(usage)/2],
        P95:    usage[int(float64(len(usage))*0.95)],
        P99:    usage[int(float64(len(usage))*0.99)],
    }
}

func (vpa *VPARecommender) recommendCPU(stats UsageStats) ResourceQuantity {
    // Request = P95 / 目标利用率
    request := stats.P95 / vpa.targetUtilization
    
    // Limit = P99 * 1.2 (留20%余量)
    limit := stats.P99 * 1.2
    
    return ResourceQuantity{
        Request: fmt.Sprintf("%.0fm", request*1000),  // 转换为millicores
        Limit:   fmt.Sprintf("%.0fm", limit*1000),
    }
}

func (vpa *VPARecommender) recommendMemory(stats UsageStats) ResourceQuantity {
    // Memory: Request = Limit = P99 * 1.1
    value := stats.P99 * 1.1
    
    return ResourceQuantity{
        Request: fmt.Sprintf("%.0fMi", value/(1024*1024)),
        Limit:   fmt.Sprintf("%.0fMi", value/(1024*1024)),
    }
}
```

### 动态调整

**在线VPA调整**：

```go
// VPA更新器
type VPAUpdater struct {
    client      *kubernetes.Clientset
    recommender *VPARecommender
    updateMode  UpdateMode
}

type UpdateMode int

const (
    UpdateModeOff UpdateMode = iota  // 仅推荐，不更新
    UpdateModeInitial                 // 仅在创建时更新
    UpdateModeRecreate                // 重建Pod更新
    UpdateModeAuto                    // 自动更新（需要in-place resize支持）
)

func (vu *VPAUpdater) Update(pod *corev1.Pod) error {
    if vu.updateMode == UpdateModeOff {
        return nil
    }
    
    // 1. 获取推荐
    recommendation := vu.recommender.Recommend(pod.Name, 7*24*time.Hour)
    
    // 2. 检查是否需要更新
    needsUpdate := vu.needsUpdate(pod, recommendation)
    if !needsUpdate {
        return nil
    }
    
    // 3. 根据模式执行更新
    switch vu.updateMode {
    case UpdateModeRecreate:
        return vu.recreatePod(pod, recommendation)
    case UpdateModeAuto:
        return vu.resizeInPlace(pod, recommendation)
    }
    
    return nil
}

func (vu *VPAUpdater) needsUpdate(
    pod *corev1.Pod,
    recommendation ResourceRecommendation,
) bool {
    current := pod.Spec.Containers[0].Resources
    
    // 检查CPU差异
    currentCPU := current.Requests.Cpu().MilliValue()
    recommendedCPU := parseMilliCPU(recommendation.CPU.Request)
    cpuDiff := math.Abs(float64(currentCPU-recommendedCPU)) / float64(currentCPU)
    
    // 检查Memory差异
    currentMem := current.Requests.Memory().Value()
    recommendedMem := parseMemory(recommendation.Memory.Request)
    memDiff := math.Abs(float64(currentMem-recommendedMem)) / float64(currentMem)
    
    // 如果差异超过20%，则需要更新
    return cpuDiff > 0.2 || memDiff > 0.2
}

func (vu *VPAUpdater) resizeInPlace(
    pod *corev1.Pod,
    recommendation ResourceRecommendation,
) error {
    // Kubernetes 1.27+ 支持in-place resize
    pod.Spec.Containers[0].Resources.Requests = corev1.ResourceList{
        corev1.ResourceCPU:    resource.MustParse(recommendation.CPU.Request),
        corev1.ResourceMemory: resource.MustParse(recommendation.Memory.Request),
    }
    pod.Spec.Containers[0].Resources.Limits = corev1.ResourceList{
        corev1.ResourceCPU:    resource.MustParse(recommendation.CPU.Limit),
        corev1.ResourceMemory: resource.MustParse(recommendation.Memory.Limit),
    }
    
    _, err := vu.client.CoreV1().Pods(pod.Namespace).Update(
        context.Background(),
        pod,
        metav1.UpdateOptions{},
    )
    
    return err
}
```

---

## 5.2.4 资源配额与限流

### 动态配额

**租户资源配额管理**：

```go
// 动态配额管理器
type DynamicQuotaManager struct {
    quotas    map[string]*TenantQuota
    allocator *ResourceAllocator
    mu        sync.RWMutex
}

type TenantQuota struct {
    TenantID string
    
    // 配额
    CPUQuota    float64
    MemoryQuota uint64
    
    // 当前使用
    CPUUsed    float64
    MemoryUsed uint64
    
    // 优先级
    Priority int
}

func (dqm *DynamicQuotaManager) AllocateResources() {
    dqm.mu.Lock()
    defer dqm.mu.Unlock()
    
    // 1. 获取总资源
    totalCPU := dqm.allocator.GetTotalCPU()
    totalMemory := dqm.allocator.GetTotalMemory()
    
    // 2. 计算权重
    totalPriority := 0
    for _, quota := range dqm.quotas {
        totalPriority += quota.Priority
    }
    
    // 3. 按优先级分配
    for _, quota := range dqm.quotas {
        weight := float64(quota.Priority) / float64(totalPriority)
        quota.CPUQuota = totalCPU * weight
        quota.MemoryQuota = uint64(float64(totalMemory) * weight)
    }
}

func (dqm *DynamicQuotaManager) CanAllocate(
    tenantID string,
    cpuRequest float64,
    memoryRequest uint64,
) bool {
    dqm.mu.RLock()
    defer dqm.mu.RUnlock()
    
    quota, exists := dqm.quotas[tenantID]
    if !exists {
        return false
    }
    
    // 检查是否超过配额
    if quota.CPUUsed+cpuRequest > quota.CPUQuota {
        return false
    }
    if quota.MemoryUsed+memoryRequest > quota.MemoryQuota {
        return false
    }
    
    return true
}
```

### 公平调度

**加权公平队列**：

```go
// 加权公平调度器
type WeightedFairScheduler struct {
    queues map[string]*TenantQueue
    mu     sync.RWMutex
}

type TenantQueue struct {
    TenantID string
    Weight   int
    Tasks    []*Task
    
    // 虚拟时间
    VirtualTime float64
}

type Task struct {
    ID          string
    CPURequired float64
    StartTime   time.Time
}

func (wfs *WeightedFairScheduler) Schedule() *Task {
    wfs.mu.Lock()
    defer wfs.mu.Unlock()
    
    // 1. 找到虚拟时间最小的队列
    var minQueue *TenantQueue
    minVTime := math.Inf(1)
    
    for _, queue := range wfs.queues {
        if len(queue.Tasks) > 0 && queue.VirtualTime < minVTime {
            minVTime = queue.VirtualTime
            minQueue = queue
        }
    }
    
    if minQueue == nil {
        return nil
    }
    
    // 2. 从该队列取出任务
    task := minQueue.Tasks[0]
    minQueue.Tasks = minQueue.Tasks[1:]
    
    // 3. 更新虚拟时间
    // VirtualTime += ServiceTime / Weight
    serviceTime := task.CPURequired
    minQueue.VirtualTime += serviceTime / float64(minQueue.Weight)
    
    return task
}
```

---

## 总结

自适应资源管理核心技术：

**监控预测**：

- 全面资源监控
- ARIMA时间序列预测
- Holt-Winters季节性预测

**水平扩缩容**：

- 基于指标的HPA
- 预测性HPA
- 多指标综合决策

**垂直扩缩容**：

- 统计分析推荐
- P95/P99百分位
- In-place动态调整

**配额管理**：

- 动态配额分配
- 优先级权重
- 加权公平调度

**最佳实践**：

- 提前预测扩容
- 保守缩容策略
- 合理设置buffer
- 多维度监控
- 持续优化调整

---

**上一篇**: [14_动态采样控制.md](14_动态采样控制.md)  
**下一篇**: [16_流量控制与限流.md](16_流量控制与限流.md)

---

*最后更新: 2025年10月7日*-
