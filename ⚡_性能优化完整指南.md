# ⚡ OTLP性能优化完整指南

> **目标**: 帮助用户优化OTLP部署性能，降低成本  
> **适用场景**: 生产环境性能调优  
> **更新时间**: 2025年10月20日

---

## 📋 目录

- [⚡ OTLP性能优化完整指南](#-otlp性能优化完整指南)
  - [📋 目录](#-目录)
  - [🔧 SDK性能优化](#-sdk性能优化)
    - [1. 采样策略优化](#1-采样策略优化)
      - [1.1 固定比例采样](#11-固定比例采样)
      - [1.2 父Span决定采样](#12-父span决定采样)
      - [1.3 智能采样（推荐）](#13-智能采样推荐)
    - [2. 批处理优化](#2-批处理优化)
      - [2.1 批处理大小](#21-批处理大小)
      - [2.2 超时时间](#22-超时时间)
    - [3. 资源池复用](#3-资源池复用)
      - [3.1 连接池](#31-连接池)
      - [3.2 Span对象池](#32-span对象池)
    - [4. 减少Span数量](#4-减少span数量)
      - [4.1 合并细粒度操作](#41-合并细粒度操作)
      - [4.2 过滤不重要的操作](#42-过滤不重要的操作)
  - [🚀 Collector性能优化](#-collector性能优化)
    - [1. 并发处理](#1-并发处理)
      - [1.1 Receiver并发](#11-receiver并发)
      - [1.2 Processor并发](#12-processor并发)
    - [2. 内存优化](#2-内存优化)
      - [2.1 Memory Limiter配置](#21-memory-limiter配置)
      - [2.2 队列大小优化](#22-队列大小优化)
    - [3. 批处理优化](#3-批处理优化)
      - [3.1 批量大小vs延迟](#31-批量大小vs延迟)
      - [3.2 压缩](#32-压缩)
    - [4. 过滤器优化](#4-过滤器优化)
      - [4.1 早期过滤](#41-早期过滤)
      - [4.2 高效过滤规则](#42-高效过滤规则)
  - [🌐 网络性能优化](#-网络性能优化)
    - [1. 协议选择](#1-协议选择)
      - [1.1 gRPC vs HTTP](#11-grpc-vs-http)
      - [1.2 连接复用](#12-连接复用)
    - [2. 压缩](#2-压缩)
      - [2.1 SDK端压缩](#21-sdk端压缩)
      - [2.2 Collector端压缩](#22-collector端压缩)
  - [💾 存储性能优化](#-存储性能优化)
    - [1. 分层存储策略](#1-分层存储策略)
      - [1.1 热温冷分层](#11-热温冷分层)
      - [1.2 成本对比](#12-成本对比)
    - [2. 索引优化](#2-索引优化)
      - [2.1 Elasticsearch索引策略](#21-elasticsearch索引策略)
      - [2.2 ClickHouse表优化](#22-clickhouse表优化)
    - [3. 查询优化](#3-查询优化)
      - [3.1 添加合适的索引](#31-添加合适的索引)
      - [3.2 使用物化视图](#32-使用物化视图)
  - [💰 成本优化](#-成本优化)
    - [1. Uber案例：成本优化99%](#1-uber案例成本优化99)
      - [问题](#问题)
      - [优化方案](#优化方案)
      - [效果](#效果)
    - [2. 采样策略推荐](#2-采样策略推荐)
  - [📊 监控与调优](#-监控与调优)
    - [1. 关键指标监控](#1-关键指标监控)
      - [1.1 Collector指标](#11-collector指标)
      - [1.2 告警规则](#12-告警规则)
    - [2. 性能基准测试](#2-性能基准测试)
      - [2.1 吞吐量测试](#21-吞吐量测试)
      - [2.2 延迟测试](#22-延迟测试)
    - [3. 调优检查清单](#3-调优检查清单)
      - [SDK调优](#sdk调优)
      - [Collector调优](#collector调优)
      - [存储调优](#存储调优)
      - [成本优化](#成本优化)
  - [🔗 相关资源](#-相关资源)

---

## 🔧 SDK性能优化

### 1. 采样策略优化

#### 1.1 固定比例采样

```go
// 生产环境：1%采样
tp := sdktrace.NewTracerProvider(
    sdktrace.WithSampler(sdktrace.TraceIDRatioBased(0.01)),  // 1%
    sdktrace.WithBatcher(exporter),
)

// 测试环境：100%采样
tp := sdktrace.NewTracerProvider(
    sdktrace.WithSampler(sdktrace.AlwaysSample()),  // 100%
)
```

**效果**:

- 数据量减少99%
- 成本降低99%
- 仍能看到1%的正常流量

#### 1.2 父Span决定采样

```go
// 子Span跟随父Span的采样决策
tp := sdktrace.NewTracerProvider(
    sdktrace.WithSampler(sdktrace.ParentBased(
        sdktrace.TraceIDRatioBased(0.01),  // 根Span 1%采样
    )),
)
```

**优势**:

- 保证Trace完整性
- 避免Trace碎片化

#### 1.3 智能采样（推荐）

在Collector端使用Tail Sampling：

```yaml
processors:
  tail_sampling:
    decision_wait: 10s
    num_traces: 100000
    policies:
      # 100%保留错误Trace
      - name: errors
        type: status_code
        status_code:
          status_codes: [ERROR]
      
      # 100%保留慢Trace (>1s)
      - name: slow
        type: latency
        latency:
          threshold_ms: 1000
      
      # 100%保留VIP用户
      - name: vip-users
        type: string_attribute
        string_attribute:
          key: myapp.user.tier
          values: [platinum, gold]
      
      # 1%采样普通流量
      - name: normal
        type: probabilistic
        probabilistic:
          sampling_percentage: 1
```

**效果对比**:

| 场景 | 固定1%采样 | 智能采样 |
|------|-----------|---------|
| **数据量** | 1% | 3-5% |
| **错误覆盖** | 1% | 100% ✅ |
| **慢请求覆盖** | 1% | 100% ✅ |
| **VIP用户** | 1% | 100% ✅ |
| **成本** | $$ | $$$ |

---

### 2. 批处理优化

#### 2.1 批处理大小

```go
exporter, err := otlptracegrpc.New(ctx,
    otlptracegrpc.WithEndpoint("localhost:4317"),
)

tp := sdktrace.NewTracerProvider(
    // 批处理配置
    sdktrace.WithBatcher(exporter,
        sdktrace.WithMaxExportBatchSize(512),    // ✅ 批量大小
        sdktrace.WithBatchTimeout(time.Second),  // ✅ 超时时间
        sdktrace.WithMaxQueueSize(2048),         // ✅ 队列大小
    ),
)
```

**性能影响**:

| 批量大小 | 网络请求 | 延迟 | CPU | 推荐场景 |
|---------|---------|------|-----|---------|
| 128 | 多 | 低 | 高 | 低延迟要求 |
| 512 | 中 | 中 | 中 | **推荐** ⭐ |
| 2048 | 少 | 高 | 低 | 高吞吐量 |

#### 2.2 超时时间

```go
// 低延迟场景（实时监控）
sdktrace.WithBatchTimeout(100 * time.Millisecond)

// 均衡场景（推荐）
sdktrace.WithBatchTimeout(1 * time.Second)

// 高吞吐场景（离线分析）
sdktrace.WithBatchTimeout(5 * time.Second)
```

---

### 3. 资源池复用

#### 3.1 连接池

```go
// ✅ 复用gRPC连接
var (
    conn     *grpc.ClientConn
    connOnce sync.Once
)

func getExporter(ctx context.Context) (*otlptrace.Exporter, error) {
    connOnce.Do(func() {
        var err error
        conn, err = grpc.DialContext(ctx, "localhost:4317",
            grpc.WithTransportCredentials(insecure.NewCredentials()),
            grpc.WithBlock(),
        )
        if err != nil {
            log.Fatal(err)
        }
    })
    
    return otlptracegrpc.New(ctx, otlptracegrpc.WithGRPCConn(conn))
}
```

#### 3.2 Span对象池

```go
// 对于高频操作，使用对象池
var spanPool = sync.Pool{
    New: func() interface{} {
        return &spanData{}
    },
}

func getSpan() *spanData {
    return spanPool.Get().(*spanData)
}

func putSpan(s *spanData) {
    s.Reset()
    spanPool.Put(s)
}
```

---

### 4. 减少Span数量

#### 4.1 合并细粒度操作

```go
// ❌ 过度细化
func processOrder(ctx context.Context) {
    _, span1 := tracer.Start(ctx, "validate_field_1")
    // ...
    span1.End()
    
    _, span2 := tracer.Start(ctx, "validate_field_2")
    // ...
    span2.End()
    
    // 100+ spans for one order
}

// ✅ 合理粒度
func processOrder(ctx context.Context) {
    _, span := tracer.Start(ctx, "validate_order")
    // validate all fields
    span.End()
    
    // 5-10 spans per order
}
```

#### 4.2 过滤不重要的操作

```go
// 不为健康检查创建Span
func healthCheck(w http.ResponseWriter, r *http.Request) {
    // ❌ 不需要追踪
    // ctx, span := tracer.Start(r.Context(), "health_check")
    // defer span.End()
    
    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}
```

---

## 🚀 Collector性能优化

### 1. 并发处理

#### 1.1 Receiver并发

```yaml
receivers:
  otlp:
    protocols:
      grpc:
        max_recv_msg_size_mib: 16        # ✅ 增大消息大小
        max_concurrent_streams: 100      # ✅ 增加并发流
        read_buffer_size: 524288         # 512KB
        write_buffer_size: 524288
```

#### 1.2 Processor并发

```yaml
processors:
  batch:
    timeout: 1s
    send_batch_size: 512
  
  # 并发处理多个batch
  batch/parallel:
    timeout: 1s
    send_batch_size: 512
```

---

### 2. 内存优化

#### 2.1 Memory Limiter配置

```yaml
processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 2048        # 根据实际内存调整
    spike_limit_mib: 512   # 允许20-25%突发
```

**推荐配置**:

| 主机内存 | limit_mib | spike_limit_mib |
|---------|-----------|-----------------|
| 4GB | 2048 | 512 |
| 8GB | 4096 | 1024 |
| 16GB | 8192 | 2048 |

#### 2.2 队列大小优化

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    sending_queue:
      enabled: true
      num_consumers: 10        # ✅ CPU cores * 1.5
      queue_size: 5000         # ✅ 根据吞吐量调整
```

**计算方法**:

```text
queue_size = 峰值QPS * 延迟(秒) * 1.5

例如：
峰值QPS: 1000 spans/s
平均延迟: 2s
queue_size = 1000 * 2 * 1.5 = 3000
```

---

### 3. 批处理优化

#### 3.1 批量大小vs延迟

```yaml
# 低延迟优先（<100ms）
processors:
  batch:
    timeout: 100ms
    send_batch_size: 128

# 平衡模式（推荐）
processors:
  batch:
    timeout: 1s
    send_batch_size: 512

# 高吞吐优先
processors:
  batch:
    timeout: 5s
    send_batch_size: 2048
```

#### 3.2 压缩

```yaml
exporters:
  otlp:
    endpoint: backend:4317
    compression: gzip    # ✅ 启用压缩
```

**压缩效果**:

- 网络带宽: 减少70-80%
- CPU开销: 增加10-15%
- 推荐: 远程导出

---

### 4. 过滤器优化

#### 4.1 早期过滤

```yaml
# ✅ 在Pipeline早期过滤，减少后续处理
service:
  pipelines:
    traces:
      receivers: [otlp]
      processors:
        - filter          # 1️⃣ 先过滤
        - memory_limiter  # 2️⃣ 再限制内存
        - batch           # 3️⃣ 最后批处理
      exporters: [jaeger]
```

#### 4.2 高效过滤规则

```yaml
processors:
  filter:
    traces:
      span:
        # ✅ 使用简单匹配
        - 'attributes["http.target"] == "/health"'
        
        # ❌ 避免复杂正则
        # - 'attributes["http.target"] matches "^/api/v[0-9]+/health.*"'
```

---

## 🌐 网络性能优化

### 1. 协议选择

#### 1.1 gRPC vs HTTP

```go
// gRPC（推荐）- 性能更好
exporter, err := otlptracegrpc.New(ctx,
    otlptracegrpc.WithEndpoint("localhost:4317"),
)

// HTTP - 兼容性更好
exporter, err := otlptracehttp.New(ctx,
    otlptracehttp.WithEndpoint("http://localhost:4318/v1/traces"),
)
```

**性能对比**:

| 指标 | gRPC | HTTP |
|------|------|------|
| **吞吐量** | 高 ✅ | 中 |
| **延迟** | 低 ✅ | 中 |
| **CPU** | 低 ✅ | 高 |
| **兼容性** | 中 | 高 ✅ |

#### 1.2 连接复用

```go
// ✅ 启用HTTP/2连接复用
exporter, err := otlptracegrpc.New(ctx,
    otlptracegrpc.WithEndpoint("localhost:4317"),
    otlptracegrpc.WithGRPCConn(conn),  // 复用连接
)
```

---

### 2. 压缩

#### 2.1 SDK端压缩

```go
import "google.golang.org/grpc/encoding/gzip"

exporter, err := otlptracegrpc.New(ctx,
    otlptracegrpc.WithEndpoint("localhost:4317"),
    otlptracegrpc.WithCompressor(gzip.Name),  // ✅ gzip压缩
)
```

#### 2.2 Collector端压缩

```yaml
exporters:
  otlp:
    endpoint: remote-collector:4317
    compression: gzip   # ✅ 远程导出使用压缩
    # compression: none # ✅ 本地导出不压缩
```

**压缩效果**:

- 带宽节省: 70-80%
- CPU开销: +10-15%
- 推荐场景: 跨地域、带宽受限

---

## 💾 存储性能优化

### 1. 分层存储策略

#### 1.1 热温冷分层

```yaml
# 热数据: Elasticsearch (7天)
exporters:
  elasticsearch/hot:
    endpoints: [http://es-hot:9200]
    traces_index: traces-hot
    ilm_enabled: true
    ilm_policy_name: traces-hot-ilm

# 温数据: ClickHouse (30天，10%采样)
exporters:
  clickhouse/warm:
    endpoint: tcp://clickhouse:9000
    database: otlp
    ttl_days: 30

# 冷数据: S3 (永久归档)
exporters:
  awss3/cold:
    s3uploader:
      region: us-west-2
      s3_bucket: otlp-archive
      storage_class: GLACIER
```

#### 1.2 成本对比

| 存储层 | 保留时间 | 数据量 | 月成本/TB | 查询延迟 |
|--------|---------|-------|----------|---------|
| **热 (ES)** | 7天 | 100% | $350 | <100ms |
| **温 (CH)** | 30天 | 10% | $45 | <1s |
| **冷 (S3)** | 1年+ | 100% | $4 | 分钟级 |

---

### 2. 索引优化

#### 2.1 Elasticsearch索引策略

```json
{
  "settings": {
    "number_of_shards": 6,      // ✅ 根据数据量调整
    "number_of_replicas": 1,    // ✅ 高可用
    "refresh_interval": "30s",  // ✅ 降低刷新频率
    "index.codec": "best_compression"  // ✅ 压缩
  },
  "mappings": {
    "properties": {
      "trace_id": {
        "type": "keyword",
        "index": true  // ✅ 高频查询字段
      },
      "attributes": {
        "type": "object",
        "enabled": false  // ❌ 不索引，减少空间
      }
    }
  }
}
```

#### 2.2 ClickHouse表优化

```sql
CREATE TABLE otlp.traces (
    trace_id String,
    span_id String,
    start_time DateTime64(9),
    duration UInt64,
    service_name String,
    
    -- 索引优化
    INDEX idx_service service_name TYPE bloom_filter GRANULARITY 4,
    INDEX idx_duration duration TYPE minmax GRANULARITY 1
)
ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/traces', '{replica}')
PARTITION BY toYYYYMMDD(start_time)  -- ✅ 按天分区
ORDER BY (service_name, start_time, trace_id)  -- ✅ 排序键
TTL start_time + INTERVAL 30 DAY  -- ✅ 自动清理
SETTINGS
    index_granularity = 8192,  -- ✅ 索引粒度
    min_bytes_for_wide_part = 0,  -- ✅ 压缩
    min_rows_for_wide_part = 0;
```

---

### 3. 查询优化

#### 3.1 添加合适的索引

```sql
-- ClickHouse: 为常用查询添加跳数索引
ALTER TABLE traces ADD INDEX idx_status_code status_code TYPE set(0) GRANULARITY 1;
```

#### 3.2 使用物化视图

```sql
-- 预聚合常用指标
CREATE MATERIALIZED VIEW traces_hourly_stats
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(hour)
ORDER BY (service_name, hour)
AS SELECT
    service_name,
    toStartOfHour(start_time) as hour,
    count() as span_count,
    avg(duration) as avg_duration,
    quantile(0.99)(duration) as p99_duration
FROM traces
GROUP BY service_name, hour;
```

---

## 💰 成本优化

### 1. Uber案例：成本优化99%

#### 问题

```text
原始成本: $500K/月
数据量: 50亿 spans/天
存储: 全量存储90天
```

#### 优化方案

```yaml
# 1. 智能采样
processors:
  tail_sampling:
    policies:
      - name: errors
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow
        type: latency
        latency: {threshold_ms: 2000}
      - name: normal
        type: probabilistic
        probabilistic: {sampling_percentage: 0.1}  # 0.1%

# 2. 分层存储
# 热数据(3天): 错误+慢请求
# 温数据(30天): 0.1%采样
# 冷数据(1年): S3归档

# 3. 压缩
compression: gzip
```

#### 效果

```text
优化后成本: $5K/月
数据量: 500M spans/天 (减少90%)
错误覆盖: 100% ✅
慢请求覆盖: 100% ✅
成本节省: 99% ✅
```

---

### 2. 采样策略推荐

| 场景 | 采样率 | 月成本/1M spans | 说明 |
|------|--------|----------------|------|
| **开发环境** | 100% | $100 | 全量数据 |
| **测试环境** | 50% | $50 | 足够测试 |
| **生产环境** | | | |
| - 小规模 (<10M/天) | 10% | $10 | 成本可控 |
| - 中规模 (10-100M/天) | 1% | $10 | **推荐** ⭐ |
| - 大规模 (>100M/天) | 智能采样 | $5-15 | 最优方案 |

---

## 📊 监控与调优

### 1. 关键指标监控

#### 1.1 Collector指标

```bash
# 接收速率
otelcol_receiver_accepted_spans{receiver="otlp"} 

# 导出速率
otelcol_exporter_sent_spans{exporter="jaeger"}

# 队列长度
otelcol_exporter_queue_size{exporter="jaeger"}

# 处理延迟
otelcol_processor_batch_batch_send_size_sum
otelcol_processor_batch_batch_send_size_count
```

#### 1.2 告警规则

```yaml
# Prometheus告警
groups:
  - name: otlp-collector
    rules:
      # 队列接近满
      - alert: CollectorQueueAlmostFull
        expr: otelcol_exporter_queue_size > 4000
        for: 5m
        annotations:
          summary: "Collector queue is almost full"
      
      # 导出失败率高
      - alert: HighExportFailureRate
        expr: rate(otelcol_exporter_send_failed_spans[5m]) > 100
        for: 5m
        annotations:
          summary: "High export failure rate"
```

---

### 2. 性能基准测试

#### 2.1 吞吐量测试

```bash
# 使用otel-bench进行压测
go install github.com/open-telemetry/opentelemetry-collector-contrib/cmd/telemetrygen@latest

# 生成10000 spans，1000 spans/s
telemetrygen traces --otlp-insecure \
  --traces 10000 \
  --rate 1000 \
  --otlp-endpoint localhost:4317
```

#### 2.2 延迟测试

```go
// 测量端到端延迟
start := time.Now()

ctx, span := tracer.Start(ctx, "test")
span.End()

// 等待导出完成
time.Sleep(2 * time.Second)

latency := time.Since(start)
fmt.Printf("End-to-end latency: %v\n", latency)
```

---

### 3. 调优检查清单

#### SDK调优

- [ ] 启用批处理
- [ ] 配置合理的采样率
- [ ] 使用异步导出
- [ ] 复用连接
- [ ] 减少不必要的Span
- [ ] 启用压缩（远程场景）

#### Collector调优

- [ ] 配置Memory Limiter
- [ ] 优化批处理大小
- [ ] 增加并发处理
- [ ] 早期过滤
- [ ] 启用智能采样
- [ ] 配置合理的队列大小

#### 存储调优

- [ ] 分层存储策略
- [ ] 索引优化
- [ ] 数据压缩
- [ ] 自动清理（TTL）
- [ ] 使用物化视图

#### 成本优化

- [ ] 智能采样
- [ ] 分层存储
- [ ] 数据压缩
- [ ] 定期清理
- [ ] 监控成本指标

---

## 🔗 相关资源

- [🔧 故障排查手册](🔧_故障排查完整手册.md) - 解决常见问题
- [🎯 快速入门指南](🎯_5分钟快速入门指南.md) - 快速开始
- [Collector配置示例](examples/collector-configurations/README.md) - 配置参考

---

**更新时间**: 2025年10月20日  
**版本**: v1.0.0  
**维护者**: OTLP项目团队

---

**⚡ 优化性能，降低成本！** 🚀
