# â˜¸ï¸ OTLP Kuberneteséƒ¨ç½²å®Œæ•´æŒ‡å—

> **ç›®æ ‡**: å¸®åŠ©ç”¨æˆ·åœ¨Kubernetesé›†ç¾¤ä¸­éƒ¨ç½²ç”Ÿäº§çº§OTLPç¯å¢ƒ  
> **é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡éƒ¨ç½²  
> **æ›´æ–°æ—¶é—´**: 2025å¹´10æœˆ20æ—¥

---

## ğŸ“‹ ç›®å½•

- [â˜¸ï¸ OTLP Kuberneteséƒ¨ç½²å®Œæ•´æŒ‡å—](#ï¸-otlp-kuberneteséƒ¨ç½²å®Œæ•´æŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [ğŸš€ ç¯å¢ƒå‡†å¤‡](#-ç¯å¢ƒå‡†å¤‡)
    - [1. å‰ç½®æ¡ä»¶](#1-å‰ç½®æ¡ä»¶)
    - [2. åˆ›å»ºå‘½åç©ºé—´](#2-åˆ›å»ºå‘½åç©ºé—´)
  - [ğŸ¯ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
    - [1. ä½¿ç”¨Helméƒ¨ç½²](#1-ä½¿ç”¨helméƒ¨ç½²)
    - [2. éªŒè¯éƒ¨ç½²](#2-éªŒè¯éƒ¨ç½²)
  - [ğŸ—ï¸ å®Œæ•´éƒ¨ç½²](#ï¸-å®Œæ•´éƒ¨ç½²)
    - [1. OpenTelemetry Collectoréƒ¨ç½²](#1-opentelemetry-collectoréƒ¨ç½²)
    - [2. åº”ç”¨é…ç½®](#2-åº”ç”¨é…ç½®)
    - [3. éªŒè¯éƒ¨ç½²](#3-éªŒè¯éƒ¨ç½²)
  - [ğŸ”§ Jaegeréƒ¨ç½²](#-jaegeréƒ¨ç½²)
  - [âš™ï¸ é…ç½®ç®¡ç†](#ï¸-é…ç½®ç®¡ç†)
    - [1. ä½¿ç”¨Kustomize](#1-ä½¿ç”¨kustomize)
    - [2. ä½¿ç”¨Helm Values](#2-ä½¿ç”¨helm-values)
  - [ğŸ“ˆ æ‰©å±•å’Œé«˜å¯ç”¨](#-æ‰©å±•å’Œé«˜å¯ç”¨)
    - [1. DaemonSetæ¨¡å¼ï¼ˆèŠ‚ç‚¹çº§é‡‡é›†ï¼‰](#1-daemonsetæ¨¡å¼èŠ‚ç‚¹çº§é‡‡é›†)
    - [2. StatefulSetæ¨¡å¼ï¼ˆæœ‰çŠ¶æ€éƒ¨ç½²ï¼‰](#2-statefulsetæ¨¡å¼æœ‰çŠ¶æ€éƒ¨ç½²)
    - [3. å¤šå±‚æ¶æ„](#3-å¤šå±‚æ¶æ„)
  - [ğŸ“Š ç›‘æ§å’Œæ—¥å¿—](#-ç›‘æ§å’Œæ—¥å¿—)
    - [1. Prometheus ServiceMonitor](#1-prometheus-servicemonitor)
    - [2. æ—¥å¿—èšåˆ](#2-æ—¥å¿—èšåˆ)
    - [3. Grafana Dashboard](#3-grafana-dashboard)
  - [ğŸ”§ æ•…éšœæ’æŸ¥](#-æ•…éšœæ’æŸ¥)
    - [1. Podæ— æ³•å¯åŠ¨](#1-podæ— æ³•å¯åŠ¨)
    - [2. æœåŠ¡è¿æ¥é—®é¢˜](#2-æœåŠ¡è¿æ¥é—®é¢˜)
    - [3. æ€§èƒ½é—®é¢˜](#3-æ€§èƒ½é—®é¢˜)
  - [ğŸ“‹ æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
    - [1. RBACé…ç½®](#1-rbacé…ç½®)
    - [2. èµ„æºé™åˆ¶](#2-èµ„æºé™åˆ¶)
    - [3. èŠ‚ç‚¹äº²å’Œæ€§](#3-èŠ‚ç‚¹äº²å’Œæ€§)
    - [4. PodDisruptionBudget](#4-poddisruptionbudget)
    - [5. NetworkPolicy](#5-networkpolicy)
  - [ğŸ”— ç›¸å…³èµ„æº](#-ç›¸å…³èµ„æº)

---

## ğŸš€ ç¯å¢ƒå‡†å¤‡

### 1. å‰ç½®æ¡ä»¶

```bash
# Kubernetesé›†ç¾¤ >= 1.24
kubectl version

# Helm >= 3.0
helm version

# ç¡®è®¤é›†ç¾¤å¯ç”¨
kubectl cluster-info
kubectl get nodes
```

### 2. åˆ›å»ºå‘½åç©ºé—´

```bash
# åˆ›å»ºobservabilityå‘½åç©ºé—´
kubectl create namespace observability

# è®¾ç½®é»˜è®¤å‘½åç©ºé—´
kubectl config set-context --current --namespace=observability
```

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨Helméƒ¨ç½²

```bash
# æ·»åŠ OpenTelemetry Helmä»“åº“
helm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts
helm repo update

# å®‰è£…OpenTelemetry Collector
helm install otel-collector open-telemetry/opentelemetry-collector \
  --namespace observability \
  --create-namespace

# å®‰è£…Jaeger
helm repo add jaegertracing https://jaegertracing.github.io/helm-charts
helm install jaeger jaegertracing/jaeger \
  --namespace observability
```

### 2. éªŒè¯éƒ¨ç½²

```bash
# æŸ¥çœ‹PodçŠ¶æ€
kubectl get pods -n observability

# æŸ¥çœ‹æœåŠ¡
kubectl get svc -n observability

# ç«¯å£è½¬å‘è®¿é—®Jaeger UI
kubectl port-forward -n observability svc/jaeger-query 16686:16686
# è®¿é—® http://localhost:16686
```

âœ… **å¿«é€Ÿéƒ¨ç½²å®Œæˆï¼**

---

## ğŸ—ï¸ å®Œæ•´éƒ¨ç½²

### 1. OpenTelemetry Collectoréƒ¨ç½²

åˆ›å»º `otel-collector.yaml`:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: observability
data:
  otel-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:
      memory_limiter:
        check_interval: 1s
        limit_mib: 2048
        spike_limit_mib: 512
      
      batch:
        timeout: 1s
        send_batch_size: 512
      
      resourcedetection:
        detectors: [env, system, docker]
        timeout: 5s
    
    exporters:
      jaeger:
        endpoint: jaeger-collector.observability.svc.cluster.local:14250
        tls:
          insecure: true
      
      prometheus:
        endpoint: 0.0.0.0:8889
      
      logging:
        loglevel: info
    
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      
      pprof:
        endpoint: 0.0.0.0:1777
    
    service:
      extensions: [health_check, pprof]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, resourcedetection, batch]
          exporters: [jaeger, logging]
        
        metrics:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [prometheus]

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: observability
  labels:
    app: otel-collector
    component: collector
spec:
  replicas: 2
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        args:
          - "--config=/conf/otel-config.yaml"
        ports:
        - containerPort: 4317
          name: otlp-grpc
          protocol: TCP
        - containerPort: 4318
          name: otlp-http
          protocol: TCP
        - containerPort: 13133
          name: health-check
          protocol: TCP
        - containerPort: 8888
          name: metrics
          protocol: TCP
        - containerPort: 8889
          name: prometheus
          protocol: TCP
        
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 10
          periodSeconds: 5
        
        volumeMounts:
        - name: config
          mountPath: /conf
      
      volumes:
      - name: config
        configMap:
          name: otel-collector-config

---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: observability
  labels:
    app: otel-collector
spec:
  type: ClusterIP
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  - name: metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
  - name: prometheus
    port: 8889
    targetPort: 8889
    protocol: TCP
  selector:
    app: otel-collector

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: otel-collector-hpa
  namespace: observability
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: otel-collector
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 2. åº”ç”¨é…ç½®

```bash
kubectl apply -f otel-collector.yaml
```

### 3. éªŒè¯éƒ¨ç½²

```bash
# æŸ¥çœ‹Deployment
kubectl get deployment -n observability

# æŸ¥çœ‹Pod
kubectl get pods -n observability -l app=otel-collector

# æŸ¥çœ‹Service
kubectl get svc -n observability otel-collector

# æŸ¥çœ‹HPA
kubectl get hpa -n observability
```

---

## ğŸ”§ Jaegeréƒ¨ç½²

åˆ›å»º `jaeger.yaml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: jaeger-collector
  namespace: observability
  labels:
    app: jaeger
    component: collector
spec:
  type: ClusterIP
  ports:
  - name: grpc
    port: 14250
    targetPort: 14250
    protocol: TCP
  - name: http
    port: 14268
    targetPort: 14268
    protocol: TCP
  selector:
    app: jaeger
    component: collector

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-query
  namespace: observability
  labels:
    app: jaeger
    component: query
spec:
  type: LoadBalancer
  ports:
  - name: http-query
    port: 16686
    targetPort: 16686
    protocol: TCP
  selector:
    app: jaeger
    component: query

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
  namespace: observability
  labels:
    app: jaeger
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
        component: all-in-one
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:latest
        env:
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        - name: SPAN_STORAGE_TYPE
          value: "badger"
        - name: BADGER_EPHEMERAL
          value: "false"
        - name: BADGER_DIRECTORY_VALUE
          value: "/badger/data"
        - name: BADGER_DIRECTORY_KEY
          value: "/badger/key"
        ports:
        - containerPort: 16686
          name: query
        - containerPort: 14250
          name: grpc
        - containerPort: 14268
          name: http
        - containerPort: 6831
          name: thrift
          protocol: UDP
        
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        
        volumeMounts:
        - name: badger-data
          mountPath: /badger
      
      volumes:
      - name: badger-data
        persistentVolumeClaim:
          claimName: jaeger-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jaeger-pvc
  namespace: observability
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
```

åº”ç”¨é…ç½®:

```bash
kubectl apply -f jaeger.yaml
```

---

## âš™ï¸ é…ç½®ç®¡ç†

### 1. ä½¿ç”¨Kustomize

åˆ›å»ºç›®å½•ç»“æ„:

```text
k8s/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ otel-collector.yaml
â”‚   â””â”€â”€ jaeger.yaml
â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â””â”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ kustomization.yaml
â”‚   â””â”€â”€ prod/
â”‚       â””â”€â”€ kustomization.yaml
```

**base/kustomization.yaml**:

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - otel-collector.yaml
  - jaeger.yaml

commonLabels:
  app.kubernetes.io/name: otlp
  app.kubernetes.io/managed-by: kustomize
```

**overlays/prod/kustomization.yaml**:

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

bases:
  - ../../base

namespace: observability-prod

replicas:
  - name: otel-collector
    count: 5

patchesStrategicMerge:
  - |-
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: otel-collector
    spec:
      template:
        spec:
          containers:
          - name: otel-collector
            resources:
              requests:
                memory: "2Gi"
                cpu: "1000m"
              limits:
                memory: "4Gi"
                cpu: "2000m"
```

éƒ¨ç½²:

```bash
# å¼€å‘ç¯å¢ƒ
kubectl apply -k k8s/overlays/dev

# ç”Ÿäº§ç¯å¢ƒ
kubectl apply -k k8s/overlays/prod
```

### 2. ä½¿ç”¨Helm Values

åˆ›å»º `values.yaml`:

```yaml
# OpenTelemetry Collectoré…ç½®
opentelemetry-collector:
  mode: deployment
  replicaCount: 3
  
  image:
    repository: otel/opentelemetry-collector-contrib
    tag: latest
  
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
  
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:
      memory_limiter:
        limit_mib: 2048
      batch:
        timeout: 1s
    
    exporters:
      jaeger:
        endpoint: jaeger-collector:14250
        tls:
          insecure: true
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [jaeger]
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
```

éƒ¨ç½²:

```bash
helm install otel-collector open-telemetry/opentelemetry-collector \
  --namespace observability \
  --values values.yaml
```

---

## ğŸ“ˆ æ‰©å±•å’Œé«˜å¯ç”¨

### 1. DaemonSetæ¨¡å¼ï¼ˆèŠ‚ç‚¹çº§é‡‡é›†ï¼‰

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-collector-agent
  namespace: observability
spec:
  selector:
    matchLabels:
      app: otel-collector-agent
  template:
    metadata:
      labels:
        app: otel-collector-agent
    spec:
      serviceAccountName: otel-collector
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        args:
          - "--config=/conf/otel-agent-config.yaml"
        volumeMounts:
        - name: config
          mountPath: /conf
        - name: hostfs
          mountPath: /hostfs
          readOnly: true
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      
      volumes:
      - name: config
        configMap:
          name: otel-collector-agent-config
      - name: hostfs
        hostPath:
          path: /
```

### 2. StatefulSetæ¨¡å¼ï¼ˆæœ‰çŠ¶æ€éƒ¨ç½²ï¼‰

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: otel-collector-stateful
  namespace: observability
spec:
  serviceName: otel-collector-stateful
  replicas: 3
  selector:
    matchLabels:
      app: otel-collector-stateful
  template:
    metadata:
      labels:
        app: otel-collector-stateful
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        volumeMounts:
        - name: data
          mountPath: /data
  
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
```

### 3. å¤šå±‚æ¶æ„

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           åº”ç”¨Pod (æ¯ä¸ªèŠ‚ç‚¹)                 â”‚
â”‚         â†“ (DaemonSet Agent)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      otel-collector-agent (DaemonSet)       â”‚
â”‚         â†“ (æœ¬åœ°èšåˆ)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    otel-collector-gateway (Deployment)      â”‚
â”‚         â†“ (é›†ä¸­å¤„ç†)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Jaeger / Prometheus / ES            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### 1. Prometheus ServiceMonitor

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: otel-collector
  namespace: observability
  labels:
    app: otel-collector
spec:
  selector:
    matchLabels:
      app: otel-collector
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### 2. æ—¥å¿—èšåˆ

```bash
# æŸ¥çœ‹æ‰€æœ‰Collectoræ—¥å¿—
kubectl logs -n observability -l app=otel-collector --tail=100 -f

# æŸ¥çœ‹ç‰¹å®šPodæ—¥å¿—
kubectl logs -n observability otel-collector-xxx -f

# å¯¼å‡ºæ—¥å¿—
kubectl logs -n observability -l app=otel-collector > collector.log
```

### 3. Grafana Dashboard

```bash
# å®‰è£…Grafana
helm install grafana grafana/grafana \
  --namespace observability \
  --set adminPassword=admin123

# ç«¯å£è½¬å‘
kubectl port-forward -n observability svc/grafana 3000:80

# è®¿é—® http://localhost:3000
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### 1. Podæ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹PodçŠ¶æ€
kubectl get pods -n observability

# æŸ¥çœ‹Podè¯¦æƒ…
kubectl describe pod -n observability otel-collector-xxx

# æŸ¥çœ‹äº‹ä»¶
kubectl get events -n observability --sort-by='.lastTimestamp'

# æŸ¥çœ‹æ—¥å¿—
kubectl logs -n observability otel-collector-xxx --previous
```

### 2. æœåŠ¡è¿æ¥é—®é¢˜

```bash
# æµ‹è¯•æœåŠ¡DNS
kubectl run -it --rm debug --image=busybox --restart=Never -n observability -- sh
nslookup otel-collector
nslookup jaeger-collector

# æµ‹è¯•æœåŠ¡è¿æ¥
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -n observability -- \
  curl http://otel-collector:13133/
```

### 3. æ€§èƒ½é—®é¢˜

```bash
# æŸ¥çœ‹èµ„æºä½¿ç”¨
kubectl top pods -n observability

# æŸ¥çœ‹èŠ‚ç‚¹èµ„æº
kubectl top nodes

# æŸ¥çœ‹HPAçŠ¶æ€
kubectl get hpa -n observability
kubectl describe hpa otel-collector-hpa -n observability
```

---

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. RBACé…ç½®

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: observability

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector
  namespace: observability
```

### 2. èµ„æºé™åˆ¶

```yaml
resources:
  requests:
    memory: "1Gi"
    cpu: "500m"
  limits:
    memory: "2Gi"
    cpu: "1000m"
```

### 3. èŠ‚ç‚¹äº²å’Œæ€§

```yaml
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: node-role.kubernetes.io/worker
          operator: In
          values:
          - "true"
  
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - otel-collector
        topologyKey: kubernetes.io/hostname
```

### 4. PodDisruptionBudget

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: otel-collector-pdb
  namespace: observability
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: otel-collector
```

### 5. NetworkPolicy

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: otel-collector-netpol
  namespace: observability
spec:
  podSelector:
    matchLabels:
      app: otel-collector
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 4317
    - protocol: TCP
      port: 4318
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: observability
    ports:
    - protocol: TCP
      port: 14250  # Jaeger
```

---

## ğŸ”— ç›¸å…³èµ„æº

- [ğŸ³ Dockeréƒ¨ç½²æŒ‡å—](ğŸ³_Dockeréƒ¨ç½²å®Œæ•´æŒ‡å—.md) - Dockeréƒ¨ç½²
- [ğŸ”§ æ•…éšœæ’æŸ¥æ‰‹å†Œ](ğŸ”§_æ•…éšœæ’æŸ¥å®Œæ•´æ‰‹å†Œ.md) - è§£å†³é—®é¢˜
- [âš¡ æ€§èƒ½ä¼˜åŒ–æŒ‡å—](âš¡_æ€§èƒ½ä¼˜åŒ–å®Œæ•´æŒ‡å—.md) - ä¼˜åŒ–æ€§èƒ½

---

**æ›´æ–°æ—¶é—´**: 2025å¹´10æœˆ20æ—¥  
**ç‰ˆæœ¬**: v1.0.0  
**ç»´æŠ¤è€…**: OTLPé¡¹ç›®å›¢é˜Ÿ

---

**â˜¸ï¸ åœ¨Kubernetesä¸Šéƒ¨ç½²ç”Ÿäº§çº§OTLPç¯å¢ƒï¼** ğŸš€
